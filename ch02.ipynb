{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 9.0\n",
      "x.grad: 18.0\n",
      "y.grad: -6.0\n",
      "a.grad: 12.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor(2, dtype=torch.float32, requires_grad=True)\n",
    "y = torch.tensor(3, dtype=torch.float32, requires_grad=True)\n",
    "a = torch.tensor(3, dtype=torch.float32, requires_grad=True)\n",
    "\n",
    "loss = (a * x - y) ** 2\n",
    "\n",
    "print(f\"loss: {loss}\")\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print(f\"x.grad: {x.grad}\")\n",
    "print(f\"y.grad: {y.grad}\")\n",
    "print(f\"a.grad: {a.grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a : 3.0, loss : 9.0, a.grad: 12.0\n",
      "a : 2.880000114440918, loss : 7.61760139465332, a.grad: 11.040000915527344\n",
      "a : 2.7696001529693604, loss : 6.447538375854492, a.grad: 10.156801223754883\n",
      "a : 2.668032169342041, loss : 5.4571967124938965, a.grad: 9.344257354736328\n",
      "a : 2.574589490890503, loss : 4.6189703941345215, a.grad: 8.596715927124023\n",
      "a : 2.4886224269866943, loss : 3.9094972610473633, a.grad: 7.908979415893555\n",
      "a : 2.4095325469970703, loss : 3.308997869491577, a.grad: 7.2762603759765625\n",
      "a : 2.3367700576782227, loss : 2.800736427307129, a.grad: 6.694160461425781\n",
      "a : 2.2698285579681396, loss : 2.370543956756592, a.grad: 6.158628463745117\n",
      "a : 2.208242177963257, loss : 2.0064280033111572, a.grad: 5.665937423706055\n",
      "a : 2.151582717895508, loss : 1.6982401609420776, a.grad: 5.2126617431640625\n",
      "a : 2.0994560718536377, loss : 1.4373903274536133, a.grad: 4.795648574829102\n",
      "a : 2.051499605178833, loss : 1.2166072130203247, a.grad: 4.411996841430664\n",
      "a : 2.0073795318603516, loss : 1.0297359228134155, a.grad: 4.0590362548828125\n",
      "a : 1.9667891263961792, loss : 0.8715683817863464, a.grad: 3.7343130111694336\n",
      "a : 1.9294459819793701, loss : 0.7376953959465027, a.grad: 3.435567855834961\n",
      "a : 1.8950903415679932, loss : 0.6243855357170105, a.grad: 3.1607227325439453\n",
      "a : 1.8634830713272095, loss : 0.5284797549247742, a.grad: 2.907864570617676\n",
      "a : 1.834404468536377, loss : 0.4473053812980652, a.grad: 2.6752357482910156\n",
      "a : 1.8076521158218384, loss : 0.37859928607940674, a.grad: 2.461216926574707\n",
      "a : 1.783039927482605, loss : 0.3204464018344879, a.grad: 2.26431941986084\n",
      "a : 1.7603967189788818, loss : 0.27122581005096436, a.grad: 2.0831737518310547\n",
      "a : 1.7395650148391724, loss : 0.2295655906200409, a.grad: 1.916520118713379\n",
      "a : 1.7203998565673828, loss : 0.19430439174175262, a.grad: 1.7631988525390625\n",
      "a : 1.7027678489685059, loss : 0.1644591987133026, a.grad: 1.6221427917480469\n",
      "a : 1.6865464448928833, loss : 0.13919830322265625, a.grad: 1.4923715591430664\n",
      "a : 1.6716227531433105, loss : 0.1178174763917923, a.grad: 1.3729820251464844\n",
      "a : 1.6578929424285889, loss : 0.09972072392702103, a.grad: 1.263143539428711\n",
      "a : 1.645261526107788, loss : 0.0844036415219307, a.grad: 1.1620922088623047\n",
      "a : 1.6336406469345093, loss : 0.07143928855657578, a.grad: 1.0691251754760742\n",
      "a : 1.6229493618011475, loss : 0.060466181486845016, a.grad: 0.9835948944091797\n",
      "a : 1.6131134033203125, loss : 0.05117856711149216, a.grad: 0.9049072265625\n",
      "a : 1.6040643453598022, loss : 0.04331755265593529, a.grad: 0.832514762878418\n",
      "a : 1.5957392454147339, loss : 0.03666401281952858, a.grad: 0.7659139633178711\n",
      "a : 1.5880800485610962, loss : 0.03103237971663475, a.grad: 0.7046403884887695\n",
      "a : 1.5810335874557495, loss : 0.026265768334269524, a.grad: 0.6482686996459961\n",
      "a : 1.5745508670806885, loss : 0.02223132736980915, a.grad: 0.5964069366455078\n",
      "a : 1.568586826324463, loss : 0.018816610798239708, a.grad: 0.5486946105957031\n",
      "a : 1.5630998611450195, loss : 0.01592637039721012, a.grad: 0.5047988891601562\n",
      "a : 1.5580518245697021, loss : 0.013480057008564472, a.grad: 0.4644145965576172\n",
      "a : 1.5534076690673828, loss : 0.0114095164462924, a.grad: 0.4272613525390625\n",
      "a : 1.5491350889205933, loss : 0.009657028131186962, a.grad: 0.3930807113647461\n",
      "a : 1.5452042818069458, loss : 0.00817370880395174, a.grad: 0.3616342544555664\n",
      "a : 1.5415879487991333, loss : 0.006918230094015598, a.grad: 0.3327035903930664\n",
      "a : 1.5382609367370605, loss : 0.005855597089976072, a.grad: 0.3060874938964844\n",
      "a : 1.5352001190185547, loss : 0.00495619373396039, a.grad: 0.2816009521484375\n",
      "a : 1.5323841571807861, loss : 0.004194934386759996, a.grad: 0.25907325744628906\n",
      "a : 1.529793381690979, loss : 0.003550582332536578, a.grad: 0.23834705352783203\n",
      "a : 1.5274099111557007, loss : 0.0030052128713577986, a.grad: 0.21927928924560547\n",
      "a : 1.5252171754837036, loss : 0.0025436237920075655, a.grad: 0.2017374038696289\n",
      "a : 1.5231997966766357, loss : 0.0021529223304241896, a.grad: 0.18559837341308594\n",
      "a : 1.5213438272476196, loss : 0.0018222358776256442, a.grad: 0.17075061798095703\n",
      "a : 1.5196362733840942, loss : 0.0015423329314216971, a.grad: 0.1570901870727539\n",
      "a : 1.518065333366394, loss : 0.0013054250739514828, a.grad: 0.14452266693115234\n",
      "a : 1.51662015914917, loss : 0.0011049187742173672, a.grad: 0.13296127319335938\n",
      "a : 1.5152904987335205, loss : 0.0009351974003948271, a.grad: 0.12232398986816406\n",
      "a : 1.51406729221344, loss : 0.0007915548630990088, a.grad: 0.11253833770751953\n",
      "a : 1.5129419565200806, loss : 0.0006699769292026758, a.grad: 0.10353565216064453\n",
      "a : 1.511906623840332, loss : 0.000567070790566504, a.grad: 0.09525299072265625\n",
      "a : 1.5109541416168213, loss : 0.0004799728631041944, a.grad: 0.08763313293457031\n",
      "a : 1.5100778341293335, loss : 0.00040625096880830824, a.grad: 0.08062267303466797\n",
      "a : 1.5092716217041016, loss : 0.0003438518615439534, a.grad: 0.0741729736328125\n",
      "a : 1.5085299015045166, loss : 0.00029103687847964466, a.grad: 0.06823921203613281\n",
      "a : 1.507847547531128, loss : 0.0002463360142428428, a.grad: 0.06278038024902344\n",
      "a : 1.5072197914123535, loss : 0.0002085015585180372, a.grad: 0.057758331298828125\n",
      "a : 1.50664222240448, loss : 0.00017647647473495454, a.grad: 0.053137779235839844\n",
      "a : 1.5061107873916626, loss : 0.00014936689694877714, a.grad: 0.04888629913330078\n",
      "a : 1.5056219100952148, loss : 0.0001264234888367355, a.grad: 0.04497528076171875\n",
      "a : 1.5051721334457397, loss : 0.00010700385610107332, a.grad: 0.04137706756591797\n",
      "a : 1.504758358001709, loss : 9.056788258021697e-05, a.grad: 0.038066864013671875\n",
      "a : 1.5043777227401733, loss : 7.665782322874293e-05, a.grad: 0.03502178192138672\n",
      "a : 1.5040274858474731, loss : 6.488256622105837e-05, a.grad: 0.032219886779785156\n",
      "a : 1.5037052631378174, loss : 5.4915901273489e-05, a.grad: 0.029642105102539062\n",
      "a : 1.5034087896347046, loss : 4.647938840207644e-05, a.grad: 0.02727031707763672\n",
      "a : 1.5031360387802124, loss : 3.93389564123936e-05, a.grad: 0.02508831024169922\n",
      "a : 1.502885103225708, loss : 3.3295284083578736e-05, a.grad: 0.023080825805664062\n",
      "a : 1.5026543140411377, loss : 2.8181531888549216e-05, a.grad: 0.021234512329101562\n",
      "a : 1.5024420022964478, loss : 2.3853501261328347e-05, a.grad: 0.01953601837158203\n",
      "a : 1.502246618270874, loss : 2.0189174392726272e-05, a.grad: 0.017972946166992188\n",
      "a : 1.5020668506622314, loss : 1.708748641249258e-05, a.grad: 0.016534805297851562\n",
      "a : 1.5019015073776245, loss : 1.446292117179837e-05, a.grad: 0.015212059020996094\n",
      "a : 1.5017493963241577, loss : 1.224155039381003e-05, a.grad: 0.013995170593261719\n",
      "a : 1.501609444618225, loss : 1.0361248314438853e-05, a.grad: 0.012875556945800781\n",
      "a : 1.5014806985855103, loss : 8.769873602432199e-06, a.grad: 0.011845588684082031\n",
      "a : 1.5013622045516968, loss : 7.422404905810254e-06, a.grad: 0.010897636413574219\n",
      "a : 1.5012532472610474, loss : 6.282514732447453e-06, a.grad: 0.010025978088378906\n",
      "a : 1.5011529922485352, loss : 5.317564500728622e-06, a.grad: 0.00922393798828125\n",
      "a : 1.5010607242584229, loss : 4.500543582253158e-06, a.grad: 0.008485794067382812\n",
      "a : 1.5009758472442627, loss : 3.809111376540386e-06, a.grad: 0.0078067779541015625\n",
      "a : 1.500897765159607, loss : 3.223929070372833e-06, a.grad: 0.007182121276855469\n",
      "a : 1.5008260011672974, loss : 2.729111656663008e-06, a.grad: 0.006608009338378906\n",
      "a : 1.5007599592208862, loss : 2.310152012796607e-06, a.grad: 0.006079673767089844\n",
      "a : 1.5006991624832153, loss : 1.955312654899899e-06, a.grad: 0.005593299865722656\n",
      "a : 1.500643253326416, loss : 1.6550993677810766e-06, a.grad: 0.005146026611328125\n",
      "a : 1.50059175491333, loss : 1.400695509801153e-06, a.grad: 0.004734039306640625\n",
      "a : 1.5005444288253784, loss : 1.1856109267682768e-06, a.grad: 0.004355430603027344\n",
      "a : 1.5005009174346924, loss : 1.0036731055151904e-06, a.grad: 0.0040073394775390625\n",
      "a : 1.5004608631134033, loss : 8.495792371832067e-07, a.grad: 0.0036869049072265625\n",
      "a : 1.5004240274429321, loss : 7.191970894382393e-07, a.grad: 0.0033922195434570312\n",
      "a : 1.5003900527954102, loss : 6.085647328291088e-07, a.grad: 0.00312042236328125\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor(3, dtype=torch.float32, requires_grad=True)\n",
    "for idx in range(100):\n",
    "    loss = (a * x - y) ** 2\n",
    "    loss.backward()\n",
    "\n",
    "    print(f\"a : {a}, loss : {loss}, a.grad: {a.grad}\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        a -= 0.01 * a.grad\n",
    "        \n",
    "    a.grad.zero_()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
