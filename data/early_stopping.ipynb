{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNql7Ez4a9cp2pvULikqfd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/nn/early_stopping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FL3EbWiZIyL2",
        "outputId": "24f663ad-582a-4b42-ad59-f6bb601df3c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 96, done.\u001b[K\n",
            "remote: Counting objects: 100% (96/96), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 96 (delta 24), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (96/96), 3.66 MiB | 7.39 MiB/s, done.\n",
            "Resolving deltas: 100% (24/24), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load the DataFrame from a CSV file\n",
        "df = pd.read_csv('./deepLearning/nn/swirl.csv')\n",
        "data = df[['x', 'y']].values\n",
        "labels = df['label'].values.reshape(-1, 1)\n",
        "\n",
        "# Print the shapes of the data and labels\n",
        "print('Data shape:', data.shape)\n",
        "print('Labels shape:', labels.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrYCzwSyI4ed",
        "outputId": "df927f01-b611-41a2-8938-93ba314451f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape: (280, 2)\n",
            "Labels shape: (280, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "# Create a scatter plot\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap='viridis')\n",
        "# plt.scatter(val_data[:,0], val_data[:,1], c=val_labels, cmap='viridis')\n",
        "\n",
        "# Set the title and labels\n",
        "plt.title('2D Synthetic Data')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 718
        },
        "id": "CvushGgeI5Xb",
        "outputId": "578948c8-8fac-4e3f-eb3f-f849ea800ae3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# Convert the numpy arrays to PyTorch tensors\n",
        "data_torch = torch.tensor(data, dtype=torch.float32)\n",
        "labels_torch = torch.tensor(labels, dtype=torch.float32)\n",
        "data_length = len(data_torch)\n",
        "split_length = int(0.7*data_length)\n",
        "\n",
        "train_data = data_torch[:split_length]\n",
        "train_labels = labels_torch[:split_length]\n",
        "val_data = data_torch[split_length:]\n",
        "val_labels = labels_torch[split_length:]\n",
        "\n",
        "print(train_data.shape, train_labels.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DckZE_YpI6M-",
        "outputId": "09c95a46-ce81-4702-e2f4-8aac915ee392"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([196, 2]) torch.Size([196, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "g.manual_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class DNet(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
        "        super().__init__()\n",
        "        self.seq_model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.seq_model(x)\n",
        "\n",
        "\n",
        "dnet = DNet(input_size=2,hidden_size=16,output_size=1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(dnet.parameters(), lr=0.01)\n",
        "\n",
        "t_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for steps in range(50000):\n",
        "    dnet.train()\n",
        "\n",
        "    output = dnet(train_data)\n",
        "    train_loss = loss_fn(output, train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if steps % 10 == 0:\n",
        "        dnet.eval()\n",
        "        output = dnet(val_data)\n",
        "        val_loss = loss_fn(output, val_labels)\n",
        "        output = dnet(train_data)\n",
        "        t_loss = loss_fn(output,train_labels)\n",
        "        t_losses.append(t_loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "        print(f\"{steps} val_loss: {val_loss.item()}, train_loss: {t_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL3Iia8JI8x4",
        "outputId": "b2abdd0f-7eb4-43f9-d99b-9a8ff269521a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 val_loss: 0.6986285448074341, train_loss: 0.6956262588500977\n",
            "10 val_loss: 0.6983290910720825, train_loss: 0.6954140663146973\n",
            "20 val_loss: 0.6980547308921814, train_loss: 0.6952260136604309\n",
            "30 val_loss: 0.6977909207344055, train_loss: 0.6950458884239197\n",
            "40 val_loss: 0.6975520253181458, train_loss: 0.6948809027671814\n",
            "50 val_loss: 0.6973202228546143, train_loss: 0.6947291493415833\n",
            "60 val_loss: 0.697106659412384, train_loss: 0.6945889592170715\n",
            "70 val_loss: 0.6969023942947388, train_loss: 0.694453775882721\n",
            "80 val_loss: 0.6967265605926514, train_loss: 0.6943433284759521\n",
            "90 val_loss: 0.6965711712837219, train_loss: 0.6942458748817444\n",
            "100 val_loss: 0.6963969469070435, train_loss: 0.6941355466842651\n",
            "110 val_loss: 0.6962149143218994, train_loss: 0.6940233707427979\n",
            "120 val_loss: 0.6960594654083252, train_loss: 0.6939280033111572\n",
            "130 val_loss: 0.6959155201911926, train_loss: 0.6938427686691284\n",
            "140 val_loss: 0.6957721710205078, train_loss: 0.6937555074691772\n",
            "150 val_loss: 0.6956433057785034, train_loss: 0.6936823725700378\n",
            "160 val_loss: 0.6955013871192932, train_loss: 0.6936026811599731\n",
            "170 val_loss: 0.695388913154602, train_loss: 0.6935348510742188\n",
            "180 val_loss: 0.6952803134918213, train_loss: 0.693469226360321\n",
            "190 val_loss: 0.69517982006073, train_loss: 0.6934119462966919\n",
            "200 val_loss: 0.6950823664665222, train_loss: 0.6933532953262329\n",
            "210 val_loss: 0.6949751973152161, train_loss: 0.6932919025421143\n",
            "220 val_loss: 0.69487065076828, train_loss: 0.6932324767112732\n",
            "230 val_loss: 0.6947720646858215, train_loss: 0.6931775808334351\n",
            "240 val_loss: 0.6946943998336792, train_loss: 0.6931345462799072\n",
            "250 val_loss: 0.6946194767951965, train_loss: 0.6930895447731018\n",
            "260 val_loss: 0.6945284605026245, train_loss: 0.6930378675460815\n",
            "270 val_loss: 0.6944741606712341, train_loss: 0.6930104494094849\n",
            "280 val_loss: 0.6944040060043335, train_loss: 0.6929692029953003\n",
            "290 val_loss: 0.6943312883377075, train_loss: 0.6929247975349426\n",
            "300 val_loss: 0.6942589282989502, train_loss: 0.6928823590278625\n",
            "310 val_loss: 0.6941876411437988, train_loss: 0.6928337216377258\n",
            "320 val_loss: 0.6941276788711548, train_loss: 0.6927957534790039\n",
            "330 val_loss: 0.6940689086914062, train_loss: 0.6927617788314819\n",
            "340 val_loss: 0.6940001249313354, train_loss: 0.6927222609519958\n",
            "350 val_loss: 0.6939187049865723, train_loss: 0.6926761269569397\n",
            "360 val_loss: 0.6938657760620117, train_loss: 0.6926460266113281\n",
            "370 val_loss: 0.6938067674636841, train_loss: 0.6926131248474121\n",
            "380 val_loss: 0.6937628984451294, train_loss: 0.6925860047340393\n",
            "390 val_loss: 0.6937115788459778, train_loss: 0.6925578117370605\n",
            "400 val_loss: 0.6936749815940857, train_loss: 0.6925363540649414\n",
            "410 val_loss: 0.6936265826225281, train_loss: 0.6925041675567627\n",
            "420 val_loss: 0.6935722827911377, train_loss: 0.6924688220024109\n",
            "430 val_loss: 0.6935286521911621, train_loss: 0.6924422979354858\n",
            "440 val_loss: 0.6934770941734314, train_loss: 0.6924112439155579\n",
            "450 val_loss: 0.693449854850769, train_loss: 0.6923899054527283\n",
            "460 val_loss: 0.6934068202972412, train_loss: 0.6923577189445496\n",
            "470 val_loss: 0.6933644413948059, train_loss: 0.6923279762268066\n",
            "480 val_loss: 0.6933189630508423, train_loss: 0.6922937631607056\n",
            "490 val_loss: 0.6932847499847412, train_loss: 0.692267119884491\n",
            "500 val_loss: 0.6932587623596191, train_loss: 0.6922488212585449\n",
            "510 val_loss: 0.6932300329208374, train_loss: 0.6922233700752258\n",
            "520 val_loss: 0.6932108998298645, train_loss: 0.6922035813331604\n",
            "530 val_loss: 0.6931703686714172, train_loss: 0.6921713948249817\n",
            "540 val_loss: 0.6931414604187012, train_loss: 0.6921424865722656\n",
            "550 val_loss: 0.6931197047233582, train_loss: 0.6921223998069763\n",
            "560 val_loss: 0.6931114196777344, train_loss: 0.6921142339706421\n",
            "570 val_loss: 0.6930915117263794, train_loss: 0.692094624042511\n",
            "580 val_loss: 0.6930646300315857, train_loss: 0.6920781135559082\n",
            "590 val_loss: 0.6930290460586548, train_loss: 0.6920514106750488\n",
            "600 val_loss: 0.6930047273635864, train_loss: 0.6920269727706909\n",
            "610 val_loss: 0.6929905414581299, train_loss: 0.692016065120697\n",
            "620 val_loss: 0.692968487739563, train_loss: 0.6920006275177002\n",
            "630 val_loss: 0.6929546594619751, train_loss: 0.6919843554496765\n",
            "640 val_loss: 0.6929338574409485, train_loss: 0.69196617603302\n",
            "650 val_loss: 0.6929119229316711, train_loss: 0.6919479370117188\n",
            "660 val_loss: 0.6928809285163879, train_loss: 0.6919263005256653\n",
            "670 val_loss: 0.6928688883781433, train_loss: 0.6919143199920654\n",
            "680 val_loss: 0.6928431391716003, train_loss: 0.6918858885765076\n",
            "690 val_loss: 0.6928245425224304, train_loss: 0.6918659806251526\n",
            "700 val_loss: 0.6927960515022278, train_loss: 0.6918368339538574\n",
            "710 val_loss: 0.692772388458252, train_loss: 0.6918141841888428\n",
            "720 val_loss: 0.692754864692688, train_loss: 0.6917931437492371\n",
            "730 val_loss: 0.6927343010902405, train_loss: 0.6917738914489746\n",
            "740 val_loss: 0.6927043199539185, train_loss: 0.6917462944984436\n",
            "750 val_loss: 0.6926810145378113, train_loss: 0.691724419593811\n",
            "760 val_loss: 0.6926583051681519, train_loss: 0.6917038559913635\n",
            "770 val_loss: 0.6926455497741699, train_loss: 0.6916879415512085\n",
            "780 val_loss: 0.6926204562187195, train_loss: 0.691663384437561\n",
            "790 val_loss: 0.6925875544548035, train_loss: 0.6916377544403076\n",
            "800 val_loss: 0.6925516724586487, train_loss: 0.6916096806526184\n",
            "810 val_loss: 0.6925328373908997, train_loss: 0.6915898323059082\n",
            "820 val_loss: 0.6925240755081177, train_loss: 0.6915761232376099\n",
            "830 val_loss: 0.6925129890441895, train_loss: 0.691560685634613\n",
            "840 val_loss: 0.6924923658370972, train_loss: 0.6915425062179565\n",
            "850 val_loss: 0.6924713253974915, train_loss: 0.6915239095687866\n",
            "860 val_loss: 0.6924647092819214, train_loss: 0.6915143728256226\n",
            "870 val_loss: 0.6924501061439514, train_loss: 0.691502571105957\n",
            "880 val_loss: 0.6924378275871277, train_loss: 0.6914892196655273\n",
            "890 val_loss: 0.6924242973327637, train_loss: 0.691473662853241\n",
            "900 val_loss: 0.6924055218696594, train_loss: 0.6914568543434143\n",
            "910 val_loss: 0.6923907399177551, train_loss: 0.6914370656013489\n",
            "920 val_loss: 0.6923718452453613, train_loss: 0.6914179921150208\n",
            "930 val_loss: 0.6923605799674988, train_loss: 0.6914018988609314\n",
            "940 val_loss: 0.6923428177833557, train_loss: 0.6913840770721436\n",
            "950 val_loss: 0.69233638048172, train_loss: 0.6913688778877258\n",
            "960 val_loss: 0.6923170685768127, train_loss: 0.6913579702377319\n",
            "970 val_loss: 0.6923031806945801, train_loss: 0.691340446472168\n",
            "980 val_loss: 0.6922918558120728, train_loss: 0.6913243532180786\n",
            "990 val_loss: 0.6922798752784729, train_loss: 0.6913047432899475\n",
            "1000 val_loss: 0.6922621726989746, train_loss: 0.6912891864776611\n",
            "1010 val_loss: 0.6922515630722046, train_loss: 0.6912767887115479\n",
            "1020 val_loss: 0.692236602306366, train_loss: 0.6912553906440735\n",
            "1030 val_loss: 0.6922106742858887, train_loss: 0.6912365555763245\n",
            "1040 val_loss: 0.692196786403656, train_loss: 0.691223680973053\n",
            "1050 val_loss: 0.6921780109405518, train_loss: 0.691209077835083\n",
            "1060 val_loss: 0.6921636462211609, train_loss: 0.6911951899528503\n",
            "1070 val_loss: 0.6921475529670715, train_loss: 0.6911788582801819\n",
            "1080 val_loss: 0.692138135433197, train_loss: 0.6911671161651611\n",
            "1090 val_loss: 0.692126989364624, train_loss: 0.6911517381668091\n",
            "1100 val_loss: 0.6921061277389526, train_loss: 0.6911298632621765\n",
            "1110 val_loss: 0.6920973658561707, train_loss: 0.6911160349845886\n",
            "1120 val_loss: 0.6920884251594543, train_loss: 0.6910985708236694\n",
            "1130 val_loss: 0.6920693516731262, train_loss: 0.6910814046859741\n",
            "1140 val_loss: 0.6920628547668457, train_loss: 0.691070556640625\n",
            "1150 val_loss: 0.6920500993728638, train_loss: 0.6910476088523865\n",
            "1160 val_loss: 0.692035973072052, train_loss: 0.6910330057144165\n",
            "1170 val_loss: 0.6920252442359924, train_loss: 0.6910179853439331\n",
            "1180 val_loss: 0.692014217376709, train_loss: 0.6909952759742737\n",
            "1190 val_loss: 0.6920028328895569, train_loss: 0.690974235534668\n",
            "1200 val_loss: 0.691985011100769, train_loss: 0.6909500956535339\n",
            "1210 val_loss: 0.6919748187065125, train_loss: 0.6909341812133789\n",
            "1220 val_loss: 0.6919649243354797, train_loss: 0.6909209489822388\n",
            "1230 val_loss: 0.6919493079185486, train_loss: 0.690900981426239\n",
            "1240 val_loss: 0.6919365525245667, train_loss: 0.6908848881721497\n",
            "1250 val_loss: 0.6919170618057251, train_loss: 0.6908597946166992\n",
            "1260 val_loss: 0.6919034123420715, train_loss: 0.6908416152000427\n",
            "1270 val_loss: 0.6918920874595642, train_loss: 0.6908226609230042\n",
            "1280 val_loss: 0.6918691396713257, train_loss: 0.6907974481582642\n",
            "1290 val_loss: 0.691851019859314, train_loss: 0.6907755136489868\n",
            "1300 val_loss: 0.6918357610702515, train_loss: 0.6907569169998169\n",
            "1310 val_loss: 0.6918166875839233, train_loss: 0.6907298564910889\n",
            "1320 val_loss: 0.6917960047721863, train_loss: 0.6907076835632324\n",
            "1330 val_loss: 0.6917681694030762, train_loss: 0.6906811594963074\n",
            "1340 val_loss: 0.6917561888694763, train_loss: 0.6906625628471375\n",
            "1350 val_loss: 0.6917446851730347, train_loss: 0.6906423568725586\n",
            "1360 val_loss: 0.6917272210121155, train_loss: 0.6906164288520813\n",
            "1370 val_loss: 0.6917071342468262, train_loss: 0.6905851364135742\n",
            "1380 val_loss: 0.6916916966438293, train_loss: 0.6905617117881775\n",
            "1390 val_loss: 0.6916722655296326, train_loss: 0.6905422806739807\n",
            "1400 val_loss: 0.6916539669036865, train_loss: 0.6905158758163452\n",
            "1410 val_loss: 0.6916287541389465, train_loss: 0.6904816627502441\n",
            "1420 val_loss: 0.6916197538375854, train_loss: 0.6904690861701965\n",
            "1430 val_loss: 0.6916008591651917, train_loss: 0.6904368996620178\n",
            "1440 val_loss: 0.6915706396102905, train_loss: 0.690406084060669\n",
            "1450 val_loss: 0.6915440559387207, train_loss: 0.6903727650642395\n",
            "1460 val_loss: 0.6915192604064941, train_loss: 0.6903389692306519\n",
            "1470 val_loss: 0.6915009617805481, train_loss: 0.6903132200241089\n",
            "1480 val_loss: 0.6914942860603333, train_loss: 0.6902941465377808\n",
            "1490 val_loss: 0.6914767026901245, train_loss: 0.690266489982605\n",
            "1500 val_loss: 0.6914582252502441, train_loss: 0.6902463436126709\n",
            "1510 val_loss: 0.6914315819740295, train_loss: 0.6902155876159668\n",
            "1520 val_loss: 0.6914120316505432, train_loss: 0.6901884078979492\n",
            "1530 val_loss: 0.6913885474205017, train_loss: 0.6901596188545227\n",
            "1540 val_loss: 0.6913641095161438, train_loss: 0.6901273727416992\n",
            "1550 val_loss: 0.6913371682167053, train_loss: 0.6900994181632996\n",
            "1560 val_loss: 0.691315233707428, train_loss: 0.6900695562362671\n",
            "1570 val_loss: 0.691291332244873, train_loss: 0.6900436878204346\n",
            "1580 val_loss: 0.6912596821784973, train_loss: 0.6900078654289246\n",
            "1590 val_loss: 0.691237211227417, train_loss: 0.6899755597114563\n",
            "1600 val_loss: 0.6912055015563965, train_loss: 0.6899443864822388\n",
            "1610 val_loss: 0.6911784410476685, train_loss: 0.6899073719978333\n",
            "1620 val_loss: 0.6911572217941284, train_loss: 0.6898866891860962\n",
            "1630 val_loss: 0.6911341547966003, train_loss: 0.6898476481437683\n",
            "1640 val_loss: 0.6911120414733887, train_loss: 0.6898120045661926\n",
            "1650 val_loss: 0.6910912394523621, train_loss: 0.6897833943367004\n",
            "1660 val_loss: 0.691057562828064, train_loss: 0.6897420287132263\n",
            "1670 val_loss: 0.6910297870635986, train_loss: 0.6897000670433044\n",
            "1680 val_loss: 0.6909996867179871, train_loss: 0.6896557807922363\n",
            "1690 val_loss: 0.6909661293029785, train_loss: 0.6896102428436279\n",
            "1700 val_loss: 0.6909412145614624, train_loss: 0.6895844340324402\n",
            "1710 val_loss: 0.6909106373786926, train_loss: 0.6895481944084167\n",
            "1720 val_loss: 0.6908907294273376, train_loss: 0.6895187497138977\n",
            "1730 val_loss: 0.6908695697784424, train_loss: 0.6894800662994385\n",
            "1740 val_loss: 0.6908442378044128, train_loss: 0.6894469857215881\n",
            "1750 val_loss: 0.6908164024353027, train_loss: 0.6894097328186035\n",
            "1760 val_loss: 0.6907896995544434, train_loss: 0.6893748641014099\n",
            "1770 val_loss: 0.6907707452774048, train_loss: 0.6893438100814819\n",
            "1780 val_loss: 0.6907382011413574, train_loss: 0.6893020272254944\n",
            "1790 val_loss: 0.6907153129577637, train_loss: 0.6892654895782471\n",
            "1800 val_loss: 0.6906826496124268, train_loss: 0.6892293691635132\n",
            "1810 val_loss: 0.6906470060348511, train_loss: 0.6891822814941406\n",
            "1820 val_loss: 0.6906132698059082, train_loss: 0.6891390681266785\n",
            "1830 val_loss: 0.6905993223190308, train_loss: 0.6891099810600281\n",
            "1840 val_loss: 0.6905620694160461, train_loss: 0.6890645027160645\n",
            "1850 val_loss: 0.690530002117157, train_loss: 0.6890336871147156\n",
            "1860 val_loss: 0.6904925107955933, train_loss: 0.688995361328125\n",
            "1870 val_loss: 0.6904618740081787, train_loss: 0.6889564990997314\n",
            "1880 val_loss: 0.690432608127594, train_loss: 0.6889203786849976\n",
            "1890 val_loss: 0.6904022097587585, train_loss: 0.6888826489448547\n",
            "1900 val_loss: 0.6903749704360962, train_loss: 0.6888465285301208\n",
            "1910 val_loss: 0.6903314590454102, train_loss: 0.6887904405593872\n",
            "1920 val_loss: 0.6902897953987122, train_loss: 0.6887481212615967\n",
            "1930 val_loss: 0.6902663111686707, train_loss: 0.6887120008468628\n",
            "1940 val_loss: 0.6902338862419128, train_loss: 0.6886650323867798\n",
            "1950 val_loss: 0.6902016997337341, train_loss: 0.688618540763855\n",
            "1960 val_loss: 0.6901675462722778, train_loss: 0.6885796189308167\n",
            "1970 val_loss: 0.6901300549507141, train_loss: 0.6885260939598083\n",
            "1980 val_loss: 0.6900779008865356, train_loss: 0.6884570121765137\n",
            "1990 val_loss: 0.6900317072868347, train_loss: 0.6883980631828308\n",
            "2000 val_loss: 0.6899824142456055, train_loss: 0.6883436441421509\n",
            "2010 val_loss: 0.6899378895759583, train_loss: 0.6882898807525635\n",
            "2020 val_loss: 0.6898915767669678, train_loss: 0.6882399916648865\n",
            "2030 val_loss: 0.6898589134216309, train_loss: 0.6882005929946899\n",
            "2040 val_loss: 0.689827024936676, train_loss: 0.688157320022583\n",
            "2050 val_loss: 0.6897832751274109, train_loss: 0.6881065368652344\n",
            "2060 val_loss: 0.6897432804107666, train_loss: 0.6880567669868469\n",
            "2070 val_loss: 0.6897016167640686, train_loss: 0.6880044937133789\n",
            "2080 val_loss: 0.6896569728851318, train_loss: 0.6879496574401855\n",
            "2090 val_loss: 0.6896093487739563, train_loss: 0.687892735004425\n",
            "2100 val_loss: 0.689567506313324, train_loss: 0.6878301501274109\n",
            "2110 val_loss: 0.689513087272644, train_loss: 0.6877636909484863\n",
            "2120 val_loss: 0.6894795298576355, train_loss: 0.6877114176750183\n",
            "2130 val_loss: 0.6894404888153076, train_loss: 0.6876633167266846\n",
            "2140 val_loss: 0.6894068717956543, train_loss: 0.6876072883605957\n",
            "2150 val_loss: 0.6893587708473206, train_loss: 0.6875470280647278\n",
            "2160 val_loss: 0.6893230676651001, train_loss: 0.6874876022338867\n",
            "2170 val_loss: 0.689283549785614, train_loss: 0.6874299049377441\n",
            "2180 val_loss: 0.6892324090003967, train_loss: 0.6873713731765747\n",
            "2190 val_loss: 0.6891814470291138, train_loss: 0.6873156428337097\n",
            "2200 val_loss: 0.6891320943832397, train_loss: 0.6872421503067017\n",
            "2210 val_loss: 0.6890916228294373, train_loss: 0.6871821284294128\n",
            "2220 val_loss: 0.6890391111373901, train_loss: 0.6871195435523987\n",
            "2230 val_loss: 0.6889798045158386, train_loss: 0.6870407462120056\n",
            "2240 val_loss: 0.6889335513114929, train_loss: 0.6869825124740601\n",
            "2250 val_loss: 0.6888781189918518, train_loss: 0.6869052052497864\n",
            "2260 val_loss: 0.6888406872749329, train_loss: 0.6868475079536438\n",
            "2270 val_loss: 0.6887839436531067, train_loss: 0.6867831349372864\n",
            "2280 val_loss: 0.6887232661247253, train_loss: 0.6867133378982544\n",
            "2290 val_loss: 0.6886705756187439, train_loss: 0.6866413950920105\n",
            "2300 val_loss: 0.6886164546012878, train_loss: 0.6865735650062561\n",
            "2310 val_loss: 0.6885595321655273, train_loss: 0.6865034103393555\n",
            "2320 val_loss: 0.6885008811950684, train_loss: 0.6864328980445862\n",
            "2330 val_loss: 0.6884319186210632, train_loss: 0.6863550543785095\n",
            "2340 val_loss: 0.6883702874183655, train_loss: 0.6862836480140686\n",
            "2350 val_loss: 0.6883163452148438, train_loss: 0.6862116456031799\n",
            "2360 val_loss: 0.6882431507110596, train_loss: 0.6861280202865601\n",
            "2370 val_loss: 0.6881850957870483, train_loss: 0.6860668659210205\n",
            "2380 val_loss: 0.6881208419799805, train_loss: 0.6859868764877319\n",
            "2390 val_loss: 0.688056230545044, train_loss: 0.6859013438224792\n",
            "2400 val_loss: 0.6879954934120178, train_loss: 0.6858255863189697\n",
            "2410 val_loss: 0.6879355311393738, train_loss: 0.6857544183731079\n",
            "2420 val_loss: 0.6878758668899536, train_loss: 0.6856762766838074\n",
            "2430 val_loss: 0.6878027319908142, train_loss: 0.6855952143669128\n",
            "2440 val_loss: 0.6877303719520569, train_loss: 0.6855109333992004\n",
            "2450 val_loss: 0.6876537203788757, train_loss: 0.6854230165481567\n",
            "2460 val_loss: 0.6875802278518677, train_loss: 0.6853382587432861\n",
            "2470 val_loss: 0.687519907951355, train_loss: 0.6852595210075378\n",
            "2480 val_loss: 0.6874342560768127, train_loss: 0.6851677298545837\n",
            "2490 val_loss: 0.6873689889907837, train_loss: 0.685089111328125\n",
            "2500 val_loss: 0.6872941255569458, train_loss: 0.6849958300590515\n",
            "2510 val_loss: 0.687226414680481, train_loss: 0.6849291920661926\n",
            "2520 val_loss: 0.687158465385437, train_loss: 0.6848506331443787\n",
            "2530 val_loss: 0.6870914697647095, train_loss: 0.684775710105896\n",
            "2540 val_loss: 0.68702232837677, train_loss: 0.6846987009048462\n",
            "2550 val_loss: 0.6869368553161621, train_loss: 0.6846069097518921\n",
            "2560 val_loss: 0.6868725419044495, train_loss: 0.6845331192016602\n",
            "2570 val_loss: 0.6867983937263489, train_loss: 0.6844323873519897\n",
            "2580 val_loss: 0.6867097616195679, train_loss: 0.6843317151069641\n",
            "2590 val_loss: 0.6866271495819092, train_loss: 0.6842278242111206\n",
            "2600 val_loss: 0.6865618228912354, train_loss: 0.6841474175453186\n",
            "2610 val_loss: 0.6864835619926453, train_loss: 0.6840459108352661\n",
            "2620 val_loss: 0.686405599117279, train_loss: 0.6839486956596375\n",
            "2630 val_loss: 0.6863144040107727, train_loss: 0.6838546395301819\n",
            "2640 val_loss: 0.6862189769744873, train_loss: 0.6837379932403564\n",
            "2650 val_loss: 0.6861370205879211, train_loss: 0.6836290955543518\n",
            "2660 val_loss: 0.6860566735267639, train_loss: 0.683519721031189\n",
            "2670 val_loss: 0.6859830021858215, train_loss: 0.6834197044372559\n",
            "2680 val_loss: 0.685883104801178, train_loss: 0.6832966804504395\n",
            "2690 val_loss: 0.6857705116271973, train_loss: 0.6831598281860352\n",
            "2700 val_loss: 0.6856814622879028, train_loss: 0.6830533742904663\n",
            "2710 val_loss: 0.6855835914611816, train_loss: 0.6829412579536438\n",
            "2720 val_loss: 0.6854984760284424, train_loss: 0.682830274105072\n",
            "2730 val_loss: 0.6854039430618286, train_loss: 0.6827121376991272\n",
            "2740 val_loss: 0.6853195428848267, train_loss: 0.6826143264770508\n",
            "2750 val_loss: 0.6852256059646606, train_loss: 0.6825017929077148\n",
            "2760 val_loss: 0.6851385831832886, train_loss: 0.6823908090591431\n",
            "2770 val_loss: 0.6850272417068481, train_loss: 0.6822555065155029\n",
            "2780 val_loss: 0.6849246621131897, train_loss: 0.6821354627609253\n",
            "2790 val_loss: 0.6848269701004028, train_loss: 0.6820258498191833\n",
            "2800 val_loss: 0.6847351789474487, train_loss: 0.6819305419921875\n",
            "2810 val_loss: 0.6846374869346619, train_loss: 0.6818094849586487\n",
            "2820 val_loss: 0.6845418214797974, train_loss: 0.6816882491111755\n",
            "2830 val_loss: 0.6844454407691956, train_loss: 0.6815800070762634\n",
            "2840 val_loss: 0.6843363046646118, train_loss: 0.6814542412757874\n",
            "2850 val_loss: 0.684222400188446, train_loss: 0.6813235282897949\n",
            "2860 val_loss: 0.6841199994087219, train_loss: 0.6811996102333069\n",
            "2870 val_loss: 0.6840071678161621, train_loss: 0.6810632944107056\n",
            "2880 val_loss: 0.6838974356651306, train_loss: 0.6809218525886536\n",
            "2890 val_loss: 0.6837819218635559, train_loss: 0.6807770729064941\n",
            "2900 val_loss: 0.683653712272644, train_loss: 0.6806368231773376\n",
            "2910 val_loss: 0.6835419535636902, train_loss: 0.6805069446563721\n",
            "2920 val_loss: 0.6833987236022949, train_loss: 0.6803532838821411\n",
            "2930 val_loss: 0.6832836866378784, train_loss: 0.6802029013633728\n",
            "2940 val_loss: 0.6831606030464172, train_loss: 0.6800618767738342\n",
            "2950 val_loss: 0.6830234527587891, train_loss: 0.6799282431602478\n",
            "2960 val_loss: 0.6828960180282593, train_loss: 0.6797894835472107\n",
            "2970 val_loss: 0.6827737092971802, train_loss: 0.6796431541442871\n",
            "2980 val_loss: 0.682640016078949, train_loss: 0.679484486579895\n",
            "2990 val_loss: 0.6824880838394165, train_loss: 0.6793243885040283\n",
            "3000 val_loss: 0.6823662519454956, train_loss: 0.6791813969612122\n",
            "3010 val_loss: 0.6822304725646973, train_loss: 0.6790086627006531\n",
            "3020 val_loss: 0.6820862293243408, train_loss: 0.6788432002067566\n",
            "3030 val_loss: 0.6819292902946472, train_loss: 0.6786704659461975\n",
            "3040 val_loss: 0.6817913055419922, train_loss: 0.6785138249397278\n",
            "3050 val_loss: 0.6816429495811462, train_loss: 0.6783322095870972\n",
            "3060 val_loss: 0.6814658045768738, train_loss: 0.6781457662582397\n",
            "3070 val_loss: 0.6813236474990845, train_loss: 0.6779929399490356\n",
            "3080 val_loss: 0.6811804175376892, train_loss: 0.6778222918510437\n",
            "3090 val_loss: 0.6810172200202942, train_loss: 0.6776348948478699\n",
            "3100 val_loss: 0.6808947920799255, train_loss: 0.677484393119812\n",
            "3110 val_loss: 0.6807200312614441, train_loss: 0.6772989630699158\n",
            "3120 val_loss: 0.6805298328399658, train_loss: 0.6770989298820496\n",
            "3130 val_loss: 0.6803514361381531, train_loss: 0.6769154667854309\n",
            "3140 val_loss: 0.6801959276199341, train_loss: 0.67673259973526\n",
            "3150 val_loss: 0.6800389289855957, train_loss: 0.6765666604042053\n",
            "3160 val_loss: 0.6798660159111023, train_loss: 0.6763773560523987\n",
            "3170 val_loss: 0.6797049641609192, train_loss: 0.6761947870254517\n",
            "3180 val_loss: 0.6795210242271423, train_loss: 0.6759945750236511\n",
            "3190 val_loss: 0.6793420910835266, train_loss: 0.6758155226707458\n",
            "3200 val_loss: 0.6791672110557556, train_loss: 0.6756299138069153\n",
            "3210 val_loss: 0.6789681315422058, train_loss: 0.6754162907600403\n",
            "3220 val_loss: 0.6787990927696228, train_loss: 0.6752163767814636\n",
            "3230 val_loss: 0.6786091923713684, train_loss: 0.6750059127807617\n",
            "3240 val_loss: 0.6784051060676575, train_loss: 0.6747629642486572\n",
            "3250 val_loss: 0.6782059669494629, train_loss: 0.6745402812957764\n",
            "3260 val_loss: 0.6780091524124146, train_loss: 0.6743173599243164\n",
            "3270 val_loss: 0.6778048276901245, train_loss: 0.6740887761116028\n",
            "3280 val_loss: 0.6775985360145569, train_loss: 0.6738563776016235\n",
            "3290 val_loss: 0.677370548248291, train_loss: 0.6736042499542236\n",
            "3300 val_loss: 0.6771513819694519, train_loss: 0.6733641624450684\n",
            "3310 val_loss: 0.6769598126411438, train_loss: 0.6731466054916382\n",
            "3320 val_loss: 0.6767438650131226, train_loss: 0.6729238033294678\n",
            "3330 val_loss: 0.6765367984771729, train_loss: 0.6726910471916199\n",
            "3340 val_loss: 0.67634117603302, train_loss: 0.6724687814712524\n",
            "3350 val_loss: 0.6761616468429565, train_loss: 0.6722701787948608\n",
            "3360 val_loss: 0.6759305000305176, train_loss: 0.6720494627952576\n",
            "3370 val_loss: 0.6756700277328491, train_loss: 0.6717819571495056\n",
            "3380 val_loss: 0.6754423379898071, train_loss: 0.6715240478515625\n",
            "3390 val_loss: 0.6752182841300964, train_loss: 0.6712833046913147\n",
            "3400 val_loss: 0.6749598383903503, train_loss: 0.6710297465324402\n",
            "3410 val_loss: 0.674732506275177, train_loss: 0.6707600355148315\n",
            "3420 val_loss: 0.6745103001594543, train_loss: 0.6705187559127808\n",
            "3430 val_loss: 0.6742371320724487, train_loss: 0.6702239513397217\n",
            "3440 val_loss: 0.6740096211433411, train_loss: 0.6699671745300293\n",
            "3450 val_loss: 0.6737779974937439, train_loss: 0.669712245464325\n",
            "3460 val_loss: 0.6735438704490662, train_loss: 0.6694560647010803\n",
            "3470 val_loss: 0.6733148694038391, train_loss: 0.6691948175430298\n",
            "3480 val_loss: 0.6730847358703613, train_loss: 0.668945848941803\n",
            "3490 val_loss: 0.6728745102882385, train_loss: 0.66872638463974\n",
            "3500 val_loss: 0.6726148724555969, train_loss: 0.6684350967407227\n",
            "3510 val_loss: 0.6723187565803528, train_loss: 0.6681380867958069\n",
            "3520 val_loss: 0.672082245349884, train_loss: 0.6678590774536133\n",
            "3530 val_loss: 0.6718408465385437, train_loss: 0.6675933003425598\n",
            "3540 val_loss: 0.6716315150260925, train_loss: 0.6673498153686523\n",
            "3550 val_loss: 0.6713353395462036, train_loss: 0.6670272350311279\n",
            "3560 val_loss: 0.6711193919181824, train_loss: 0.6667762994766235\n",
            "3570 val_loss: 0.6708605885505676, train_loss: 0.6664891242980957\n",
            "3580 val_loss: 0.6705051064491272, train_loss: 0.6661244630813599\n",
            "3590 val_loss: 0.6702367663383484, train_loss: 0.6658332347869873\n",
            "3600 val_loss: 0.6699241995811462, train_loss: 0.6655216813087463\n",
            "3610 val_loss: 0.6696974635124207, train_loss: 0.6652671694755554\n",
            "3620 val_loss: 0.6693475246429443, train_loss: 0.6649012565612793\n",
            "3630 val_loss: 0.6690070033073425, train_loss: 0.6645385026931763\n",
            "3640 val_loss: 0.6686999201774597, train_loss: 0.6642091870307922\n",
            "3650 val_loss: 0.6683882474899292, train_loss: 0.6638575196266174\n",
            "3660 val_loss: 0.6680511832237244, train_loss: 0.663500189781189\n",
            "3670 val_loss: 0.6677173376083374, train_loss: 0.6631689071655273\n",
            "3680 val_loss: 0.6674045920372009, train_loss: 0.6628385186195374\n",
            "3690 val_loss: 0.6671286821365356, train_loss: 0.6625332832336426\n",
            "3700 val_loss: 0.6668460965156555, train_loss: 0.6622248888015747\n",
            "3710 val_loss: 0.6665595173835754, train_loss: 0.6619129776954651\n",
            "3720 val_loss: 0.6662734746932983, train_loss: 0.6616213917732239\n",
            "3730 val_loss: 0.6660227179527283, train_loss: 0.6613438129425049\n",
            "3740 val_loss: 0.6657189726829529, train_loss: 0.6610310077667236\n",
            "3750 val_loss: 0.665397047996521, train_loss: 0.6607089638710022\n",
            "3760 val_loss: 0.6651260852813721, train_loss: 0.6603991389274597\n",
            "3770 val_loss: 0.6648449897766113, train_loss: 0.660094141960144\n",
            "3780 val_loss: 0.6645330190658569, train_loss: 0.6597374677658081\n",
            "3790 val_loss: 0.6642142534255981, train_loss: 0.6594051718711853\n",
            "3800 val_loss: 0.6638689637184143, train_loss: 0.6590710282325745\n",
            "3810 val_loss: 0.6635787487030029, train_loss: 0.6587463617324829\n",
            "3820 val_loss: 0.6632794737815857, train_loss: 0.6584064960479736\n",
            "3830 val_loss: 0.6629632115364075, train_loss: 0.6580655574798584\n",
            "3840 val_loss: 0.6626483201980591, train_loss: 0.6577509641647339\n",
            "3850 val_loss: 0.6623532176017761, train_loss: 0.6573905944824219\n",
            "3860 val_loss: 0.6620136499404907, train_loss: 0.6570733785629272\n",
            "3870 val_loss: 0.6616677045822144, train_loss: 0.6567165851593018\n",
            "3880 val_loss: 0.6612891554832458, train_loss: 0.6563717722892761\n",
            "3890 val_loss: 0.6608981490135193, train_loss: 0.6559934020042419\n",
            "3900 val_loss: 0.6605575680732727, train_loss: 0.6556689739227295\n",
            "3910 val_loss: 0.6601866483688354, train_loss: 0.6552987098693848\n",
            "3920 val_loss: 0.6599080562591553, train_loss: 0.6549692153930664\n",
            "3930 val_loss: 0.6595736742019653, train_loss: 0.6546079516410828\n",
            "3940 val_loss: 0.6592251658439636, train_loss: 0.6542574167251587\n",
            "3950 val_loss: 0.6588683128356934, train_loss: 0.6539111733436584\n",
            "3960 val_loss: 0.6584904193878174, train_loss: 0.6535238027572632\n",
            "3970 val_loss: 0.6581861972808838, train_loss: 0.6531916260719299\n",
            "3980 val_loss: 0.657816469669342, train_loss: 0.6527954339981079\n",
            "3990 val_loss: 0.6575042009353638, train_loss: 0.6524840593338013\n",
            "4000 val_loss: 0.6571910381317139, train_loss: 0.6521286964416504\n",
            "4010 val_loss: 0.6568347811698914, train_loss: 0.651756763458252\n",
            "4020 val_loss: 0.6564471125602722, train_loss: 0.6513856053352356\n",
            "4030 val_loss: 0.656082034111023, train_loss: 0.6509652733802795\n",
            "4040 val_loss: 0.6557002663612366, train_loss: 0.6505700945854187\n",
            "4050 val_loss: 0.6553157567977905, train_loss: 0.6502004265785217\n",
            "4060 val_loss: 0.6549817323684692, train_loss: 0.6498505473136902\n",
            "4070 val_loss: 0.6546216011047363, train_loss: 0.6495020389556885\n",
            "4080 val_loss: 0.65430748462677, train_loss: 0.6491590738296509\n",
            "4090 val_loss: 0.6539565324783325, train_loss: 0.6487902998924255\n",
            "4100 val_loss: 0.6536321640014648, train_loss: 0.648422122001648\n",
            "4110 val_loss: 0.6532770991325378, train_loss: 0.6480724811553955\n",
            "4120 val_loss: 0.6528486609458923, train_loss: 0.647644579410553\n",
            "4130 val_loss: 0.6524118781089783, train_loss: 0.6472321152687073\n",
            "4140 val_loss: 0.6520432233810425, train_loss: 0.6468913555145264\n",
            "4150 val_loss: 0.6516246795654297, train_loss: 0.646448016166687\n",
            "4160 val_loss: 0.6512885689735413, train_loss: 0.6460820436477661\n",
            "4170 val_loss: 0.6509448289871216, train_loss: 0.645698070526123\n",
            "4180 val_loss: 0.6505653858184814, train_loss: 0.6453559398651123\n",
            "4190 val_loss: 0.6501297354698181, train_loss: 0.6449762582778931\n",
            "4200 val_loss: 0.6497454643249512, train_loss: 0.6445679664611816\n",
            "4210 val_loss: 0.6494072675704956, train_loss: 0.6442197561264038\n",
            "4220 val_loss: 0.6489575505256653, train_loss: 0.6437872052192688\n",
            "4230 val_loss: 0.6485190391540527, train_loss: 0.6433480978012085\n",
            "4240 val_loss: 0.6481133699417114, train_loss: 0.6429749131202698\n",
            "4250 val_loss: 0.6476853489875793, train_loss: 0.6425794363021851\n",
            "4260 val_loss: 0.6473187804222107, train_loss: 0.6422047019004822\n",
            "4270 val_loss: 0.6468843817710876, train_loss: 0.6418064832687378\n",
            "4280 val_loss: 0.6465621590614319, train_loss: 0.6414649486541748\n",
            "4290 val_loss: 0.6461247205734253, train_loss: 0.6410544514656067\n",
            "4300 val_loss: 0.6457533836364746, train_loss: 0.6406338214874268\n",
            "4310 val_loss: 0.6453465223312378, train_loss: 0.640269935131073\n",
            "4320 val_loss: 0.6449648141860962, train_loss: 0.639858603477478\n",
            "4330 val_loss: 0.6445361375808716, train_loss: 0.6394486427307129\n",
            "4340 val_loss: 0.6441168785095215, train_loss: 0.6390537023544312\n",
            "4350 val_loss: 0.6437774896621704, train_loss: 0.6386805176734924\n",
            "4360 val_loss: 0.6433549523353577, train_loss: 0.6382489800453186\n",
            "4370 val_loss: 0.6429513692855835, train_loss: 0.6378459334373474\n",
            "4380 val_loss: 0.6424884796142578, train_loss: 0.6374555826187134\n",
            "4390 val_loss: 0.6420525312423706, train_loss: 0.637068510055542\n",
            "4400 val_loss: 0.6417183876037598, train_loss: 0.6367300748825073\n",
            "4410 val_loss: 0.6413016319274902, train_loss: 0.6363852024078369\n",
            "4420 val_loss: 0.6408419013023376, train_loss: 0.6359788775444031\n",
            "4430 val_loss: 0.6404005885124207, train_loss: 0.6355194449424744\n",
            "4440 val_loss: 0.6399977803230286, train_loss: 0.6351870894432068\n",
            "4450 val_loss: 0.6396124362945557, train_loss: 0.6348695755004883\n",
            "4460 val_loss: 0.6392356157302856, train_loss: 0.6345522999763489\n",
            "4470 val_loss: 0.6388548016548157, train_loss: 0.6342344284057617\n",
            "4480 val_loss: 0.6385650634765625, train_loss: 0.633891761302948\n",
            "4490 val_loss: 0.638144850730896, train_loss: 0.6334803700447083\n",
            "4500 val_loss: 0.6377444863319397, train_loss: 0.6331325769424438\n",
            "4510 val_loss: 0.637378990650177, train_loss: 0.6327621340751648\n",
            "4520 val_loss: 0.6369500756263733, train_loss: 0.6323726177215576\n",
            "4530 val_loss: 0.6365949511528015, train_loss: 0.6320194005966187\n",
            "4540 val_loss: 0.6362650394439697, train_loss: 0.6316531300544739\n",
            "4550 val_loss: 0.6359809041023254, train_loss: 0.6313139200210571\n",
            "4560 val_loss: 0.6356329917907715, train_loss: 0.6309597492218018\n",
            "4570 val_loss: 0.6352551579475403, train_loss: 0.6306164264678955\n",
            "4580 val_loss: 0.6349323391914368, train_loss: 0.6303108930587769\n",
            "4590 val_loss: 0.6347113847732544, train_loss: 0.6300502419471741\n",
            "4600 val_loss: 0.6343740820884705, train_loss: 0.6296656727790833\n",
            "4610 val_loss: 0.6340524554252625, train_loss: 0.6293339729309082\n",
            "4620 val_loss: 0.6338214874267578, train_loss: 0.6290814876556396\n",
            "4630 val_loss: 0.6334547996520996, train_loss: 0.6287155151367188\n",
            "4640 val_loss: 0.6330128312110901, train_loss: 0.628368079662323\n",
            "4650 val_loss: 0.6326585412025452, train_loss: 0.628028154373169\n",
            "4660 val_loss: 0.6322513222694397, train_loss: 0.6276872754096985\n",
            "4670 val_loss: 0.6318495869636536, train_loss: 0.6273636817932129\n",
            "4680 val_loss: 0.6314405798912048, train_loss: 0.6270203590393066\n",
            "4690 val_loss: 0.6311327815055847, train_loss: 0.6267995834350586\n",
            "4700 val_loss: 0.6307416558265686, train_loss: 0.6264508962631226\n",
            "4710 val_loss: 0.6304261088371277, train_loss: 0.6260401010513306\n",
            "4720 val_loss: 0.6302505135536194, train_loss: 0.6257709860801697\n",
            "4730 val_loss: 0.629856288433075, train_loss: 0.6253871917724609\n",
            "4740 val_loss: 0.6295526027679443, train_loss: 0.6250008940696716\n",
            "4750 val_loss: 0.6291911005973816, train_loss: 0.6247009634971619\n",
            "4760 val_loss: 0.6287513375282288, train_loss: 0.6243313550949097\n",
            "4770 val_loss: 0.6285085678100586, train_loss: 0.6240634918212891\n",
            "4780 val_loss: 0.6282582879066467, train_loss: 0.6238461136817932\n",
            "4790 val_loss: 0.6277912855148315, train_loss: 0.6234251260757446\n",
            "4800 val_loss: 0.6274093985557556, train_loss: 0.6231178045272827\n",
            "4810 val_loss: 0.6269336342811584, train_loss: 0.6228393912315369\n",
            "4820 val_loss: 0.6264706254005432, train_loss: 0.6225285530090332\n",
            "4830 val_loss: 0.6260749101638794, train_loss: 0.622138261795044\n",
            "4840 val_loss: 0.6257522702217102, train_loss: 0.6218542456626892\n",
            "4850 val_loss: 0.6254428625106812, train_loss: 0.6216907501220703\n",
            "4860 val_loss: 0.6251997947692871, train_loss: 0.6214630603790283\n",
            "4870 val_loss: 0.6249586939811707, train_loss: 0.6211395859718323\n",
            "4880 val_loss: 0.624586284160614, train_loss: 0.6207736134529114\n",
            "4890 val_loss: 0.6242243647575378, train_loss: 0.6204599738121033\n",
            "4900 val_loss: 0.6240342855453491, train_loss: 0.6201316714286804\n",
            "4910 val_loss: 0.6236867904663086, train_loss: 0.6198829412460327\n",
            "4920 val_loss: 0.6233547925949097, train_loss: 0.6196461319923401\n",
            "4930 val_loss: 0.6229906678199768, train_loss: 0.6193094849586487\n",
            "4940 val_loss: 0.6227142810821533, train_loss: 0.6190966963768005\n",
            "4950 val_loss: 0.6222960352897644, train_loss: 0.6188712120056152\n",
            "4960 val_loss: 0.6219920516014099, train_loss: 0.6186919808387756\n",
            "4970 val_loss: 0.6217066645622253, train_loss: 0.618497371673584\n",
            "4980 val_loss: 0.6215909123420715, train_loss: 0.6181762218475342\n",
            "4990 val_loss: 0.6212218999862671, train_loss: 0.6178475022315979\n",
            "5000 val_loss: 0.6210031509399414, train_loss: 0.617628276348114\n",
            "5010 val_loss: 0.6207486987113953, train_loss: 0.617558479309082\n",
            "5020 val_loss: 0.6205765604972839, train_loss: 0.6173225045204163\n",
            "5030 val_loss: 0.6201305389404297, train_loss: 0.6170424818992615\n",
            "5040 val_loss: 0.6199202537536621, train_loss: 0.6168813705444336\n",
            "5050 val_loss: 0.6196387410163879, train_loss: 0.6167197227478027\n",
            "5060 val_loss: 0.6194249987602234, train_loss: 0.616452157497406\n",
            "5070 val_loss: 0.6191860437393188, train_loss: 0.616220235824585\n",
            "5080 val_loss: 0.6189066767692566, train_loss: 0.6160629391670227\n",
            "5090 val_loss: 0.6186753511428833, train_loss: 0.6157588362693787\n",
            "5100 val_loss: 0.6186619997024536, train_loss: 0.6156396865844727\n",
            "5110 val_loss: 0.618398129940033, train_loss: 0.6153620481491089\n",
            "5120 val_loss: 0.6180790662765503, train_loss: 0.6150936484336853\n",
            "5130 val_loss: 0.6177905797958374, train_loss: 0.6148783564567566\n",
            "5140 val_loss: 0.6173250675201416, train_loss: 0.6145944595336914\n",
            "5150 val_loss: 0.6170786619186401, train_loss: 0.6144055724143982\n",
            "5160 val_loss: 0.6167046427726746, train_loss: 0.6140907406806946\n",
            "5170 val_loss: 0.6166815161705017, train_loss: 0.6138394474983215\n",
            "5180 val_loss: 0.6164739727973938, train_loss: 0.6137151718139648\n",
            "5190 val_loss: 0.6161190271377563, train_loss: 0.6134850382804871\n",
            "5200 val_loss: 0.6158556938171387, train_loss: 0.6132622361183167\n",
            "5210 val_loss: 0.6155685186386108, train_loss: 0.6131251454353333\n",
            "5220 val_loss: 0.6153792142868042, train_loss: 0.6128960251808167\n",
            "5230 val_loss: 0.6151560544967651, train_loss: 0.6126104593276978\n",
            "5240 val_loss: 0.6148260831832886, train_loss: 0.6123083233833313\n",
            "5250 val_loss: 0.6146029233932495, train_loss: 0.6121541261672974\n",
            "5260 val_loss: 0.6142870783805847, train_loss: 0.6118705868721008\n",
            "5270 val_loss: 0.6141037940979004, train_loss: 0.6117585301399231\n",
            "5280 val_loss: 0.6138850450515747, train_loss: 0.6115481853485107\n",
            "5290 val_loss: 0.6136184930801392, train_loss: 0.6112696528434753\n",
            "5300 val_loss: 0.6135382652282715, train_loss: 0.6111889481544495\n",
            "5310 val_loss: 0.6132023334503174, train_loss: 0.6109356880187988\n",
            "5320 val_loss: 0.6129314303398132, train_loss: 0.6108179688453674\n",
            "5330 val_loss: 0.6126578450202942, train_loss: 0.6105278134346008\n",
            "5340 val_loss: 0.6123587489128113, train_loss: 0.6102864146232605\n",
            "5350 val_loss: 0.6122317910194397, train_loss: 0.6102098822593689\n",
            "5360 val_loss: 0.6120285987854004, train_loss: 0.6100082397460938\n",
            "5370 val_loss: 0.6118618845939636, train_loss: 0.6097950339317322\n",
            "5380 val_loss: 0.6116288304328918, train_loss: 0.6095594167709351\n",
            "5390 val_loss: 0.6115978956222534, train_loss: 0.6094183921813965\n",
            "5400 val_loss: 0.6112729907035828, train_loss: 0.6092453598976135\n",
            "5410 val_loss: 0.6110957264900208, train_loss: 0.6091172099113464\n",
            "5420 val_loss: 0.610961377620697, train_loss: 0.6089162230491638\n",
            "5430 val_loss: 0.6106628179550171, train_loss: 0.6086841225624084\n",
            "5440 val_loss: 0.6107115149497986, train_loss: 0.6085190773010254\n",
            "5450 val_loss: 0.6106516122817993, train_loss: 0.6083149313926697\n",
            "5460 val_loss: 0.6099492311477661, train_loss: 0.6079149842262268\n",
            "5470 val_loss: 0.6094995737075806, train_loss: 0.6077021956443787\n",
            "5480 val_loss: 0.6093221306800842, train_loss: 0.6074748039245605\n",
            "5490 val_loss: 0.6090693473815918, train_loss: 0.6073219776153564\n",
            "5500 val_loss: 0.6089808344841003, train_loss: 0.6071891784667969\n",
            "5510 val_loss: 0.608848512172699, train_loss: 0.6069799661636353\n",
            "5520 val_loss: 0.6085229516029358, train_loss: 0.6067753434181213\n",
            "5530 val_loss: 0.6084269881248474, train_loss: 0.6066303849220276\n",
            "5540 val_loss: 0.6082698702812195, train_loss: 0.6065487265586853\n",
            "5550 val_loss: 0.6079867482185364, train_loss: 0.60633385181427\n",
            "5560 val_loss: 0.6077662110328674, train_loss: 0.6060482859611511\n",
            "5570 val_loss: 0.607505202293396, train_loss: 0.6058101058006287\n",
            "5580 val_loss: 0.6073909997940063, train_loss: 0.6056087017059326\n",
            "5590 val_loss: 0.607379138469696, train_loss: 0.6055705547332764\n",
            "5600 val_loss: 0.6070650219917297, train_loss: 0.605369508266449\n",
            "5610 val_loss: 0.6067493557929993, train_loss: 0.6050922274589539\n",
            "5620 val_loss: 0.6065527200698853, train_loss: 0.6048817038536072\n",
            "5630 val_loss: 0.6064713597297668, train_loss: 0.604703962802887\n",
            "5640 val_loss: 0.6062291860580444, train_loss: 0.604500949382782\n",
            "5650 val_loss: 0.6060479283332825, train_loss: 0.6043462753295898\n",
            "5660 val_loss: 0.6058337688446045, train_loss: 0.6041682362556458\n",
            "5670 val_loss: 0.6057425737380981, train_loss: 0.6040598154067993\n",
            "5680 val_loss: 0.605362057685852, train_loss: 0.6038835644721985\n",
            "5690 val_loss: 0.6050881147384644, train_loss: 0.6037020683288574\n",
            "5700 val_loss: 0.6049980521202087, train_loss: 0.6036041975021362\n",
            "5710 val_loss: 0.6048411726951599, train_loss: 0.6034484505653381\n",
            "5720 val_loss: 0.6048981547355652, train_loss: 0.6033934950828552\n",
            "5730 val_loss: 0.6045693755149841, train_loss: 0.6031869649887085\n",
            "5740 val_loss: 0.6042300462722778, train_loss: 0.6028745770454407\n",
            "5750 val_loss: 0.6041278839111328, train_loss: 0.6027470231056213\n",
            "5760 val_loss: 0.6040409803390503, train_loss: 0.6026936173439026\n",
            "5770 val_loss: 0.6040372848510742, train_loss: 0.6026104688644409\n",
            "5780 val_loss: 0.6037920713424683, train_loss: 0.602425217628479\n",
            "5790 val_loss: 0.603672981262207, train_loss: 0.6021376848220825\n",
            "5800 val_loss: 0.6035130620002747, train_loss: 0.6020337343215942\n",
            "5810 val_loss: 0.6034963130950928, train_loss: 0.6019420027732849\n",
            "5820 val_loss: 0.6032876372337341, train_loss: 0.6017234325408936\n",
            "5830 val_loss: 0.6030057668685913, train_loss: 0.6015430092811584\n",
            "5840 val_loss: 0.602774977684021, train_loss: 0.60142982006073\n",
            "5850 val_loss: 0.6024765968322754, train_loss: 0.6012806296348572\n",
            "5860 val_loss: 0.6023643612861633, train_loss: 0.6012029647827148\n",
            "5870 val_loss: 0.6023361086845398, train_loss: 0.6010612845420837\n",
            "5880 val_loss: 0.6020458936691284, train_loss: 0.6008980870246887\n",
            "5890 val_loss: 0.6019288301467896, train_loss: 0.6006941199302673\n",
            "5900 val_loss: 0.6015843152999878, train_loss: 0.6004580855369568\n",
            "5910 val_loss: 0.6015146374702454, train_loss: 0.6003299355506897\n",
            "5920 val_loss: 0.6014645099639893, train_loss: 0.6001956462860107\n",
            "5930 val_loss: 0.6013886332511902, train_loss: 0.6000461578369141\n",
            "5940 val_loss: 0.6011185646057129, train_loss: 0.5997424721717834\n",
            "5950 val_loss: 0.6009642481803894, train_loss: 0.5996196866035461\n",
            "5960 val_loss: 0.6009029746055603, train_loss: 0.5995223522186279\n",
            "5970 val_loss: 0.6007418036460876, train_loss: 0.5993921160697937\n",
            "5980 val_loss: 0.6005825996398926, train_loss: 0.5992484092712402\n",
            "5990 val_loss: 0.6003231406211853, train_loss: 0.5991132259368896\n",
            "6000 val_loss: 0.6002033352851868, train_loss: 0.5989266633987427\n",
            "6010 val_loss: 0.6000807881355286, train_loss: 0.5987281203269958\n",
            "6020 val_loss: 0.5999653935432434, train_loss: 0.5986588001251221\n",
            "6030 val_loss: 0.5999493598937988, train_loss: 0.5985960960388184\n",
            "6040 val_loss: 0.5997191667556763, train_loss: 0.5984005331993103\n",
            "6050 val_loss: 0.5996285676956177, train_loss: 0.5983245968818665\n",
            "6060 val_loss: 0.5995697975158691, train_loss: 0.5981943607330322\n",
            "6070 val_loss: 0.5993735790252686, train_loss: 0.5980624556541443\n",
            "6080 val_loss: 0.5993375182151794, train_loss: 0.5979041457176208\n",
            "6090 val_loss: 0.5993965268135071, train_loss: 0.5978964567184448\n",
            "6100 val_loss: 0.5995795130729675, train_loss: 0.5977638959884644\n",
            "6110 val_loss: 0.5993454456329346, train_loss: 0.597650408744812\n",
            "6120 val_loss: 0.5989735722541809, train_loss: 0.5974510312080383\n",
            "6130 val_loss: 0.5987750291824341, train_loss: 0.5972711443901062\n",
            "6140 val_loss: 0.5985912680625916, train_loss: 0.597093403339386\n",
            "6150 val_loss: 0.5985019207000732, train_loss: 0.596950888633728\n",
            "6160 val_loss: 0.5982937812805176, train_loss: 0.5968976616859436\n",
            "6170 val_loss: 0.5981894731521606, train_loss: 0.5966863036155701\n",
            "6180 val_loss: 0.5979685187339783, train_loss: 0.5964633226394653\n",
            "6190 val_loss: 0.5979719758033752, train_loss: 0.5963897109031677\n",
            "6200 val_loss: 0.5980126261711121, train_loss: 0.5963687300682068\n",
            "6210 val_loss: 0.5978333353996277, train_loss: 0.5961840152740479\n",
            "6220 val_loss: 0.5977849364280701, train_loss: 0.5961251258850098\n",
            "6230 val_loss: 0.5975254774093628, train_loss: 0.5958221554756165\n",
            "6240 val_loss: 0.5971559882164001, train_loss: 0.595522403717041\n",
            "6250 val_loss: 0.5969312787055969, train_loss: 0.5952860713005066\n",
            "6260 val_loss: 0.5968571901321411, train_loss: 0.5951797366142273\n",
            "6270 val_loss: 0.5966443419456482, train_loss: 0.5951113104820251\n",
            "6280 val_loss: 0.5964104533195496, train_loss: 0.594875156879425\n",
            "6290 val_loss: 0.5961683988571167, train_loss: 0.594790518283844\n",
            "6300 val_loss: 0.5960640907287598, train_loss: 0.5946300029754639\n",
            "6310 val_loss: 0.5960131287574768, train_loss: 0.5944685935974121\n",
            "6320 val_loss: 0.5957595705986023, train_loss: 0.5942164659500122\n",
            "6330 val_loss: 0.5955570936203003, train_loss: 0.5941668152809143\n",
            "6340 val_loss: 0.595536470413208, train_loss: 0.5939826369285583\n",
            "6350 val_loss: 0.5954533815383911, train_loss: 0.5939281582832336\n",
            "6360 val_loss: 0.5954516530036926, train_loss: 0.5937836766242981\n",
            "6370 val_loss: 0.5951400995254517, train_loss: 0.5935431718826294\n",
            "6380 val_loss: 0.5951134562492371, train_loss: 0.5934453010559082\n",
            "6390 val_loss: 0.59491366147995, train_loss: 0.593386173248291\n",
            "6400 val_loss: 0.5947991609573364, train_loss: 0.5931875109672546\n",
            "6410 val_loss: 0.5947204828262329, train_loss: 0.5930705070495605\n",
            "6420 val_loss: 0.5945448279380798, train_loss: 0.593001127243042\n",
            "6430 val_loss: 0.5944762825965881, train_loss: 0.5927972197532654\n",
            "6440 val_loss: 0.5943441390991211, train_loss: 0.592677116394043\n",
            "6450 val_loss: 0.5942134261131287, train_loss: 0.5924886465072632\n",
            "6460 val_loss: 0.5939480662345886, train_loss: 0.5921845436096191\n",
            "6470 val_loss: 0.5937772393226624, train_loss: 0.5920389294624329\n",
            "6480 val_loss: 0.5935454964637756, train_loss: 0.5918816924095154\n",
            "6490 val_loss: 0.5932019352912903, train_loss: 0.5916743278503418\n",
            "6500 val_loss: 0.5929907560348511, train_loss: 0.5913411378860474\n",
            "6510 val_loss: 0.5929235219955444, train_loss: 0.5911153554916382\n",
            "6520 val_loss: 0.5925144553184509, train_loss: 0.5908949971199036\n",
            "6530 val_loss: 0.5920985341072083, train_loss: 0.5907957553863525\n",
            "6540 val_loss: 0.5918469429016113, train_loss: 0.5906339287757874\n",
            "6550 val_loss: 0.591619610786438, train_loss: 0.5903928875923157\n",
            "6560 val_loss: 0.5913246870040894, train_loss: 0.5901259779930115\n",
            "6570 val_loss: 0.5912700891494751, train_loss: 0.5900801420211792\n",
            "6580 val_loss: 0.5912061333656311, train_loss: 0.5900560617446899\n",
            "6590 val_loss: 0.5909867882728577, train_loss: 0.5898727178573608\n",
            "6600 val_loss: 0.5908976793289185, train_loss: 0.5896425247192383\n",
            "6610 val_loss: 0.5907352566719055, train_loss: 0.5894128084182739\n",
            "6620 val_loss: 0.5905445218086243, train_loss: 0.5891849398612976\n",
            "6630 val_loss: 0.5904328227043152, train_loss: 0.5889252424240112\n",
            "6640 val_loss: 0.5901492238044739, train_loss: 0.5887016654014587\n",
            "6650 val_loss: 0.5899547934532166, train_loss: 0.5885925889015198\n",
            "6660 val_loss: 0.5898881554603577, train_loss: 0.5884699821472168\n",
            "6670 val_loss: 0.5897422432899475, train_loss: 0.5882567763328552\n",
            "6680 val_loss: 0.5894984006881714, train_loss: 0.5880880355834961\n",
            "6690 val_loss: 0.5893099904060364, train_loss: 0.5877388715744019\n",
            "6700 val_loss: 0.5891960859298706, train_loss: 0.5876182317733765\n",
            "6710 val_loss: 0.5890837907791138, train_loss: 0.5875857472419739\n",
            "6720 val_loss: 0.5891185998916626, train_loss: 0.587477445602417\n",
            "6730 val_loss: 0.5888471007347107, train_loss: 0.5871441960334778\n",
            "6740 val_loss: 0.588699460029602, train_loss: 0.5870709419250488\n",
            "6750 val_loss: 0.5886750221252441, train_loss: 0.586966872215271\n",
            "6760 val_loss: 0.5884495973587036, train_loss: 0.5867615342140198\n",
            "6770 val_loss: 0.5883559584617615, train_loss: 0.586597204208374\n",
            "6780 val_loss: 0.5882720351219177, train_loss: 0.5864662528038025\n",
            "6790 val_loss: 0.5880122184753418, train_loss: 0.5863297581672668\n",
            "6800 val_loss: 0.5879019498825073, train_loss: 0.5862029790878296\n",
            "6810 val_loss: 0.5878832936286926, train_loss: 0.5860253572463989\n",
            "6820 val_loss: 0.5876593589782715, train_loss: 0.585807740688324\n",
            "6830 val_loss: 0.5874984860420227, train_loss: 0.5856257081031799\n",
            "6840 val_loss: 0.5872671604156494, train_loss: 0.5853661298751831\n",
            "6850 val_loss: 0.5872121453285217, train_loss: 0.5853894352912903\n",
            "6860 val_loss: 0.5870392918586731, train_loss: 0.5851977467536926\n",
            "6870 val_loss: 0.5868239402770996, train_loss: 0.5850066542625427\n",
            "6880 val_loss: 0.5868387818336487, train_loss: 0.5849089026451111\n",
            "6890 val_loss: 0.5865337252616882, train_loss: 0.5846461653709412\n",
            "6900 val_loss: 0.5863663554191589, train_loss: 0.5844699144363403\n",
            "6910 val_loss: 0.5864076018333435, train_loss: 0.5844926834106445\n",
            "6920 val_loss: 0.5862886309623718, train_loss: 0.5842410326004028\n",
            "6930 val_loss: 0.5860909223556519, train_loss: 0.5841102600097656\n",
            "6940 val_loss: 0.5858330726623535, train_loss: 0.583846926689148\n",
            "6950 val_loss: 0.5853973031044006, train_loss: 0.5834329724311829\n",
            "6960 val_loss: 0.5853223204612732, train_loss: 0.5832425951957703\n",
            "6970 val_loss: 0.5851914882659912, train_loss: 0.583096981048584\n",
            "6980 val_loss: 0.5849749445915222, train_loss: 0.582853376865387\n",
            "6990 val_loss: 0.5847845673561096, train_loss: 0.582576334476471\n",
            "7000 val_loss: 0.584645688533783, train_loss: 0.5823971033096313\n",
            "7010 val_loss: 0.5844137072563171, train_loss: 0.5820809006690979\n",
            "7020 val_loss: 0.5842517614364624, train_loss: 0.5819512605667114\n",
            "7030 val_loss: 0.5842074155807495, train_loss: 0.5819491744041443\n",
            "7040 val_loss: 0.584070086479187, train_loss: 0.5817475318908691\n",
            "7050 val_loss: 0.5836700201034546, train_loss: 0.5815000534057617\n",
            "7060 val_loss: 0.583411693572998, train_loss: 0.5812557339668274\n",
            "7070 val_loss: 0.5833672881126404, train_loss: 0.5811111927032471\n",
            "7080 val_loss: 0.5833783149719238, train_loss: 0.5809341073036194\n",
            "7090 val_loss: 0.5831090211868286, train_loss: 0.580674409866333\n",
            "7100 val_loss: 0.58287513256073, train_loss: 0.5804899334907532\n",
            "7110 val_loss: 0.5825857520103455, train_loss: 0.5800901651382446\n",
            "7120 val_loss: 0.5822351574897766, train_loss: 0.5797362327575684\n",
            "7130 val_loss: 0.582024872303009, train_loss: 0.5794235467910767\n",
            "7140 val_loss: 0.5817790031433105, train_loss: 0.5791480541229248\n",
            "7150 val_loss: 0.581444263458252, train_loss: 0.5788136720657349\n",
            "7160 val_loss: 0.5812408328056335, train_loss: 0.5785337090492249\n",
            "7170 val_loss: 0.5811741948127747, train_loss: 0.5783791542053223\n",
            "7180 val_loss: 0.5810383558273315, train_loss: 0.5783745646476746\n",
            "7190 val_loss: 0.5808414220809937, train_loss: 0.5781041979789734\n",
            "7200 val_loss: 0.5806345343589783, train_loss: 0.5778573155403137\n",
            "7210 val_loss: 0.5804644227027893, train_loss: 0.5776951909065247\n",
            "7220 val_loss: 0.5804030299186707, train_loss: 0.5777509212493896\n",
            "7230 val_loss: 0.5802432298660278, train_loss: 0.5775361657142639\n",
            "7240 val_loss: 0.5800720453262329, train_loss: 0.5773599147796631\n",
            "7250 val_loss: 0.5797989964485168, train_loss: 0.577091634273529\n",
            "7260 val_loss: 0.5796520113945007, train_loss: 0.5768893361091614\n",
            "7270 val_loss: 0.5795429944992065, train_loss: 0.5767707228660583\n",
            "7280 val_loss: 0.5793773531913757, train_loss: 0.5766288042068481\n",
            "7290 val_loss: 0.5790057182312012, train_loss: 0.5762149691581726\n",
            "7300 val_loss: 0.5786267518997192, train_loss: 0.5758674740791321\n",
            "7310 val_loss: 0.5785145163536072, train_loss: 0.5756658315658569\n",
            "7320 val_loss: 0.5782707929611206, train_loss: 0.5753718018531799\n",
            "7330 val_loss: 0.5781019926071167, train_loss: 0.5752193927764893\n",
            "7340 val_loss: 0.5778029561042786, train_loss: 0.5749943256378174\n",
            "7350 val_loss: 0.5777705311775208, train_loss: 0.5748247504234314\n",
            "7360 val_loss: 0.577552318572998, train_loss: 0.5744869709014893\n",
            "7370 val_loss: 0.5773744583129883, train_loss: 0.5743777751922607\n",
            "7380 val_loss: 0.5770284533500671, train_loss: 0.5742579102516174\n",
            "7390 val_loss: 0.5767804384231567, train_loss: 0.5740041732788086\n",
            "7400 val_loss: 0.5766516923904419, train_loss: 0.5738008618354797\n",
            "7410 val_loss: 0.5766200423240662, train_loss: 0.5737595558166504\n",
            "7420 val_loss: 0.5765048265457153, train_loss: 0.5733945965766907\n",
            "7430 val_loss: 0.5762823820114136, train_loss: 0.5732062458992004\n",
            "7440 val_loss: 0.5761595368385315, train_loss: 0.5729509592056274\n",
            "7450 val_loss: 0.5758258104324341, train_loss: 0.5726625919342041\n",
            "7460 val_loss: 0.5753747224807739, train_loss: 0.5721650123596191\n",
            "7470 val_loss: 0.5751572847366333, train_loss: 0.5719770193099976\n",
            "7480 val_loss: 0.5750072002410889, train_loss: 0.5717009902000427\n",
            "7490 val_loss: 0.5750041007995605, train_loss: 0.5716182589530945\n",
            "7500 val_loss: 0.5748714804649353, train_loss: 0.5714110732078552\n",
            "7510 val_loss: 0.5746783018112183, train_loss: 0.5711696147918701\n",
            "7520 val_loss: 0.5743821263313293, train_loss: 0.5709456205368042\n",
            "7530 val_loss: 0.5739649534225464, train_loss: 0.5706462264060974\n",
            "7540 val_loss: 0.5735695958137512, train_loss: 0.5702494382858276\n",
            "7550 val_loss: 0.5733090043067932, train_loss: 0.5698979496955872\n",
            "7560 val_loss: 0.5728990435600281, train_loss: 0.5695458054542542\n",
            "7570 val_loss: 0.5728141069412231, train_loss: 0.5693740248680115\n",
            "7580 val_loss: 0.5728882551193237, train_loss: 0.5694499015808105\n",
            "7590 val_loss: 0.572687029838562, train_loss: 0.5691884160041809\n",
            "7600 val_loss: 0.5725150108337402, train_loss: 0.5689225792884827\n",
            "7610 val_loss: 0.5723015666007996, train_loss: 0.568716824054718\n",
            "7620 val_loss: 0.5720032453536987, train_loss: 0.568414568901062\n",
            "7630 val_loss: 0.5718762278556824, train_loss: 0.5683528184890747\n",
            "7640 val_loss: 0.5717025995254517, train_loss: 0.5679823160171509\n",
            "7650 val_loss: 0.5717580914497375, train_loss: 0.5679018497467041\n",
            "7660 val_loss: 0.5714744329452515, train_loss: 0.5675331950187683\n",
            "7670 val_loss: 0.5714049339294434, train_loss: 0.5672938227653503\n",
            "7680 val_loss: 0.5713577270507812, train_loss: 0.5672568678855896\n",
            "7690 val_loss: 0.5711817741394043, train_loss: 0.567034900188446\n",
            "7700 val_loss: 0.571049690246582, train_loss: 0.5668764710426331\n",
            "7710 val_loss: 0.5706448554992676, train_loss: 0.5663920044898987\n",
            "7720 val_loss: 0.570453941822052, train_loss: 0.566182017326355\n",
            "7730 val_loss: 0.5702791810035706, train_loss: 0.5658842325210571\n",
            "7740 val_loss: 0.5701298713684082, train_loss: 0.5655950307846069\n",
            "7750 val_loss: 0.5699394345283508, train_loss: 0.5652459859848022\n",
            "7760 val_loss: 0.5696913003921509, train_loss: 0.5650215148925781\n",
            "7770 val_loss: 0.5694182515144348, train_loss: 0.5646108388900757\n",
            "7780 val_loss: 0.5690493583679199, train_loss: 0.5642780065536499\n",
            "7790 val_loss: 0.5687575936317444, train_loss: 0.5639219284057617\n",
            "7800 val_loss: 0.5682626366615295, train_loss: 0.5635156035423279\n",
            "7810 val_loss: 0.5677266120910645, train_loss: 0.5631091594696045\n",
            "7820 val_loss: 0.5673636794090271, train_loss: 0.5627437233924866\n",
            "7830 val_loss: 0.5671799778938293, train_loss: 0.5626558065414429\n",
            "7840 val_loss: 0.5668956637382507, train_loss: 0.5623719096183777\n",
            "7850 val_loss: 0.5666662454605103, train_loss: 0.5620808601379395\n",
            "7860 val_loss: 0.5663673877716064, train_loss: 0.5615895390510559\n",
            "7870 val_loss: 0.5658794045448303, train_loss: 0.5610844492912292\n",
            "7880 val_loss: 0.5654518008232117, train_loss: 0.560764729976654\n",
            "7890 val_loss: 0.5650396347045898, train_loss: 0.560440182685852\n",
            "7900 val_loss: 0.5646238923072815, train_loss: 0.5601195096969604\n",
            "7910 val_loss: 0.564435601234436, train_loss: 0.5597435832023621\n",
            "7920 val_loss: 0.5639125108718872, train_loss: 0.5593162178993225\n",
            "7930 val_loss: 0.5636229515075684, train_loss: 0.5588675737380981\n",
            "7940 val_loss: 0.563265860080719, train_loss: 0.5585618019104004\n",
            "7950 val_loss: 0.5629099011421204, train_loss: 0.558144211769104\n",
            "7960 val_loss: 0.5627099871635437, train_loss: 0.557907223701477\n",
            "7970 val_loss: 0.5625224709510803, train_loss: 0.5575754046440125\n",
            "7980 val_loss: 0.5619970560073853, train_loss: 0.557138204574585\n",
            "7990 val_loss: 0.5617775917053223, train_loss: 0.5567631125450134\n",
            "8000 val_loss: 0.5614193677902222, train_loss: 0.5565236806869507\n",
            "8010 val_loss: 0.5610901713371277, train_loss: 0.5561909079551697\n",
            "8020 val_loss: 0.5608420372009277, train_loss: 0.5559232234954834\n",
            "8030 val_loss: 0.5605119466781616, train_loss: 0.5556160807609558\n",
            "8040 val_loss: 0.5604212284088135, train_loss: 0.5553522706031799\n",
            "8050 val_loss: 0.5601604580879211, train_loss: 0.5551405549049377\n",
            "8060 val_loss: 0.5597060918807983, train_loss: 0.5546818375587463\n",
            "8070 val_loss: 0.5595175623893738, train_loss: 0.5545195937156677\n",
            "8080 val_loss: 0.5592796206474304, train_loss: 0.5542714595794678\n",
            "8090 val_loss: 0.5591368675231934, train_loss: 0.5539980530738831\n",
            "8100 val_loss: 0.5587589740753174, train_loss: 0.5535743236541748\n",
            "8110 val_loss: 0.5582081079483032, train_loss: 0.5532193183898926\n",
            "8120 val_loss: 0.557797908782959, train_loss: 0.552861213684082\n",
            "8130 val_loss: 0.5573228597640991, train_loss: 0.5523932576179504\n",
            "8140 val_loss: 0.5567564964294434, train_loss: 0.5518903732299805\n",
            "8150 val_loss: 0.5565472841262817, train_loss: 0.5515280365943909\n",
            "8160 val_loss: 0.556135892868042, train_loss: 0.5511899590492249\n",
            "8170 val_loss: 0.555823028087616, train_loss: 0.5507978200912476\n",
            "8180 val_loss: 0.5554732084274292, train_loss: 0.5504170060157776\n",
            "8190 val_loss: 0.555138111114502, train_loss: 0.5500456094741821\n",
            "8200 val_loss: 0.5548166632652283, train_loss: 0.5496897101402283\n",
            "8210 val_loss: 0.5544076561927795, train_loss: 0.5492891073226929\n",
            "8220 val_loss: 0.5539559125900269, train_loss: 0.5488766431808472\n",
            "8230 val_loss: 0.5537629127502441, train_loss: 0.5485779643058777\n",
            "8240 val_loss: 0.5534325242042542, train_loss: 0.54816734790802\n",
            "8250 val_loss: 0.5529047846794128, train_loss: 0.5476136803627014\n",
            "8260 val_loss: 0.5526949763298035, train_loss: 0.5471428632736206\n",
            "8270 val_loss: 0.5524938702583313, train_loss: 0.5467631816864014\n",
            "8280 val_loss: 0.5521146655082703, train_loss: 0.5463581681251526\n",
            "8290 val_loss: 0.5516918897628784, train_loss: 0.545781672000885\n",
            "8300 val_loss: 0.5513120293617249, train_loss: 0.545420229434967\n",
            "8310 val_loss: 0.5508206486701965, train_loss: 0.5449370741844177\n",
            "8320 val_loss: 0.5503895878791809, train_loss: 0.5444499850273132\n",
            "8330 val_loss: 0.549986720085144, train_loss: 0.5440071225166321\n",
            "8340 val_loss: 0.5496624708175659, train_loss: 0.5435585379600525\n",
            "8350 val_loss: 0.5491111278533936, train_loss: 0.5429767966270447\n",
            "8360 val_loss: 0.5485426783561707, train_loss: 0.5424522161483765\n",
            "8370 val_loss: 0.5477643013000488, train_loss: 0.541802704334259\n",
            "8380 val_loss: 0.547226071357727, train_loss: 0.5411341786384583\n",
            "8390 val_loss: 0.5469690561294556, train_loss: 0.5407640337944031\n",
            "8400 val_loss: 0.5466562509536743, train_loss: 0.5403488278388977\n",
            "8410 val_loss: 0.5461671948432922, train_loss: 0.5398659110069275\n",
            "8420 val_loss: 0.5458685755729675, train_loss: 0.539470911026001\n",
            "8430 val_loss: 0.5455505847930908, train_loss: 0.5391054153442383\n",
            "8440 val_loss: 0.5453356504440308, train_loss: 0.5386947989463806\n",
            "8450 val_loss: 0.5446128249168396, train_loss: 0.5381168127059937\n",
            "8460 val_loss: 0.5441074967384338, train_loss: 0.5375622510910034\n",
            "8470 val_loss: 0.5435936450958252, train_loss: 0.5371311902999878\n",
            "8480 val_loss: 0.5430768728256226, train_loss: 0.5366080403327942\n",
            "8490 val_loss: 0.5426112413406372, train_loss: 0.5360466837882996\n",
            "8500 val_loss: 0.5420785546302795, train_loss: 0.5355925559997559\n",
            "8510 val_loss: 0.5417860150337219, train_loss: 0.5351349115371704\n",
            "8520 val_loss: 0.5413085222244263, train_loss: 0.5345964431762695\n",
            "8530 val_loss: 0.5409579277038574, train_loss: 0.5340721011161804\n",
            "8540 val_loss: 0.5402975082397461, train_loss: 0.5334298014640808\n",
            "8550 val_loss: 0.5398701429367065, train_loss: 0.5327801704406738\n",
            "8560 val_loss: 0.5392853617668152, train_loss: 0.532261848449707\n",
            "8570 val_loss: 0.5388003587722778, train_loss: 0.5318038463592529\n",
            "8580 val_loss: 0.5383152365684509, train_loss: 0.5313687920570374\n",
            "8590 val_loss: 0.5379139184951782, train_loss: 0.5309798717498779\n",
            "8600 val_loss: 0.5374277830123901, train_loss: 0.5304507613182068\n",
            "8610 val_loss: 0.5370714068412781, train_loss: 0.5299357771873474\n",
            "8620 val_loss: 0.5366761088371277, train_loss: 0.5293946266174316\n",
            "8630 val_loss: 0.5363430976867676, train_loss: 0.529067873954773\n",
            "8640 val_loss: 0.5358824133872986, train_loss: 0.5284698605537415\n",
            "8650 val_loss: 0.5354021191596985, train_loss: 0.5278549790382385\n",
            "8660 val_loss: 0.5348305702209473, train_loss: 0.5272771716117859\n",
            "8670 val_loss: 0.5343137383460999, train_loss: 0.5267295837402344\n",
            "8680 val_loss: 0.5339248180389404, train_loss: 0.5262868404388428\n",
            "8690 val_loss: 0.5334773659706116, train_loss: 0.5257019400596619\n",
            "8700 val_loss: 0.5330367684364319, train_loss: 0.525303304195404\n",
            "8710 val_loss: 0.532810389995575, train_loss: 0.5249813795089722\n",
            "8720 val_loss: 0.5326024889945984, train_loss: 0.5246117115020752\n",
            "8730 val_loss: 0.5321491956710815, train_loss: 0.524134635925293\n",
            "8740 val_loss: 0.5315952897071838, train_loss: 0.5235376358032227\n",
            "8750 val_loss: 0.5311254262924194, train_loss: 0.5230856537818909\n",
            "8760 val_loss: 0.5307040810585022, train_loss: 0.5226207971572876\n",
            "8770 val_loss: 0.5301048755645752, train_loss: 0.5220135450363159\n",
            "8780 val_loss: 0.5297709107398987, train_loss: 0.5215609669685364\n",
            "8790 val_loss: 0.5294594764709473, train_loss: 0.5211464166641235\n",
            "8800 val_loss: 0.5287274122238159, train_loss: 0.5204724669456482\n",
            "8810 val_loss: 0.5282396078109741, train_loss: 0.520054817199707\n",
            "8820 val_loss: 0.5278825163841248, train_loss: 0.5196951031684875\n",
            "8830 val_loss: 0.5276440382003784, train_loss: 0.5192614793777466\n",
            "8840 val_loss: 0.5273759365081787, train_loss: 0.518709123134613\n",
            "8850 val_loss: 0.5266888737678528, train_loss: 0.518150806427002\n",
            "8860 val_loss: 0.5262888073921204, train_loss: 0.5177217125892639\n",
            "8870 val_loss: 0.5258831977844238, train_loss: 0.5172893404960632\n",
            "8880 val_loss: 0.5255579948425293, train_loss: 0.5167006850242615\n",
            "8890 val_loss: 0.5251469612121582, train_loss: 0.5162187814712524\n",
            "8900 val_loss: 0.5247061848640442, train_loss: 0.5159175992012024\n",
            "8910 val_loss: 0.5243895649909973, train_loss: 0.5153638124465942\n",
            "8920 val_loss: 0.5238909721374512, train_loss: 0.5149841904640198\n",
            "8930 val_loss: 0.5234631896018982, train_loss: 0.514488697052002\n",
            "8940 val_loss: 0.5231049060821533, train_loss: 0.5140066146850586\n",
            "8950 val_loss: 0.5229254364967346, train_loss: 0.5135095715522766\n",
            "8960 val_loss: 0.5222546458244324, train_loss: 0.5131451487541199\n",
            "8970 val_loss: 0.5217625498771667, train_loss: 0.5125707387924194\n",
            "8980 val_loss: 0.5212658643722534, train_loss: 0.5121297240257263\n",
            "8990 val_loss: 0.520869791507721, train_loss: 0.5114474892616272\n",
            "9000 val_loss: 0.5204776525497437, train_loss: 0.5109427571296692\n",
            "9010 val_loss: 0.5199589729309082, train_loss: 0.5104000568389893\n",
            "9020 val_loss: 0.5192090272903442, train_loss: 0.5097786784172058\n",
            "9030 val_loss: 0.5187077522277832, train_loss: 0.5091602206230164\n",
            "9040 val_loss: 0.5180814862251282, train_loss: 0.5088993906974792\n",
            "9050 val_loss: 0.5180792808532715, train_loss: 0.5085218548774719\n",
            "9060 val_loss: 0.5177319645881653, train_loss: 0.508086621761322\n",
            "9070 val_loss: 0.51725834608078, train_loss: 0.5074325799942017\n",
            "9080 val_loss: 0.5165625810623169, train_loss: 0.5068443417549133\n",
            "9090 val_loss: 0.5159828662872314, train_loss: 0.5063482522964478\n",
            "9100 val_loss: 0.5155141949653625, train_loss: 0.5058673620223999\n",
            "9110 val_loss: 0.5150967836380005, train_loss: 0.5052515864372253\n",
            "9120 val_loss: 0.5144533514976501, train_loss: 0.5047985911369324\n",
            "9130 val_loss: 0.5139201283454895, train_loss: 0.5044012069702148\n",
            "9140 val_loss: 0.5134173035621643, train_loss: 0.5038057565689087\n",
            "9150 val_loss: 0.5131784081459045, train_loss: 0.5032477378845215\n",
            "9160 val_loss: 0.5127831697463989, train_loss: 0.5028176307678223\n",
            "9170 val_loss: 0.5126149654388428, train_loss: 0.5024731755256653\n",
            "9180 val_loss: 0.5120567083358765, train_loss: 0.5020416975021362\n",
            "9190 val_loss: 0.5115921497344971, train_loss: 0.501481831073761\n",
            "9200 val_loss: 0.5109334588050842, train_loss: 0.5008888244628906\n",
            "9210 val_loss: 0.5105974674224854, train_loss: 0.5004306435585022\n",
            "9220 val_loss: 0.510729193687439, train_loss: 0.5001416206359863\n",
            "9230 val_loss: 0.5098345875740051, train_loss: 0.4994065463542938\n",
            "9240 val_loss: 0.5092487335205078, train_loss: 0.498837411403656\n",
            "9250 val_loss: 0.5086754560470581, train_loss: 0.49830058217048645\n",
            "9260 val_loss: 0.5082293748855591, train_loss: 0.4977625608444214\n",
            "9270 val_loss: 0.5077117085456848, train_loss: 0.49704059958457947\n",
            "9280 val_loss: 0.5073018074035645, train_loss: 0.4965933859348297\n",
            "9290 val_loss: 0.5066708326339722, train_loss: 0.49587973952293396\n",
            "9300 val_loss: 0.506788432598114, train_loss: 0.4955649971961975\n",
            "9310 val_loss: 0.5063925981521606, train_loss: 0.4951428771018982\n",
            "9320 val_loss: 0.5058242082595825, train_loss: 0.49446016550064087\n",
            "9330 val_loss: 0.5050876140594482, train_loss: 0.4940328299999237\n",
            "9340 val_loss: 0.5048003196716309, train_loss: 0.4934960901737213\n",
            "9350 val_loss: 0.50407874584198, train_loss: 0.4928879141807556\n",
            "9360 val_loss: 0.5038701891899109, train_loss: 0.4924158751964569\n",
            "9370 val_loss: 0.5036641955375671, train_loss: 0.4920385777950287\n",
            "9380 val_loss: 0.5034552216529846, train_loss: 0.4915252923965454\n",
            "9390 val_loss: 0.5029935836791992, train_loss: 0.4910213053226471\n",
            "9400 val_loss: 0.5025599002838135, train_loss: 0.49054059386253357\n",
            "9410 val_loss: 0.5019716620445251, train_loss: 0.4899385869503021\n",
            "9420 val_loss: 0.5013728141784668, train_loss: 0.48919397592544556\n",
            "9430 val_loss: 0.500935435295105, train_loss: 0.4885771572589874\n",
            "9440 val_loss: 0.5004358887672424, train_loss: 0.48799028992652893\n",
            "9450 val_loss: 0.5002883076667786, train_loss: 0.48755306005477905\n",
            "9460 val_loss: 0.5000407695770264, train_loss: 0.48700472712516785\n",
            "9470 val_loss: 0.49946194887161255, train_loss: 0.48634159564971924\n",
            "9480 val_loss: 0.4988870620727539, train_loss: 0.48568403720855713\n",
            "9490 val_loss: 0.4987412989139557, train_loss: 0.48526865243911743\n",
            "9500 val_loss: 0.49834537506103516, train_loss: 0.4848192632198334\n",
            "9510 val_loss: 0.49819788336753845, train_loss: 0.48443642258644104\n",
            "9520 val_loss: 0.49782535433769226, train_loss: 0.48405900597572327\n",
            "9530 val_loss: 0.497460275888443, train_loss: 0.4834032654762268\n",
            "9540 val_loss: 0.49742966890335083, train_loss: 0.4831608235836029\n",
            "9550 val_loss: 0.4972541332244873, train_loss: 0.48273542523384094\n",
            "9560 val_loss: 0.4967203140258789, train_loss: 0.482328325510025\n",
            "9570 val_loss: 0.4960143566131592, train_loss: 0.4817354381084442\n",
            "9580 val_loss: 0.49545055627822876, train_loss: 0.4809792935848236\n",
            "9590 val_loss: 0.4953216016292572, train_loss: 0.4806532561779022\n",
            "9600 val_loss: 0.49479231238365173, train_loss: 0.4801902770996094\n",
            "9610 val_loss: 0.494584858417511, train_loss: 0.47981682419776917\n",
            "9620 val_loss: 0.49386268854141235, train_loss: 0.4791482388973236\n",
            "9630 val_loss: 0.49359965324401855, train_loss: 0.478655070066452\n",
            "9640 val_loss: 0.4934837818145752, train_loss: 0.47810131311416626\n",
            "9650 val_loss: 0.492888867855072, train_loss: 0.4776413142681122\n",
            "9660 val_loss: 0.4927738606929779, train_loss: 0.47707536816596985\n",
            "9670 val_loss: 0.4924629330635071, train_loss: 0.4764886200428009\n",
            "9680 val_loss: 0.4920785129070282, train_loss: 0.4760456085205078\n",
            "9690 val_loss: 0.4914973974227905, train_loss: 0.47545990347862244\n",
            "9700 val_loss: 0.4912240505218506, train_loss: 0.4751325249671936\n",
            "9710 val_loss: 0.4908706247806549, train_loss: 0.4746987819671631\n",
            "9720 val_loss: 0.49119439721107483, train_loss: 0.4744257926940918\n",
            "9730 val_loss: 0.4904234707355499, train_loss: 0.47375941276550293\n",
            "9740 val_loss: 0.4900653064250946, train_loss: 0.47316497564315796\n",
            "9750 val_loss: 0.4899543225765228, train_loss: 0.47264936566352844\n",
            "9760 val_loss: 0.48903146386146545, train_loss: 0.4719393253326416\n",
            "9770 val_loss: 0.48942869901657104, train_loss: 0.4715142846107483\n",
            "9780 val_loss: 0.488650918006897, train_loss: 0.47073665261268616\n",
            "9790 val_loss: 0.487903356552124, train_loss: 0.4700034260749817\n",
            "9800 val_loss: 0.48779624700546265, train_loss: 0.46949082612991333\n",
            "9810 val_loss: 0.48732179403305054, train_loss: 0.46881455183029175\n",
            "9820 val_loss: 0.48736509680747986, train_loss: 0.4683816134929657\n",
            "9830 val_loss: 0.48708775639533997, train_loss: 0.4679073393344879\n",
            "9840 val_loss: 0.48695605993270874, train_loss: 0.4676227271556854\n",
            "9850 val_loss: 0.4867955148220062, train_loss: 0.46722412109375\n",
            "9860 val_loss: 0.4865071475505829, train_loss: 0.46647724509239197\n",
            "9870 val_loss: 0.4860433042049408, train_loss: 0.4660063087940216\n",
            "9880 val_loss: 0.4855947494506836, train_loss: 0.465453565120697\n",
            "9890 val_loss: 0.4851047992706299, train_loss: 0.46485722064971924\n",
            "9900 val_loss: 0.48451051115989685, train_loss: 0.464105486869812\n",
            "9910 val_loss: 0.4846429228782654, train_loss: 0.4637407064437866\n",
            "9920 val_loss: 0.48415616154670715, train_loss: 0.4631215035915375\n",
            "9930 val_loss: 0.48377755284309387, train_loss: 0.46268540620803833\n",
            "9940 val_loss: 0.48329442739486694, train_loss: 0.4620307683944702\n",
            "9950 val_loss: 0.4828932583332062, train_loss: 0.46148043870925903\n",
            "9960 val_loss: 0.48260748386383057, train_loss: 0.46092021465301514\n",
            "9970 val_loss: 0.4826413691043854, train_loss: 0.4604358673095703\n",
            "9980 val_loss: 0.48201146721839905, train_loss: 0.4595733880996704\n",
            "9990 val_loss: 0.48179149627685547, train_loss: 0.4589707851409912\n",
            "10000 val_loss: 0.4815022051334381, train_loss: 0.45833227038383484\n",
            "10010 val_loss: 0.48099222779273987, train_loss: 0.45754116773605347\n",
            "10020 val_loss: 0.48122406005859375, train_loss: 0.4574480950832367\n",
            "10030 val_loss: 0.4803207814693451, train_loss: 0.4565578103065491\n",
            "10040 val_loss: 0.4795970320701599, train_loss: 0.4556259214878082\n",
            "10050 val_loss: 0.4794202148914337, train_loss: 0.45498529076576233\n",
            "10060 val_loss: 0.4793064594268799, train_loss: 0.4546286165714264\n",
            "10070 val_loss: 0.4787430167198181, train_loss: 0.45384112000465393\n",
            "10080 val_loss: 0.47836363315582275, train_loss: 0.45327144861221313\n",
            "10090 val_loss: 0.4778972864151001, train_loss: 0.4524231255054474\n",
            "10100 val_loss: 0.4774375259876251, train_loss: 0.4517004191875458\n",
            "10110 val_loss: 0.4775756597518921, train_loss: 0.451262503862381\n",
            "10120 val_loss: 0.47695377469062805, train_loss: 0.45039257407188416\n",
            "10130 val_loss: 0.4767955541610718, train_loss: 0.4499312937259674\n",
            "10140 val_loss: 0.4762626886367798, train_loss: 0.4491492807865143\n",
            "10150 val_loss: 0.47633013129234314, train_loss: 0.44879579544067383\n",
            "10160 val_loss: 0.47553208470344543, train_loss: 0.4478522837162018\n",
            "10170 val_loss: 0.47534042596817017, train_loss: 0.4472541809082031\n",
            "10180 val_loss: 0.4750421941280365, train_loss: 0.4465492069721222\n",
            "10190 val_loss: 0.4746556878089905, train_loss: 0.44578543305397034\n",
            "10200 val_loss: 0.47362014651298523, train_loss: 0.44471609592437744\n",
            "10210 val_loss: 0.47320693731307983, train_loss: 0.4440794289112091\n",
            "10220 val_loss: 0.4732641577720642, train_loss: 0.44373396039009094\n",
            "10230 val_loss: 0.47307533025741577, train_loss: 0.4431796669960022\n",
            "10240 val_loss: 0.4724699556827545, train_loss: 0.442388653755188\n",
            "10250 val_loss: 0.47199422121047974, train_loss: 0.4415862560272217\n",
            "10260 val_loss: 0.47191283106803894, train_loss: 0.44111502170562744\n",
            "10270 val_loss: 0.4716518819332123, train_loss: 0.44053322076797485\n",
            "10280 val_loss: 0.4709409177303314, train_loss: 0.43945375084877014\n",
            "10290 val_loss: 0.4704192876815796, train_loss: 0.43868380784988403\n",
            "10300 val_loss: 0.47001901268959045, train_loss: 0.4378349184989929\n",
            "10310 val_loss: 0.469788134098053, train_loss: 0.4374527037143707\n",
            "10320 val_loss: 0.4699211120605469, train_loss: 0.4371699392795563\n",
            "10330 val_loss: 0.46936729550361633, train_loss: 0.43635380268096924\n",
            "10340 val_loss: 0.46908873319625854, train_loss: 0.4357895255088806\n",
            "10350 val_loss: 0.4684453308582306, train_loss: 0.43492254614830017\n",
            "10360 val_loss: 0.4681365489959717, train_loss: 0.43433278799057007\n",
            "10370 val_loss: 0.4678348898887634, train_loss: 0.43373847007751465\n",
            "10380 val_loss: 0.467195600271225, train_loss: 0.4328089654445648\n",
            "10390 val_loss: 0.466636061668396, train_loss: 0.4318012297153473\n",
            "10400 val_loss: 0.4662398397922516, train_loss: 0.43120816349983215\n",
            "10410 val_loss: 0.4659351706504822, train_loss: 0.43058332800865173\n",
            "10420 val_loss: 0.4656258523464203, train_loss: 0.42986810207366943\n",
            "10430 val_loss: 0.46534818410873413, train_loss: 0.42909619212150574\n",
            "10440 val_loss: 0.46491163969039917, train_loss: 0.42832767963409424\n",
            "10450 val_loss: 0.46469825506210327, train_loss: 0.4277833104133606\n",
            "10460 val_loss: 0.46421703696250916, train_loss: 0.42684656381607056\n",
            "10470 val_loss: 0.4635652005672455, train_loss: 0.4258219599723816\n",
            "10480 val_loss: 0.4630557894706726, train_loss: 0.4248594641685486\n",
            "10490 val_loss: 0.4632304906845093, train_loss: 0.4247535467147827\n",
            "10500 val_loss: 0.46283072233200073, train_loss: 0.42385634779930115\n",
            "10510 val_loss: 0.46229806542396545, train_loss: 0.42289742827415466\n",
            "10520 val_loss: 0.46196892857551575, train_loss: 0.42214593291282654\n",
            "10530 val_loss: 0.4619887173175812, train_loss: 0.4217830300331116\n",
            "10540 val_loss: 0.4616045355796814, train_loss: 0.4210403859615326\n",
            "10550 val_loss: 0.46131956577301025, train_loss: 0.4203704595565796\n",
            "10560 val_loss: 0.46061456203460693, train_loss: 0.4192006289958954\n",
            "10570 val_loss: 0.4604730010032654, train_loss: 0.4188007414340973\n",
            "10580 val_loss: 0.46019309759140015, train_loss: 0.4182388484477997\n",
            "10590 val_loss: 0.46009841561317444, train_loss: 0.41777944564819336\n",
            "10600 val_loss: 0.4595567286014557, train_loss: 0.41694632172584534\n",
            "10610 val_loss: 0.4586055874824524, train_loss: 0.4156917929649353\n",
            "10620 val_loss: 0.4581655263900757, train_loss: 0.4147476255893707\n",
            "10630 val_loss: 0.45759767293930054, train_loss: 0.41387712955474854\n",
            "10640 val_loss: 0.457775354385376, train_loss: 0.4135280251502991\n",
            "10650 val_loss: 0.4571102559566498, train_loss: 0.4126835763454437\n",
            "10660 val_loss: 0.45639723539352417, train_loss: 0.4117182493209839\n",
            "10670 val_loss: 0.45582544803619385, train_loss: 0.41074129939079285\n",
            "10680 val_loss: 0.4556773006916046, train_loss: 0.41015422344207764\n",
            "10690 val_loss: 0.4554475247859955, train_loss: 0.40967902541160583\n",
            "10700 val_loss: 0.4551457464694977, train_loss: 0.40905800461769104\n",
            "10710 val_loss: 0.45450904965400696, train_loss: 0.40820562839508057\n",
            "10720 val_loss: 0.4543207287788391, train_loss: 0.4077762961387634\n",
            "10730 val_loss: 0.45428362488746643, train_loss: 0.40720078349113464\n",
            "10740 val_loss: 0.453519731760025, train_loss: 0.4062747061252594\n",
            "10750 val_loss: 0.4523228704929352, train_loss: 0.4048496186733246\n",
            "10760 val_loss: 0.4519549310207367, train_loss: 0.4041086435317993\n",
            "10770 val_loss: 0.4516274929046631, train_loss: 0.40330302715301514\n",
            "10780 val_loss: 0.45164966583251953, train_loss: 0.40288183093070984\n",
            "10790 val_loss: 0.4516115188598633, train_loss: 0.4026094079017639\n",
            "10800 val_loss: 0.45125457644462585, train_loss: 0.4019601047039032\n",
            "10810 val_loss: 0.45109036564826965, train_loss: 0.4014316499233246\n",
            "10820 val_loss: 0.45115798711776733, train_loss: 0.4011249244213104\n",
            "10830 val_loss: 0.45077288150787354, train_loss: 0.40051382780075073\n",
            "10840 val_loss: 0.4494771957397461, train_loss: 0.3988620936870575\n",
            "10850 val_loss: 0.4492718279361725, train_loss: 0.39822909235954285\n",
            "10860 val_loss: 0.44879841804504395, train_loss: 0.39750874042510986\n",
            "10870 val_loss: 0.4487832486629486, train_loss: 0.39700186252593994\n",
            "10880 val_loss: 0.44846847653388977, train_loss: 0.39656496047973633\n",
            "10890 val_loss: 0.4475758373737335, train_loss: 0.3953307271003723\n",
            "10900 val_loss: 0.4476150870323181, train_loss: 0.39500224590301514\n",
            "10910 val_loss: 0.4471626281738281, train_loss: 0.39435896277427673\n",
            "10920 val_loss: 0.4469076693058014, train_loss: 0.39331719279289246\n",
            "10930 val_loss: 0.4464173913002014, train_loss: 0.3929690420627594\n",
            "10940 val_loss: 0.4455505907535553, train_loss: 0.3916485011577606\n",
            "10950 val_loss: 0.4454651474952698, train_loss: 0.3912700414657593\n",
            "10960 val_loss: 0.4450434744358063, train_loss: 0.39031243324279785\n",
            "10970 val_loss: 0.44475069642066956, train_loss: 0.38975244760513306\n",
            "10980 val_loss: 0.44443821907043457, train_loss: 0.3891856074333191\n",
            "10990 val_loss: 0.4444115161895752, train_loss: 0.3885418176651001\n",
            "11000 val_loss: 0.4444494843482971, train_loss: 0.38860368728637695\n",
            "11010 val_loss: 0.4439266622066498, train_loss: 0.3876670002937317\n",
            "11020 val_loss: 0.4434010088443756, train_loss: 0.3868117034435272\n",
            "11030 val_loss: 0.44284892082214355, train_loss: 0.3859793543815613\n",
            "11040 val_loss: 0.44287219643592834, train_loss: 0.3855926990509033\n",
            "11050 val_loss: 0.4428955316543579, train_loss: 0.385689377784729\n",
            "11060 val_loss: 0.44246119260787964, train_loss: 0.38489586114883423\n",
            "11070 val_loss: 0.4422110617160797, train_loss: 0.38436904549598694\n",
            "11080 val_loss: 0.4419665038585663, train_loss: 0.3833896219730377\n",
            "11090 val_loss: 0.44172078371047974, train_loss: 0.38300198316574097\n",
            "11100 val_loss: 0.44126495718955994, train_loss: 0.38226500153541565\n",
            "11110 val_loss: 0.4409383535385132, train_loss: 0.38189592957496643\n",
            "11120 val_loss: 0.44040316343307495, train_loss: 0.38096246123313904\n",
            "11130 val_loss: 0.440458208322525, train_loss: 0.3806471526622772\n",
            "11140 val_loss: 0.440051794052124, train_loss: 0.38010716438293457\n",
            "11150 val_loss: 0.4398365914821625, train_loss: 0.37955716252326965\n",
            "11160 val_loss: 0.4394198954105377, train_loss: 0.37910282611846924\n",
            "11170 val_loss: 0.4390241503715515, train_loss: 0.3785537779331207\n",
            "11180 val_loss: 0.4387710988521576, train_loss: 0.37812691926956177\n",
            "11190 val_loss: 0.4386860132217407, train_loss: 0.3774963617324829\n",
            "11200 val_loss: 0.4382341504096985, train_loss: 0.37722712755203247\n",
            "11210 val_loss: 0.4379350543022156, train_loss: 0.3763607442378998\n",
            "11220 val_loss: 0.43746668100357056, train_loss: 0.3758423328399658\n",
            "11230 val_loss: 0.43702924251556396, train_loss: 0.37540462613105774\n",
            "11240 val_loss: 0.4368906021118164, train_loss: 0.37535378336906433\n",
            "11250 val_loss: 0.4363287389278412, train_loss: 0.37462180852890015\n",
            "11260 val_loss: 0.43621140718460083, train_loss: 0.37433841824531555\n",
            "11270 val_loss: 0.43547379970550537, train_loss: 0.3736971318721771\n",
            "11280 val_loss: 0.4351966381072998, train_loss: 0.3733123540878296\n",
            "11290 val_loss: 0.4350900650024414, train_loss: 0.37276265025138855\n",
            "11300 val_loss: 0.4344813823699951, train_loss: 0.37243103981018066\n",
            "11310 val_loss: 0.4342384338378906, train_loss: 0.37181371450424194\n",
            "11320 val_loss: 0.43387866020202637, train_loss: 0.3716907799243927\n",
            "11330 val_loss: 0.43361568450927734, train_loss: 0.3712306022644043\n",
            "11340 val_loss: 0.43332523107528687, train_loss: 0.37081411480903625\n",
            "11350 val_loss: 0.4331708550453186, train_loss: 0.37100911140441895\n",
            "11360 val_loss: 0.43264007568359375, train_loss: 0.37040975689888\n",
            "11370 val_loss: 0.431854248046875, train_loss: 0.3692533075809479\n",
            "11380 val_loss: 0.4316824972629547, train_loss: 0.3684294521808624\n",
            "11390 val_loss: 0.4313482940196991, train_loss: 0.3680203855037689\n",
            "11400 val_loss: 0.4308055341243744, train_loss: 0.36745452880859375\n",
            "11410 val_loss: 0.4303419589996338, train_loss: 0.3666713237762451\n",
            "11420 val_loss: 0.4301563501358032, train_loss: 0.3662738800048828\n",
            "11430 val_loss: 0.4296796917915344, train_loss: 0.3653901517391205\n",
            "11440 val_loss: 0.42941126227378845, train_loss: 0.3648090660572052\n",
            "11450 val_loss: 0.42906561493873596, train_loss: 0.36450979113578796\n",
            "11460 val_loss: 0.4286896288394928, train_loss: 0.364063024520874\n",
            "11470 val_loss: 0.4284679889678955, train_loss: 0.3636520206928253\n",
            "11480 val_loss: 0.4282780587673187, train_loss: 0.3635196387767792\n",
            "11490 val_loss: 0.42791733145713806, train_loss: 0.3629559874534607\n",
            "11500 val_loss: 0.4277670383453369, train_loss: 0.36280229687690735\n",
            "11510 val_loss: 0.4274621605873108, train_loss: 0.3623366951942444\n",
            "11520 val_loss: 0.42694222927093506, train_loss: 0.3617532551288605\n",
            "11530 val_loss: 0.4263322055339813, train_loss: 0.3610229790210724\n",
            "11540 val_loss: 0.42564913630485535, train_loss: 0.3600735664367676\n",
            "11550 val_loss: 0.4253230392932892, train_loss: 0.3594440221786499\n",
            "11560 val_loss: 0.4250093698501587, train_loss: 0.35901492834091187\n",
            "11570 val_loss: 0.4248240292072296, train_loss: 0.35895463824272156\n",
            "11580 val_loss: 0.42468321323394775, train_loss: 0.3585887849330902\n",
            "11590 val_loss: 0.4244835674762726, train_loss: 0.35800856351852417\n",
            "11600 val_loss: 0.42382916808128357, train_loss: 0.35739049315452576\n",
            "11610 val_loss: 0.4235399663448334, train_loss: 0.35665014386177063\n",
            "11620 val_loss: 0.42327994108200073, train_loss: 0.35684633255004883\n",
            "11630 val_loss: 0.42374610900878906, train_loss: 0.35730594396591187\n",
            "11640 val_loss: 0.42251914739608765, train_loss: 0.35545119643211365\n",
            "11650 val_loss: 0.42187246680259705, train_loss: 0.35492080450057983\n",
            "11660 val_loss: 0.42179998755455017, train_loss: 0.35469719767570496\n",
            "11670 val_loss: 0.4216153621673584, train_loss: 0.354280561208725\n",
            "11680 val_loss: 0.4210050106048584, train_loss: 0.35391274094581604\n",
            "11690 val_loss: 0.42081713676452637, train_loss: 0.3536668121814728\n",
            "11700 val_loss: 0.4203150272369385, train_loss: 0.3533400297164917\n",
            "11710 val_loss: 0.42001405358314514, train_loss: 0.3529275357723236\n",
            "11720 val_loss: 0.41940897703170776, train_loss: 0.3525192439556122\n",
            "11730 val_loss: 0.4191705286502838, train_loss: 0.3521714508533478\n",
            "11740 val_loss: 0.4187392294406891, train_loss: 0.35149243474006653\n",
            "11750 val_loss: 0.4186003506183624, train_loss: 0.35122621059417725\n",
            "11760 val_loss: 0.417860209941864, train_loss: 0.3501586616039276\n",
            "11770 val_loss: 0.4178628921508789, train_loss: 0.3501774072647095\n",
            "11780 val_loss: 0.4175336956977844, train_loss: 0.34986308217048645\n",
            "11790 val_loss: 0.41728490591049194, train_loss: 0.34922805428504944\n",
            "11800 val_loss: 0.4168884754180908, train_loss: 0.3491922914981842\n",
            "11810 val_loss: 0.41661152243614197, train_loss: 0.348877876996994\n",
            "11820 val_loss: 0.4158230423927307, train_loss: 0.3482148051261902\n",
            "11830 val_loss: 0.41528311371803284, train_loss: 0.34779754281044006\n",
            "11840 val_loss: 0.41551119089126587, train_loss: 0.34781816601753235\n",
            "11850 val_loss: 0.4149726331233978, train_loss: 0.34724870324134827\n",
            "11860 val_loss: 0.41487249732017517, train_loss: 0.34703516960144043\n",
            "11870 val_loss: 0.41443830728530884, train_loss: 0.34644293785095215\n",
            "11880 val_loss: 0.41399770975112915, train_loss: 0.345980703830719\n",
            "11890 val_loss: 0.4138495922088623, train_loss: 0.34570449590682983\n",
            "11900 val_loss: 0.4133797287940979, train_loss: 0.3449079990386963\n",
            "11910 val_loss: 0.41294875741004944, train_loss: 0.3446595370769501\n",
            "11920 val_loss: 0.4126238226890564, train_loss: 0.34406179189682007\n",
            "11930 val_loss: 0.41252246499061584, train_loss: 0.3441017270088196\n",
            "11940 val_loss: 0.4122178554534912, train_loss: 0.34373706579208374\n",
            "11950 val_loss: 0.411996066570282, train_loss: 0.34311628341674805\n",
            "11960 val_loss: 0.41160860657691956, train_loss: 0.34275972843170166\n",
            "11970 val_loss: 0.4118529260158539, train_loss: 0.342695951461792\n",
            "11980 val_loss: 0.4110959470272064, train_loss: 0.34214138984680176\n",
            "11990 val_loss: 0.41081055998802185, train_loss: 0.34176504611968994\n",
            "12000 val_loss: 0.4105587899684906, train_loss: 0.34136977791786194\n",
            "12010 val_loss: 0.4104646146297455, train_loss: 0.3412908911705017\n",
            "12020 val_loss: 0.4101261794567108, train_loss: 0.34090685844421387\n",
            "12030 val_loss: 0.4098196029663086, train_loss: 0.34053000807762146\n",
            "12040 val_loss: 0.40912365913391113, train_loss: 0.3395810127258301\n",
            "12050 val_loss: 0.4089301526546478, train_loss: 0.3393207788467407\n",
            "12060 val_loss: 0.408744752407074, train_loss: 0.3389696776866913\n",
            "12070 val_loss: 0.4081275165081024, train_loss: 0.3383200466632843\n",
            "12080 val_loss: 0.40785449743270874, train_loss: 0.33807143568992615\n",
            "12090 val_loss: 0.4076364040374756, train_loss: 0.3375989496707916\n",
            "12100 val_loss: 0.40747570991516113, train_loss: 0.3373871147632599\n",
            "12110 val_loss: 0.40701985359191895, train_loss: 0.33713799715042114\n",
            "12120 val_loss: 0.4066300690174103, train_loss: 0.33673396706581116\n",
            "12130 val_loss: 0.4063587188720703, train_loss: 0.33636611700057983\n",
            "12140 val_loss: 0.4060679078102112, train_loss: 0.33585792779922485\n",
            "12150 val_loss: 0.40604501962661743, train_loss: 0.3357420265674591\n",
            "12160 val_loss: 0.4058774411678314, train_loss: 0.3355737030506134\n",
            "12170 val_loss: 0.4055660665035248, train_loss: 0.33538374304771423\n",
            "12180 val_loss: 0.40551063418388367, train_loss: 0.3352908194065094\n",
            "12190 val_loss: 0.40528297424316406, train_loss: 0.3348473906517029\n",
            "12200 val_loss: 0.40441203117370605, train_loss: 0.3343336880207062\n",
            "12210 val_loss: 0.40423229336738586, train_loss: 0.3340858817100525\n",
            "12220 val_loss: 0.40420401096343994, train_loss: 0.33384817838668823\n",
            "12230 val_loss: 0.40396371483802795, train_loss: 0.33349916338920593\n",
            "12240 val_loss: 0.40385526418685913, train_loss: 0.33342790603637695\n",
            "12250 val_loss: 0.40353187918663025, train_loss: 0.33292463421821594\n",
            "12260 val_loss: 0.40302199125289917, train_loss: 0.3324582278728485\n",
            "12270 val_loss: 0.40263307094573975, train_loss: 0.3319369852542877\n",
            "12280 val_loss: 0.4028083384037018, train_loss: 0.33229944109916687\n",
            "12290 val_loss: 0.4020896255970001, train_loss: 0.3318375051021576\n",
            "12300 val_loss: 0.40204986929893494, train_loss: 0.33166277408599854\n",
            "12310 val_loss: 0.40186554193496704, train_loss: 0.331268310546875\n",
            "12320 val_loss: 0.4015417993068695, train_loss: 0.3307144045829773\n",
            "12330 val_loss: 0.4017547369003296, train_loss: 0.33045804500579834\n",
            "12340 val_loss: 0.40115007758140564, train_loss: 0.3302682638168335\n",
            "12350 val_loss: 0.40102115273475647, train_loss: 0.329916387796402\n",
            "12360 val_loss: 0.4008626341819763, train_loss: 0.32974857091903687\n",
            "12370 val_loss: 0.4003865420818329, train_loss: 0.3295716345310211\n",
            "12380 val_loss: 0.39996424317359924, train_loss: 0.32907813787460327\n",
            "12390 val_loss: 0.39961352944374084, train_loss: 0.32884711027145386\n",
            "12400 val_loss: 0.3993372321128845, train_loss: 0.32872438430786133\n",
            "12410 val_loss: 0.399308443069458, train_loss: 0.3285054862499237\n",
            "12420 val_loss: 0.3995032012462616, train_loss: 0.3284325897693634\n",
            "12430 val_loss: 0.39889761805534363, train_loss: 0.3278457224369049\n",
            "12440 val_loss: 0.3987051546573639, train_loss: 0.32741624116897583\n",
            "12450 val_loss: 0.398325651884079, train_loss: 0.3271675109863281\n",
            "12460 val_loss: 0.39830008149147034, train_loss: 0.3271256685256958\n",
            "12470 val_loss: 0.39804816246032715, train_loss: 0.3266403377056122\n",
            "12480 val_loss: 0.3975931406021118, train_loss: 0.3263396918773651\n",
            "12490 val_loss: 0.39777788519859314, train_loss: 0.326066255569458\n",
            "12500 val_loss: 0.3971403241157532, train_loss: 0.3256624639034271\n",
            "12510 val_loss: 0.3975111246109009, train_loss: 0.32561013102531433\n",
            "12520 val_loss: 0.3967708945274353, train_loss: 0.3249945640563965\n",
            "12530 val_loss: 0.39629894495010376, train_loss: 0.324697345495224\n",
            "12540 val_loss: 0.39681148529052734, train_loss: 0.32481101155281067\n",
            "12550 val_loss: 0.3963790237903595, train_loss: 0.32470735907554626\n",
            "12560 val_loss: 0.39627406001091003, train_loss: 0.32408589124679565\n",
            "12570 val_loss: 0.3958646357059479, train_loss: 0.32376039028167725\n",
            "12580 val_loss: 0.39550358057022095, train_loss: 0.32341527938842773\n",
            "12590 val_loss: 0.395377516746521, train_loss: 0.32335203886032104\n",
            "12600 val_loss: 0.3951512277126312, train_loss: 0.3231446146965027\n",
            "12610 val_loss: 0.39444205164909363, train_loss: 0.3226066827774048\n",
            "12620 val_loss: 0.3943931460380554, train_loss: 0.32251596450805664\n",
            "12630 val_loss: 0.394096702337265, train_loss: 0.3222765624523163\n",
            "12640 val_loss: 0.39389368891716003, train_loss: 0.3221416175365448\n",
            "12650 val_loss: 0.3938860297203064, train_loss: 0.3218438923358917\n",
            "12660 val_loss: 0.39363306760787964, train_loss: 0.3216508626937866\n",
            "12670 val_loss: 0.39350515604019165, train_loss: 0.32121899724006653\n",
            "12680 val_loss: 0.39334923028945923, train_loss: 0.3208298087120056\n",
            "12690 val_loss: 0.3928455710411072, train_loss: 0.3203851878643036\n",
            "12700 val_loss: 0.39255601167678833, train_loss: 0.3201199471950531\n",
            "12710 val_loss: 0.3925003707408905, train_loss: 0.31982430815696716\n",
            "12720 val_loss: 0.3919426500797272, train_loss: 0.3194012939929962\n",
            "12730 val_loss: 0.3915475308895111, train_loss: 0.318866491317749\n",
            "12740 val_loss: 0.39158254861831665, train_loss: 0.31887587904930115\n",
            "12750 val_loss: 0.39156782627105713, train_loss: 0.31864458322525024\n",
            "12760 val_loss: 0.3915606439113617, train_loss: 0.3185907006263733\n",
            "12770 val_loss: 0.39173856377601624, train_loss: 0.31891462206840515\n",
            "12780 val_loss: 0.39045289158821106, train_loss: 0.31780409812927246\n",
            "12790 val_loss: 0.3902631103992462, train_loss: 0.3176712393760681\n",
            "12800 val_loss: 0.3899497985839844, train_loss: 0.317295640707016\n",
            "12810 val_loss: 0.3897891640663147, train_loss: 0.3169448673725128\n",
            "12820 val_loss: 0.3897383213043213, train_loss: 0.3166405260562897\n",
            "12830 val_loss: 0.38914698362350464, train_loss: 0.3163002133369446\n",
            "12840 val_loss: 0.3889434039592743, train_loss: 0.315700501203537\n",
            "12850 val_loss: 0.3884822428226471, train_loss: 0.3153001368045807\n",
            "12860 val_loss: 0.388553261756897, train_loss: 0.31504419445991516\n",
            "12870 val_loss: 0.3884260654449463, train_loss: 0.31510674953460693\n",
            "12880 val_loss: 0.3883919417858124, train_loss: 0.3151338994503021\n",
            "12890 val_loss: 0.3880213797092438, train_loss: 0.31479910016059875\n",
            "12900 val_loss: 0.38762420415878296, train_loss: 0.31403425335884094\n",
            "12910 val_loss: 0.387947678565979, train_loss: 0.314136266708374\n",
            "12920 val_loss: 0.387001633644104, train_loss: 0.31338071823120117\n",
            "12930 val_loss: 0.38656729459762573, train_loss: 0.31305477023124695\n",
            "12940 val_loss: 0.3864378333091736, train_loss: 0.3128776252269745\n",
            "12950 val_loss: 0.3862226903438568, train_loss: 0.3130214810371399\n",
            "12960 val_loss: 0.38577303290367126, train_loss: 0.3122861385345459\n",
            "12970 val_loss: 0.38550955057144165, train_loss: 0.3120034337043762\n",
            "12980 val_loss: 0.38574182987213135, train_loss: 0.31196129322052\n",
            "12990 val_loss: 0.3849903643131256, train_loss: 0.3112814128398895\n",
            "13000 val_loss: 0.38482725620269775, train_loss: 0.3111666440963745\n",
            "13010 val_loss: 0.38485631346702576, train_loss: 0.3108972907066345\n",
            "13020 val_loss: 0.3843660354614258, train_loss: 0.3101635277271271\n",
            "13030 val_loss: 0.38415977358818054, train_loss: 0.3100704550743103\n",
            "13040 val_loss: 0.3836241662502289, train_loss: 0.3097013831138611\n",
            "13050 val_loss: 0.38365572690963745, train_loss: 0.30963441729545593\n",
            "13060 val_loss: 0.3832119107246399, train_loss: 0.3092085123062134\n",
            "13070 val_loss: 0.3827524781227112, train_loss: 0.30871954560279846\n",
            "13080 val_loss: 0.382990300655365, train_loss: 0.3087341785430908\n",
            "13090 val_loss: 0.3824206292629242, train_loss: 0.3082907795906067\n",
            "13100 val_loss: 0.38201653957366943, train_loss: 0.30804476141929626\n",
            "13110 val_loss: 0.38206982612609863, train_loss: 0.307903528213501\n",
            "13120 val_loss: 0.3821190297603607, train_loss: 0.30770689249038696\n",
            "13130 val_loss: 0.3819279372692108, train_loss: 0.30772992968559265\n",
            "13140 val_loss: 0.38166600465774536, train_loss: 0.3073650598526001\n",
            "13150 val_loss: 0.3812907934188843, train_loss: 0.30685359239578247\n",
            "13160 val_loss: 0.38101285696029663, train_loss: 0.3064970076084137\n",
            "13170 val_loss: 0.3806374967098236, train_loss: 0.3063240349292755\n",
            "13180 val_loss: 0.38043323159217834, train_loss: 0.3059190511703491\n",
            "13190 val_loss: 0.3803570568561554, train_loss: 0.3056902289390564\n",
            "13200 val_loss: 0.3799624741077423, train_loss: 0.3053232729434967\n",
            "13210 val_loss: 0.37969478964805603, train_loss: 0.30504661798477173\n",
            "13220 val_loss: 0.3796875476837158, train_loss: 0.30490708351135254\n",
            "13230 val_loss: 0.37917229533195496, train_loss: 0.3044907748699188\n",
            "13240 val_loss: 0.37885168194770813, train_loss: 0.30413585901260376\n",
            "13250 val_loss: 0.3787922263145447, train_loss: 0.3043093979358673\n",
            "13260 val_loss: 0.37842515110969543, train_loss: 0.30400651693344116\n",
            "13270 val_loss: 0.37786075472831726, train_loss: 0.3035193383693695\n",
            "13280 val_loss: 0.37794965505599976, train_loss: 0.30340105295181274\n",
            "13290 val_loss: 0.3774508833885193, train_loss: 0.3029550015926361\n",
            "13300 val_loss: 0.37756478786468506, train_loss: 0.30276522040367126\n",
            "13310 val_loss: 0.3770979046821594, train_loss: 0.3023228943347931\n",
            "13320 val_loss: 0.37697115540504456, train_loss: 0.30218952894210815\n",
            "13330 val_loss: 0.3768661618232727, train_loss: 0.30205586552619934\n",
            "13340 val_loss: 0.3765963912010193, train_loss: 0.30156660079956055\n",
            "13350 val_loss: 0.37639036774635315, train_loss: 0.30134138464927673\n",
            "13360 val_loss: 0.37613192200660706, train_loss: 0.30076971650123596\n",
            "13370 val_loss: 0.376235693693161, train_loss: 0.30098646879196167\n",
            "13380 val_loss: 0.37615177035331726, train_loss: 0.30072253942489624\n",
            "13390 val_loss: 0.37572887539863586, train_loss: 0.3004097640514374\n",
            "13400 val_loss: 0.37580862641334534, train_loss: 0.30038902163505554\n",
            "13410 val_loss: 0.3749387264251709, train_loss: 0.299498975276947\n",
            "13420 val_loss: 0.374515175819397, train_loss: 0.2989502251148224\n",
            "13430 val_loss: 0.3745705485343933, train_loss: 0.29886165261268616\n",
            "13440 val_loss: 0.3744882047176361, train_loss: 0.29898005723953247\n",
            "13450 val_loss: 0.3743346333503723, train_loss: 0.2988182306289673\n",
            "13460 val_loss: 0.3738836646080017, train_loss: 0.29815250635147095\n",
            "13470 val_loss: 0.3740166127681732, train_loss: 0.2983051538467407\n",
            "13480 val_loss: 0.3737037181854248, train_loss: 0.298088401556015\n",
            "13490 val_loss: 0.37312930822372437, train_loss: 0.29736611247062683\n",
            "13500 val_loss: 0.3729596436023712, train_loss: 0.29703912138938904\n",
            "13510 val_loss: 0.37279370427131653, train_loss: 0.2970196306705475\n",
            "13520 val_loss: 0.3726707696914673, train_loss: 0.29664525389671326\n",
            "13530 val_loss: 0.3726377487182617, train_loss: 0.29645824432373047\n",
            "13540 val_loss: 0.3727084696292877, train_loss: 0.29669255018234253\n",
            "13550 val_loss: 0.3720496594905853, train_loss: 0.2962021231651306\n",
            "13560 val_loss: 0.37177929282188416, train_loss: 0.296011358499527\n",
            "13570 val_loss: 0.3716318905353546, train_loss: 0.29588550329208374\n",
            "13580 val_loss: 0.3717864751815796, train_loss: 0.29585370421409607\n",
            "13590 val_loss: 0.37114307284355164, train_loss: 0.2955472767353058\n",
            "13600 val_loss: 0.37123751640319824, train_loss: 0.2950913608074188\n",
            "13610 val_loss: 0.3707433044910431, train_loss: 0.29476234316825867\n",
            "13620 val_loss: 0.37053540349006653, train_loss: 0.2945311963558197\n",
            "13630 val_loss: 0.37090954184532166, train_loss: 0.2948054373264313\n",
            "13640 val_loss: 0.3704145848751068, train_loss: 0.29457640647888184\n",
            "13650 val_loss: 0.37006300687789917, train_loss: 0.29416632652282715\n",
            "13660 val_loss: 0.37003764510154724, train_loss: 0.29404348134994507\n",
            "13670 val_loss: 0.36979517340660095, train_loss: 0.29375866055488586\n",
            "13680 val_loss: 0.3694016933441162, train_loss: 0.29346299171447754\n",
            "13690 val_loss: 0.3694477379322052, train_loss: 0.2932279109954834\n",
            "13700 val_loss: 0.36947736144065857, train_loss: 0.29310208559036255\n",
            "13710 val_loss: 0.3690944314002991, train_loss: 0.2927118241786957\n",
            "13720 val_loss: 0.36886274814605713, train_loss: 0.2925979197025299\n",
            "13730 val_loss: 0.36863523721694946, train_loss: 0.29247382283210754\n",
            "13740 val_loss: 0.36837613582611084, train_loss: 0.29207316040992737\n",
            "13750 val_loss: 0.36829671263694763, train_loss: 0.2916921079158783\n",
            "13760 val_loss: 0.3681707978248596, train_loss: 0.2916858196258545\n",
            "13770 val_loss: 0.36787334084510803, train_loss: 0.29114776849746704\n",
            "13780 val_loss: 0.3677079677581787, train_loss: 0.2907865345478058\n",
            "13790 val_loss: 0.3676317632198334, train_loss: 0.29061752557754517\n",
            "13800 val_loss: 0.36752671003341675, train_loss: 0.29066452383995056\n",
            "13810 val_loss: 0.3674580156803131, train_loss: 0.29061800241470337\n",
            "13820 val_loss: 0.3680346608161926, train_loss: 0.2912035584449768\n",
            "13830 val_loss: 0.367146372795105, train_loss: 0.2900317907333374\n",
            "13840 val_loss: 0.3667459487915039, train_loss: 0.28965699672698975\n",
            "13850 val_loss: 0.36650973558425903, train_loss: 0.28942152857780457\n",
            "13860 val_loss: 0.3664473593235016, train_loss: 0.28931424021720886\n",
            "13870 val_loss: 0.3660341799259186, train_loss: 0.28880470991134644\n",
            "13880 val_loss: 0.365966796875, train_loss: 0.2885626256465912\n",
            "13890 val_loss: 0.3659537732601166, train_loss: 0.288846492767334\n",
            "13900 val_loss: 0.3655509352684021, train_loss: 0.2883211374282837\n",
            "13910 val_loss: 0.3653787672519684, train_loss: 0.2881242036819458\n",
            "13920 val_loss: 0.3651036024093628, train_loss: 0.2879394590854645\n",
            "13930 val_loss: 0.3648885488510132, train_loss: 0.2879839837551117\n",
            "13940 val_loss: 0.36487746238708496, train_loss: 0.28814083337783813\n",
            "13950 val_loss: 0.3646867871284485, train_loss: 0.287258118391037\n",
            "13960 val_loss: 0.364192396402359, train_loss: 0.2869737148284912\n",
            "13970 val_loss: 0.36353984475135803, train_loss: 0.28631797432899475\n",
            "13980 val_loss: 0.36397773027420044, train_loss: 0.28655532002449036\n",
            "13990 val_loss: 0.36371076107025146, train_loss: 0.286337286233902\n",
            "14000 val_loss: 0.3638460636138916, train_loss: 0.28631123900413513\n",
            "14010 val_loss: 0.36326271295547485, train_loss: 0.28588780760765076\n",
            "14020 val_loss: 0.36313551664352417, train_loss: 0.28589367866516113\n",
            "14030 val_loss: 0.3632335364818573, train_loss: 0.2859143912792206\n",
            "14040 val_loss: 0.36301764845848083, train_loss: 0.2857308089733124\n",
            "14050 val_loss: 0.3630337715148926, train_loss: 0.285346120595932\n",
            "14060 val_loss: 0.3624173700809479, train_loss: 0.2849321961402893\n",
            "14070 val_loss: 0.36263424158096313, train_loss: 0.28494730591773987\n",
            "14080 val_loss: 0.36226749420166016, train_loss: 0.28470221161842346\n",
            "14090 val_loss: 0.36180540919303894, train_loss: 0.2842216193675995\n",
            "14100 val_loss: 0.3624991774559021, train_loss: 0.2850663661956787\n",
            "14110 val_loss: 0.3621640205383301, train_loss: 0.2844338119029999\n",
            "14120 val_loss: 0.36151885986328125, train_loss: 0.2836402952671051\n",
            "14130 val_loss: 0.3611639142036438, train_loss: 0.28313079476356506\n",
            "14140 val_loss: 0.36099010705947876, train_loss: 0.2831340432167053\n",
            "14150 val_loss: 0.36056098341941833, train_loss: 0.28296634554862976\n",
            "14160 val_loss: 0.36034658551216125, train_loss: 0.28250932693481445\n",
            "14170 val_loss: 0.3602536618709564, train_loss: 0.2822840213775635\n",
            "14180 val_loss: 0.36006051301956177, train_loss: 0.28184860944747925\n",
            "14190 val_loss: 0.3601301312446594, train_loss: 0.28200629353523254\n",
            "14200 val_loss: 0.35947680473327637, train_loss: 0.28120094537734985\n",
            "14210 val_loss: 0.3594803810119629, train_loss: 0.28130999207496643\n",
            "14220 val_loss: 0.35923638939857483, train_loss: 0.2807905673980713\n",
            "14230 val_loss: 0.3591318726539612, train_loss: 0.2809288799762726\n",
            "14240 val_loss: 0.3591817021369934, train_loss: 0.28070488572120667\n",
            "14250 val_loss: 0.3592011034488678, train_loss: 0.28061360120773315\n",
            "14260 val_loss: 0.3591059148311615, train_loss: 0.28066393733024597\n",
            "14270 val_loss: 0.3594992160797119, train_loss: 0.28074416518211365\n",
            "14280 val_loss: 0.3583318591117859, train_loss: 0.27996543049812317\n",
            "14290 val_loss: 0.3590071201324463, train_loss: 0.280239462852478\n",
            "14300 val_loss: 0.3579072058200836, train_loss: 0.2796706259250641\n",
            "14310 val_loss: 0.3577117621898651, train_loss: 0.2794620096683502\n",
            "14320 val_loss: 0.3577669560909271, train_loss: 0.27962175011634827\n",
            "14330 val_loss: 0.3576403558254242, train_loss: 0.27894410490989685\n",
            "14340 val_loss: 0.35779833793640137, train_loss: 0.2786218822002411\n",
            "14350 val_loss: 0.35714831948280334, train_loss: 0.2781465947628021\n",
            "14360 val_loss: 0.35721033811569214, train_loss: 0.2778239846229553\n",
            "14370 val_loss: 0.3571820557117462, train_loss: 0.27734118700027466\n",
            "14380 val_loss: 0.35707327723503113, train_loss: 0.27732765674591064\n",
            "14390 val_loss: 0.3569399118423462, train_loss: 0.27702823281288147\n",
            "14400 val_loss: 0.357135534286499, train_loss: 0.2774258553981781\n",
            "14410 val_loss: 0.35662028193473816, train_loss: 0.27688291668891907\n",
            "14420 val_loss: 0.3563271164894104, train_loss: 0.27662912011146545\n",
            "14430 val_loss: 0.3567781448364258, train_loss: 0.2771120071411133\n",
            "14440 val_loss: 0.3566809892654419, train_loss: 0.2772997319698334\n",
            "14450 val_loss: 0.3564104735851288, train_loss: 0.2766197621822357\n",
            "14460 val_loss: 0.3562659025192261, train_loss: 0.27669665217399597\n",
            "14470 val_loss: 0.3558849096298218, train_loss: 0.27608543634414673\n",
            "14480 val_loss: 0.35579586029052734, train_loss: 0.2760966420173645\n",
            "14490 val_loss: 0.35552817583084106, train_loss: 0.27558204531669617\n",
            "14500 val_loss: 0.3552960753440857, train_loss: 0.2755320072174072\n",
            "14510 val_loss: 0.3549497425556183, train_loss: 0.2749501168727875\n",
            "14520 val_loss: 0.3550291955471039, train_loss: 0.27494654059410095\n",
            "14530 val_loss: 0.35472550988197327, train_loss: 0.27458950877189636\n",
            "14540 val_loss: 0.3548155426979065, train_loss: 0.2740229070186615\n",
            "14550 val_loss: 0.3547596037387848, train_loss: 0.2742139399051666\n",
            "14560 val_loss: 0.35450732707977295, train_loss: 0.2739262580871582\n",
            "14570 val_loss: 0.3545658588409424, train_loss: 0.27331873774528503\n",
            "14580 val_loss: 0.3542133867740631, train_loss: 0.27305668592453003\n",
            "14590 val_loss: 0.3541797995567322, train_loss: 0.2729038596153259\n",
            "14600 val_loss: 0.3546714782714844, train_loss: 0.2729874551296234\n",
            "14610 val_loss: 0.354306161403656, train_loss: 0.27245721220970154\n",
            "14620 val_loss: 0.3543229103088379, train_loss: 0.27240291237831116\n",
            "14630 val_loss: 0.35373005270957947, train_loss: 0.2722108066082001\n",
            "14640 val_loss: 0.3535853326320648, train_loss: 0.2717823386192322\n",
            "14650 val_loss: 0.3535441756248474, train_loss: 0.2718632221221924\n",
            "14660 val_loss: 0.3536566197872162, train_loss: 0.2712215185165405\n",
            "14670 val_loss: 0.3531509041786194, train_loss: 0.27076467871665955\n",
            "14680 val_loss: 0.35270971059799194, train_loss: 0.2705516815185547\n",
            "14690 val_loss: 0.3528648018836975, train_loss: 0.27026471495628357\n",
            "14700 val_loss: 0.35266536474227905, train_loss: 0.26976341009140015\n",
            "14710 val_loss: 0.3523695468902588, train_loss: 0.26948481798171997\n",
            "14720 val_loss: 0.3528456389904022, train_loss: 0.26922205090522766\n",
            "14730 val_loss: 0.35209545493125916, train_loss: 0.2689019739627838\n",
            "14740 val_loss: 0.35192522406578064, train_loss: 0.2690737247467041\n",
            "14750 val_loss: 0.3530803322792053, train_loss: 0.2689621150493622\n",
            "14760 val_loss: 0.35250839591026306, train_loss: 0.2682751715183258\n",
            "14770 val_loss: 0.35166192054748535, train_loss: 0.26803502440452576\n",
            "14780 val_loss: 0.3518005609512329, train_loss: 0.2681382894515991\n",
            "14790 val_loss: 0.35154277086257935, train_loss: 0.2679362893104553\n",
            "14800 val_loss: 0.3519937992095947, train_loss: 0.26774996519088745\n",
            "14810 val_loss: 0.35144007205963135, train_loss: 0.2673005163669586\n",
            "14820 val_loss: 0.3513902425765991, train_loss: 0.26676490902900696\n",
            "14830 val_loss: 0.35127273201942444, train_loss: 0.26652419567108154\n",
            "14840 val_loss: 0.3508368134498596, train_loss: 0.2659737765789032\n",
            "14850 val_loss: 0.35102325677871704, train_loss: 0.2657468020915985\n",
            "14860 val_loss: 0.35083457827568054, train_loss: 0.26537027955055237\n",
            "14870 val_loss: 0.3502768874168396, train_loss: 0.2649034857749939\n",
            "14880 val_loss: 0.35011425614356995, train_loss: 0.26487284898757935\n",
            "14890 val_loss: 0.35009676218032837, train_loss: 0.26453056931495667\n",
            "14900 val_loss: 0.35098209977149963, train_loss: 0.2646852433681488\n",
            "14910 val_loss: 0.35041946172714233, train_loss: 0.26434141397476196\n",
            "14920 val_loss: 0.35041388869285583, train_loss: 0.26415714621543884\n",
            "14930 val_loss: 0.35002627968788147, train_loss: 0.2633166015148163\n",
            "14940 val_loss: 0.34945759177207947, train_loss: 0.26323196291923523\n",
            "14950 val_loss: 0.3495188057422638, train_loss: 0.263334184885025\n",
            "14960 val_loss: 0.34980568289756775, train_loss: 0.26292598247528076\n",
            "14970 val_loss: 0.3492588996887207, train_loss: 0.2625735402107239\n",
            "14980 val_loss: 0.34887734055519104, train_loss: 0.2624717950820923\n",
            "14990 val_loss: 0.34925392270088196, train_loss: 0.2622978389263153\n",
            "15000 val_loss: 0.3495140075683594, train_loss: 0.262467622756958\n",
            "15010 val_loss: 0.34867191314697266, train_loss: 0.2621055245399475\n",
            "15020 val_loss: 0.3488820195198059, train_loss: 0.2621595859527588\n",
            "15030 val_loss: 0.3489506244659424, train_loss: 0.26264938712120056\n",
            "15040 val_loss: 0.34833860397338867, train_loss: 0.26158127188682556\n",
            "15050 val_loss: 0.3491208851337433, train_loss: 0.26126348972320557\n",
            "15060 val_loss: 0.34805792570114136, train_loss: 0.26079005002975464\n",
            "15070 val_loss: 0.34857258200645447, train_loss: 0.26030755043029785\n",
            "15080 val_loss: 0.3482518792152405, train_loss: 0.26001042127609253\n",
            "15090 val_loss: 0.34861698746681213, train_loss: 0.25988078117370605\n",
            "15100 val_loss: 0.3482113480567932, train_loss: 0.2594371438026428\n",
            "15110 val_loss: 0.3475041687488556, train_loss: 0.2589927315711975\n",
            "15120 val_loss: 0.3473115861415863, train_loss: 0.25887876749038696\n",
            "15130 val_loss: 0.34687328338623047, train_loss: 0.2583363652229309\n",
            "15140 val_loss: 0.34721770882606506, train_loss: 0.25801026821136475\n",
            "15150 val_loss: 0.3470768630504608, train_loss: 0.2578871250152588\n",
            "15160 val_loss: 0.34734243154525757, train_loss: 0.25791412591934204\n",
            "15170 val_loss: 0.3468521237373352, train_loss: 0.257325679063797\n",
            "15180 val_loss: 0.34655117988586426, train_loss: 0.25689688324928284\n",
            "15190 val_loss: 0.34629419445991516, train_loss: 0.2566756308078766\n",
            "15200 val_loss: 0.3464578092098236, train_loss: 0.25654730200767517\n",
            "15210 val_loss: 0.3462502956390381, train_loss: 0.25633788108825684\n",
            "15220 val_loss: 0.3457644283771515, train_loss: 0.2560989260673523\n",
            "15230 val_loss: 0.3462051749229431, train_loss: 0.2560911476612091\n",
            "15240 val_loss: 0.34575822949409485, train_loss: 0.2558535933494568\n",
            "15250 val_loss: 0.3455278277397156, train_loss: 0.255541056394577\n",
            "15260 val_loss: 0.3458373546600342, train_loss: 0.25544607639312744\n",
            "15270 val_loss: 0.34628036618232727, train_loss: 0.2552379071712494\n",
            "15280 val_loss: 0.3457520008087158, train_loss: 0.25484800338745117\n",
            "15290 val_loss: 0.34560972452163696, train_loss: 0.2543592154979706\n",
            "15300 val_loss: 0.347001850605011, train_loss: 0.25523877143859863\n",
            "15310 val_loss: 0.34558579325675964, train_loss: 0.2543940246105194\n",
            "15320 val_loss: 0.34574759006500244, train_loss: 0.2544080317020416\n",
            "15330 val_loss: 0.3447958528995514, train_loss: 0.2538894712924957\n",
            "15340 val_loss: 0.34499019384384155, train_loss: 0.2535785138607025\n",
            "15350 val_loss: 0.3458210229873657, train_loss: 0.2539893686771393\n",
            "15360 val_loss: 0.3442676067352295, train_loss: 0.2527424097061157\n",
            "15370 val_loss: 0.34402942657470703, train_loss: 0.2525239884853363\n",
            "15380 val_loss: 0.34473738074302673, train_loss: 0.253000408411026\n",
            "15390 val_loss: 0.3442701995372772, train_loss: 0.2523513436317444\n",
            "15400 val_loss: 0.3457072675228119, train_loss: 0.25310665369033813\n",
            "15410 val_loss: 0.34469735622406006, train_loss: 0.2522871196269989\n",
            "15420 val_loss: 0.34406331181526184, train_loss: 0.25141438841819763\n",
            "15430 val_loss: 0.34327954053878784, train_loss: 0.25103554129600525\n",
            "15440 val_loss: 0.34297141432762146, train_loss: 0.25096800923347473\n",
            "15450 val_loss: 0.34371230006217957, train_loss: 0.2504291832447052\n",
            "15460 val_loss: 0.3431773781776428, train_loss: 0.25033751130104065\n",
            "15470 val_loss: 0.34396156668663025, train_loss: 0.2500331997871399\n",
            "15480 val_loss: 0.3439455032348633, train_loss: 0.24991562962532043\n",
            "15490 val_loss: 0.3433524966239929, train_loss: 0.24942487478256226\n",
            "15500 val_loss: 0.3452679514884949, train_loss: 0.2498914748430252\n",
            "15510 val_loss: 0.3430315852165222, train_loss: 0.24879245460033417\n",
            "15520 val_loss: 0.3428787589073181, train_loss: 0.24865417182445526\n",
            "15530 val_loss: 0.3431242108345032, train_loss: 0.24844510853290558\n",
            "15540 val_loss: 0.3432760238647461, train_loss: 0.2482876032590866\n",
            "15550 val_loss: 0.3458302915096283, train_loss: 0.2484736293554306\n",
            "15560 val_loss: 0.34343236684799194, train_loss: 0.24716217815876007\n",
            "15570 val_loss: 0.34279072284698486, train_loss: 0.24649353325366974\n",
            "15580 val_loss: 0.342639684677124, train_loss: 0.24607275426387787\n",
            "15590 val_loss: 0.3440992534160614, train_loss: 0.24604766070842743\n",
            "15600 val_loss: 0.3416590094566345, train_loss: 0.24545753002166748\n",
            "15610 val_loss: 0.34235531091690063, train_loss: 0.2447413057088852\n",
            "15620 val_loss: 0.34176355600357056, train_loss: 0.24455326795578003\n",
            "15630 val_loss: 0.3434862494468689, train_loss: 0.24517467617988586\n",
            "15640 val_loss: 0.3442649245262146, train_loss: 0.24491353332996368\n",
            "15650 val_loss: 0.34096047282218933, train_loss: 0.24430401623249054\n",
            "15660 val_loss: 0.3407716453075409, train_loss: 0.24352630972862244\n",
            "15670 val_loss: 0.34086886048316956, train_loss: 0.2434937208890915\n",
            "15680 val_loss: 0.3410482406616211, train_loss: 0.24334271252155304\n",
            "15690 val_loss: 0.3400123715400696, train_loss: 0.2437582165002823\n",
            "15700 val_loss: 0.34078970551490784, train_loss: 0.2427876591682434\n",
            "15710 val_loss: 0.34189921617507935, train_loss: 0.24280980229377747\n",
            "15720 val_loss: 0.34059014916419983, train_loss: 0.2422301471233368\n",
            "15730 val_loss: 0.3403383493423462, train_loss: 0.2428206354379654\n",
            "15740 val_loss: 0.3429315388202667, train_loss: 0.24243518710136414\n",
            "15750 val_loss: 0.34153562784194946, train_loss: 0.24221332371234894\n",
            "15760 val_loss: 0.3405568301677704, train_loss: 0.24187391996383667\n",
            "15770 val_loss: 0.3408850133419037, train_loss: 0.24162526428699493\n",
            "15780 val_loss: 0.34067147970199585, train_loss: 0.24155433475971222\n",
            "15790 val_loss: 0.34053903818130493, train_loss: 0.24123655259609222\n",
            "15800 val_loss: 0.341164767742157, train_loss: 0.24100588262081146\n",
            "15810 val_loss: 0.3397717773914337, train_loss: 0.24050331115722656\n",
            "15820 val_loss: 0.3415995240211487, train_loss: 0.2409389615058899\n",
            "15830 val_loss: 0.3402629494667053, train_loss: 0.24016518890857697\n",
            "15840 val_loss: 0.3417876660823822, train_loss: 0.24034270644187927\n",
            "15850 val_loss: 0.3396749198436737, train_loss: 0.2396528720855713\n",
            "15860 val_loss: 0.3417297303676605, train_loss: 0.23998096585273743\n",
            "15870 val_loss: 0.3402290940284729, train_loss: 0.23942548036575317\n",
            "15880 val_loss: 0.34084105491638184, train_loss: 0.23935078084468842\n",
            "15890 val_loss: 0.3391993045806885, train_loss: 0.23873215913772583\n",
            "15900 val_loss: 0.3407396078109741, train_loss: 0.2388334423303604\n",
            "15910 val_loss: 0.3412136435508728, train_loss: 0.23843306303024292\n",
            "15920 val_loss: 0.33968815207481384, train_loss: 0.2378803938627243\n",
            "15930 val_loss: 0.34075525403022766, train_loss: 0.23777665197849274\n",
            "15940 val_loss: 0.33889040350914, train_loss: 0.23745396733283997\n",
            "15950 val_loss: 0.3390670120716095, train_loss: 0.23677179217338562\n",
            "15960 val_loss: 0.3387413024902344, train_loss: 0.2365427017211914\n",
            "15970 val_loss: 0.3385131359100342, train_loss: 0.23639829456806183\n",
            "15980 val_loss: 0.33903768658638, train_loss: 0.2362765073776245\n",
            "15990 val_loss: 0.3377266526222229, train_loss: 0.23556292057037354\n",
            "16000 val_loss: 0.33716800808906555, train_loss: 0.23574793338775635\n",
            "16010 val_loss: 0.33771273493766785, train_loss: 0.23535431921482086\n",
            "16020 val_loss: 0.33692702651023865, train_loss: 0.23522642254829407\n",
            "16030 val_loss: 0.3376825749874115, train_loss: 0.2353305220603943\n",
            "16040 val_loss: 0.3385642468929291, train_loss: 0.2344110906124115\n",
            "16050 val_loss: 0.3377785086631775, train_loss: 0.23395545780658722\n",
            "16060 val_loss: 0.33965662121772766, train_loss: 0.2342471331357956\n",
            "16070 val_loss: 0.3385125696659088, train_loss: 0.23350666463375092\n",
            "16080 val_loss: 0.34053274989128113, train_loss: 0.23357117176055908\n",
            "16090 val_loss: 0.33942705392837524, train_loss: 0.23260599374771118\n",
            "16100 val_loss: 0.3396843671798706, train_loss: 0.2324778288602829\n",
            "16110 val_loss: 0.3403981029987335, train_loss: 0.23237639665603638\n",
            "16120 val_loss: 0.3391447961330414, train_loss: 0.23183579742908478\n",
            "16130 val_loss: 0.3387066125869751, train_loss: 0.23134920001029968\n",
            "16140 val_loss: 0.34081387519836426, train_loss: 0.2316068708896637\n",
            "16150 val_loss: 0.3423299193382263, train_loss: 0.23161250352859497\n",
            "16160 val_loss: 0.340010404586792, train_loss: 0.23043131828308105\n",
            "16170 val_loss: 0.339223712682724, train_loss: 0.23013371229171753\n",
            "16180 val_loss: 0.3426242470741272, train_loss: 0.23015007376670837\n",
            "16190 val_loss: 0.3407406508922577, train_loss: 0.22976669669151306\n",
            "16200 val_loss: 0.3392414152622223, train_loss: 0.2296939194202423\n",
            "16210 val_loss: 0.34283873438835144, train_loss: 0.22994104027748108\n",
            "16220 val_loss: 0.3418115973472595, train_loss: 0.22927698493003845\n",
            "16230 val_loss: 0.3382861614227295, train_loss: 0.22846050560474396\n",
            "16240 val_loss: 0.3386431336402893, train_loss: 0.22826771438121796\n",
            "16250 val_loss: 0.33940958976745605, train_loss: 0.22707030177116394\n",
            "16260 val_loss: 0.34243112802505493, train_loss: 0.227028489112854\n",
            "16270 val_loss: 0.33789509534835815, train_loss: 0.22604918479919434\n",
            "16280 val_loss: 0.3426275849342346, train_loss: 0.22666503489017487\n",
            "16290 val_loss: 0.3401394784450531, train_loss: 0.22607439756393433\n",
            "16300 val_loss: 0.33848676085472107, train_loss: 0.22575335204601288\n",
            "16310 val_loss: 0.3363036513328552, train_loss: 0.22570329904556274\n",
            "16320 val_loss: 0.35149556398391724, train_loss: 0.2284420132637024\n",
            "16330 val_loss: 0.3451630175113678, train_loss: 0.22546744346618652\n",
            "16340 val_loss: 0.3404124975204468, train_loss: 0.22430847585201263\n",
            "16350 val_loss: 0.34480297565460205, train_loss: 0.22500209510326385\n",
            "16360 val_loss: 0.3410193920135498, train_loss: 0.22346921265125275\n",
            "16370 val_loss: 0.3403090238571167, train_loss: 0.2237279713153839\n",
            "16380 val_loss: 0.3397400677204132, train_loss: 0.22257697582244873\n",
            "16390 val_loss: 0.34053319692611694, train_loss: 0.22239556908607483\n",
            "16400 val_loss: 0.3471549451351166, train_loss: 0.2242225706577301\n",
            "16410 val_loss: 0.33793944120407104, train_loss: 0.22178542613983154\n",
            "16420 val_loss: 0.3396364748477936, train_loss: 0.22170549631118774\n",
            "16430 val_loss: 0.3363993167877197, train_loss: 0.22115842998027802\n",
            "16440 val_loss: 0.34818994998931885, train_loss: 0.22318661212921143\n",
            "16450 val_loss: 0.3340047597885132, train_loss: 0.22123019397258759\n",
            "16460 val_loss: 0.33599555492401123, train_loss: 0.22040200233459473\n",
            "16470 val_loss: 0.33797791600227356, train_loss: 0.22016100585460663\n",
            "16480 val_loss: 0.3374403715133667, train_loss: 0.2195180207490921\n",
            "16490 val_loss: 0.33636224269866943, train_loss: 0.2194807082414627\n",
            "16500 val_loss: 0.33435699343681335, train_loss: 0.21922746300697327\n",
            "16510 val_loss: 0.3353670835494995, train_loss: 0.21895535290241241\n",
            "16520 val_loss: 0.3431989252567291, train_loss: 0.22020576894283295\n",
            "16530 val_loss: 0.33614906668663025, train_loss: 0.21818168461322784\n",
            "16540 val_loss: 0.3378641605377197, train_loss: 0.2176467478275299\n",
            "16550 val_loss: 0.3429584801197052, train_loss: 0.21866212785243988\n",
            "16560 val_loss: 0.33459025621414185, train_loss: 0.2172815203666687\n",
            "16570 val_loss: 0.33430594205856323, train_loss: 0.21689896285533905\n",
            "16580 val_loss: 0.3373841643333435, train_loss: 0.21709135174751282\n",
            "16590 val_loss: 0.3409733176231384, train_loss: 0.21752454340457916\n",
            "16600 val_loss: 0.331642746925354, train_loss: 0.2159089297056198\n",
            "16610 val_loss: 0.33140215277671814, train_loss: 0.21585853397846222\n",
            "16620 val_loss: 0.33417871594429016, train_loss: 0.2154443860054016\n",
            "16630 val_loss: 0.33422011137008667, train_loss: 0.21566617488861084\n",
            "16640 val_loss: 0.33636897802352905, train_loss: 0.21621842682361603\n",
            "16650 val_loss: 0.33045944571495056, train_loss: 0.21530239284038544\n",
            "16660 val_loss: 0.33480992913246155, train_loss: 0.2152135819196701\n",
            "16670 val_loss: 0.337600439786911, train_loss: 0.21527381241321564\n",
            "16680 val_loss: 0.3329072892665863, train_loss: 0.21437574923038483\n",
            "16690 val_loss: 0.33413633704185486, train_loss: 0.21405881643295288\n",
            "16700 val_loss: 0.334648460149765, train_loss: 0.21378013491630554\n",
            "16710 val_loss: 0.3292478919029236, train_loss: 0.2135687917470932\n",
            "16720 val_loss: 0.3405440151691437, train_loss: 0.2144419401884079\n",
            "16730 val_loss: 0.33496013283729553, train_loss: 0.21315987408161163\n",
            "16740 val_loss: 0.33915507793426514, train_loss: 0.2136756181716919\n",
            "16750 val_loss: 0.32757875323295593, train_loss: 0.21339119970798492\n",
            "16760 val_loss: 0.32773372530937195, train_loss: 0.21289776265621185\n",
            "16770 val_loss: 0.3365427255630493, train_loss: 0.2122112363576889\n",
            "16780 val_loss: 0.329429566860199, train_loss: 0.21121430397033691\n",
            "16790 val_loss: 0.33227089047431946, train_loss: 0.21081148087978363\n",
            "16800 val_loss: 0.3333621621131897, train_loss: 0.21087652444839478\n",
            "16810 val_loss: 0.33095067739486694, train_loss: 0.21054241061210632\n",
            "16820 val_loss: 0.3324130177497864, train_loss: 0.21013830602169037\n",
            "16830 val_loss: 0.3344864547252655, train_loss: 0.21055571734905243\n",
            "16840 val_loss: 0.3337668180465698, train_loss: 0.2099020779132843\n",
            "16850 val_loss: 0.33372941613197327, train_loss: 0.21006444096565247\n",
            "16860 val_loss: 0.3288775086402893, train_loss: 0.2093249410390854\n",
            "16870 val_loss: 0.33220213651657104, train_loss: 0.20932915806770325\n",
            "16880 val_loss: 0.33160310983657837, train_loss: 0.20905761420726776\n",
            "16890 val_loss: 0.3262125849723816, train_loss: 0.20928089320659637\n",
            "16900 val_loss: 0.33095583319664, train_loss: 0.2084953337907791\n",
            "16910 val_loss: 0.3281780481338501, train_loss: 0.208057701587677\n",
            "16920 val_loss: 0.33137989044189453, train_loss: 0.20830941200256348\n",
            "16930 val_loss: 0.3289312422275543, train_loss: 0.20741719007492065\n",
            "16940 val_loss: 0.3341480791568756, train_loss: 0.20820103585720062\n",
            "16950 val_loss: 0.3322652578353882, train_loss: 0.20764116942882538\n",
            "16960 val_loss: 0.3327444791793823, train_loss: 0.20725981891155243\n",
            "16970 val_loss: 0.33195316791534424, train_loss: 0.2068917155265808\n",
            "16980 val_loss: 0.3288685381412506, train_loss: 0.20587341487407684\n",
            "16990 val_loss: 0.3258236050605774, train_loss: 0.20612430572509766\n",
            "17000 val_loss: 0.32881778478622437, train_loss: 0.20597989857196808\n",
            "17010 val_loss: 0.327747106552124, train_loss: 0.2063700258731842\n",
            "17020 val_loss: 0.3218095004558563, train_loss: 0.20769958198070526\n",
            "17030 val_loss: 0.330152690410614, train_loss: 0.20566426217556\n",
            "17040 val_loss: 0.3273807168006897, train_loss: 0.20572979748249054\n",
            "17050 val_loss: 0.32859477400779724, train_loss: 0.20501720905303955\n",
            "17060 val_loss: 0.33034271001815796, train_loss: 0.20493920147418976\n",
            "17070 val_loss: 0.32868504524230957, train_loss: 0.20441126823425293\n",
            "17080 val_loss: 0.3285108804702759, train_loss: 0.20420797169208527\n",
            "17090 val_loss: 0.3280850052833557, train_loss: 0.20376181602478027\n",
            "17100 val_loss: 0.32622823119163513, train_loss: 0.20354263484477997\n",
            "17110 val_loss: 0.32380184531211853, train_loss: 0.20357447862625122\n",
            "17120 val_loss: 0.32298868894577026, train_loss: 0.2034667432308197\n",
            "17130 val_loss: 0.32083433866500854, train_loss: 0.2036118060350418\n",
            "17140 val_loss: 0.32524991035461426, train_loss: 0.20310625433921814\n",
            "17150 val_loss: 0.3330976963043213, train_loss: 0.2036861926317215\n",
            "17160 val_loss: 0.3240399956703186, train_loss: 0.20220468938350677\n",
            "17170 val_loss: 0.3216395378112793, train_loss: 0.20207479596138\n",
            "17180 val_loss: 0.3200526833534241, train_loss: 0.20201437175273895\n",
            "17190 val_loss: 0.32343626022338867, train_loss: 0.201522558927536\n",
            "17200 val_loss: 0.32833313941955566, train_loss: 0.20126694440841675\n",
            "17210 val_loss: 0.32921913266181946, train_loss: 0.20141340792179108\n",
            "17220 val_loss: 0.3269842565059662, train_loss: 0.2010997235774994\n",
            "17230 val_loss: 0.32286226749420166, train_loss: 0.20073388516902924\n",
            "17240 val_loss: 0.32204651832580566, train_loss: 0.20047208666801453\n",
            "17250 val_loss: 0.31811508536338806, train_loss: 0.20215560495853424\n",
            "17260 val_loss: 0.3250136971473694, train_loss: 0.2003035843372345\n",
            "17270 val_loss: 0.32529813051223755, train_loss: 0.20018655061721802\n",
            "17280 val_loss: 0.32948416471481323, train_loss: 0.2001347839832306\n",
            "17290 val_loss: 0.33363375067710876, train_loss: 0.2010013461112976\n",
            "17300 val_loss: 0.3249777853488922, train_loss: 0.19898457825183868\n",
            "17310 val_loss: 0.3334815204143524, train_loss: 0.20085692405700684\n",
            "17320 val_loss: 0.3178459107875824, train_loss: 0.1991000920534134\n",
            "17330 val_loss: 0.3191291391849518, train_loss: 0.19853249192237854\n",
            "17340 val_loss: 0.32154104113578796, train_loss: 0.19806531071662903\n",
            "17350 val_loss: 0.3242242932319641, train_loss: 0.19797661900520325\n",
            "17360 val_loss: 0.3268023431301117, train_loss: 0.198731929063797\n",
            "17370 val_loss: 0.3284617066383362, train_loss: 0.1979837566614151\n",
            "17380 val_loss: 0.3229132294654846, train_loss: 0.19706472754478455\n",
            "17390 val_loss: 0.3212680220603943, train_loss: 0.19657032191753387\n",
            "17400 val_loss: 0.3191480338573456, train_loss: 0.19670771062374115\n",
            "17410 val_loss: 0.3184892237186432, train_loss: 0.19699352979660034\n",
            "17420 val_loss: 0.32032638788223267, train_loss: 0.1966313123703003\n",
            "17430 val_loss: 0.3270273208618164, train_loss: 0.19736360013484955\n",
            "17440 val_loss: 0.3209964334964752, train_loss: 0.1962515413761139\n",
            "17450 val_loss: 0.31552258133888245, train_loss: 0.1966559737920761\n",
            "17460 val_loss: 0.3190329372882843, train_loss: 0.19534926116466522\n",
            "17470 val_loss: 0.3218832015991211, train_loss: 0.1949314922094345\n",
            "17480 val_loss: 0.32260531187057495, train_loss: 0.1950616091489792\n",
            "17490 val_loss: 0.317157119512558, train_loss: 0.194814532995224\n",
            "17500 val_loss: 0.3270314335823059, train_loss: 0.19516099989414215\n",
            "17510 val_loss: 0.31985217332839966, train_loss: 0.19425171613693237\n",
            "17520 val_loss: 0.3227805495262146, train_loss: 0.19433557987213135\n",
            "17530 val_loss: 0.31909430027008057, train_loss: 0.19348476827144623\n",
            "17540 val_loss: 0.3278776705265045, train_loss: 0.19407668709754944\n",
            "17550 val_loss: 0.3153981864452362, train_loss: 0.19409391283988953\n",
            "17560 val_loss: 0.3194442689418793, train_loss: 0.19309329986572266\n",
            "17570 val_loss: 0.3179683983325958, train_loss: 0.19261114299297333\n",
            "17580 val_loss: 0.322604238986969, train_loss: 0.1927119493484497\n",
            "17590 val_loss: 0.3200848400592804, train_loss: 0.1923167109489441\n",
            "17600 val_loss: 0.3220762014389038, train_loss: 0.19300812482833862\n",
            "17610 val_loss: 0.3131314218044281, train_loss: 0.19214844703674316\n",
            "17620 val_loss: 0.3200840651988983, train_loss: 0.1923062652349472\n",
            "17630 val_loss: 0.3142942488193512, train_loss: 0.19123965501785278\n",
            "17640 val_loss: 0.31873640418052673, train_loss: 0.19141319394111633\n",
            "17650 val_loss: 0.3216056525707245, train_loss: 0.19131915271282196\n",
            "17660 val_loss: 0.31975868344306946, train_loss: 0.1906009018421173\n",
            "17670 val_loss: 0.31377533078193665, train_loss: 0.1902124285697937\n",
            "17680 val_loss: 0.31822577118873596, train_loss: 0.19002725183963776\n",
            "17690 val_loss: 0.3230094313621521, train_loss: 0.1907232701778412\n",
            "17700 val_loss: 0.3133411407470703, train_loss: 0.18942411243915558\n",
            "17710 val_loss: 0.31203848123550415, train_loss: 0.19008547067642212\n",
            "17720 val_loss: 0.3104560971260071, train_loss: 0.1895076036453247\n",
            "17730 val_loss: 0.3153403103351593, train_loss: 0.18872828781604767\n",
            "17740 val_loss: 0.31765016913414, train_loss: 0.18876443803310394\n",
            "17750 val_loss: 0.31335005164146423, train_loss: 0.188853919506073\n",
            "17760 val_loss: 0.32017141580581665, train_loss: 0.18889321386814117\n",
            "17770 val_loss: 0.3174933195114136, train_loss: 0.18816488981246948\n",
            "17780 val_loss: 0.31518787145614624, train_loss: 0.18758359551429749\n",
            "17790 val_loss: 0.3107362687587738, train_loss: 0.1874535083770752\n",
            "17800 val_loss: 0.3141891062259674, train_loss: 0.18680857121944427\n",
            "17810 val_loss: 0.3228774666786194, train_loss: 0.18754208087921143\n",
            "17820 val_loss: 0.31614696979522705, train_loss: 0.18602962791919708\n",
            "17830 val_loss: 0.3070759177207947, train_loss: 0.1867837905883789\n",
            "17840 val_loss: 0.3175860047340393, train_loss: 0.18591448664665222\n",
            "17850 val_loss: 0.31871405243873596, train_loss: 0.1856694370508194\n",
            "17860 val_loss: 0.3228921592235565, train_loss: 0.18601633608341217\n",
            "17870 val_loss: 0.3194158971309662, train_loss: 0.18570056557655334\n",
            "17880 val_loss: 0.3152245283126831, train_loss: 0.1854459047317505\n",
            "17890 val_loss: 0.3134666979312897, train_loss: 0.18525150418281555\n",
            "17900 val_loss: 0.3145386278629303, train_loss: 0.18473239243030548\n",
            "17910 val_loss: 0.31552624702453613, train_loss: 0.18488773703575134\n",
            "17920 val_loss: 0.31482911109924316, train_loss: 0.1845591813325882\n",
            "17930 val_loss: 0.3162226378917694, train_loss: 0.184222012758255\n",
            "17940 val_loss: 0.3129759728908539, train_loss: 0.1836577206850052\n",
            "17950 val_loss: 0.31663164496421814, train_loss: 0.18380106985569\n",
            "17960 val_loss: 0.32500118017196655, train_loss: 0.18626177310943604\n",
            "17970 val_loss: 0.3200896680355072, train_loss: 0.18467484414577484\n",
            "17980 val_loss: 0.31208235025405884, train_loss: 0.18289576470851898\n",
            "17990 val_loss: 0.3130914270877838, train_loss: 0.1826445460319519\n",
            "18000 val_loss: 0.31459876894950867, train_loss: 0.18262867629528046\n",
            "18010 val_loss: 0.31373417377471924, train_loss: 0.18237432837486267\n",
            "18020 val_loss: 0.30412811040878296, train_loss: 0.18214154243469238\n",
            "18030 val_loss: 0.3173011541366577, train_loss: 0.18289780616760254\n",
            "18040 val_loss: 0.31005528569221497, train_loss: 0.18138563632965088\n",
            "18050 val_loss: 0.30143406987190247, train_loss: 0.18222719430923462\n",
            "18060 val_loss: 0.3063088059425354, train_loss: 0.1807786077260971\n",
            "18070 val_loss: 0.31759151816368103, train_loss: 0.1812298595905304\n",
            "18080 val_loss: 0.31336238980293274, train_loss: 0.18002603948116302\n",
            "18090 val_loss: 0.3057537078857422, train_loss: 0.17991867661476135\n",
            "18100 val_loss: 0.30903297662734985, train_loss: 0.18021894991397858\n",
            "18110 val_loss: 0.30611783266067505, train_loss: 0.1795600950717926\n",
            "18120 val_loss: 0.30563852190971375, train_loss: 0.1793276071548462\n",
            "18130 val_loss: 0.3081469237804413, train_loss: 0.17844931781291962\n",
            "18140 val_loss: 0.30268874764442444, train_loss: 0.17915304005146027\n",
            "18150 val_loss: 0.3092496991157532, train_loss: 0.1782498061656952\n",
            "18160 val_loss: 0.3101755976676941, train_loss: 0.17796197533607483\n",
            "18170 val_loss: 0.314230352640152, train_loss: 0.17860879004001617\n",
            "18180 val_loss: 0.3087002635002136, train_loss: 0.17847709357738495\n",
            "18190 val_loss: 0.30848976969718933, train_loss: 0.17738954722881317\n",
            "18200 val_loss: 0.31285959482192993, train_loss: 0.17684143781661987\n",
            "18210 val_loss: 0.30692270398139954, train_loss: 0.17683196067810059\n",
            "18220 val_loss: 0.30792236328125, train_loss: 0.1766848862171173\n",
            "18230 val_loss: 0.2991320788860321, train_loss: 0.17740744352340698\n",
            "18240 val_loss: 0.31411129236221313, train_loss: 0.1769886016845703\n",
            "18250 val_loss: 0.3077313005924225, train_loss: 0.1763138622045517\n",
            "18260 val_loss: 0.3186010718345642, train_loss: 0.17692552506923676\n",
            "18270 val_loss: 0.30343544483184814, train_loss: 0.17499792575836182\n",
            "18280 val_loss: 0.3045969009399414, train_loss: 0.17438991367816925\n",
            "18290 val_loss: 0.3075796663761139, train_loss: 0.1742105484008789\n",
            "18300 val_loss: 0.3070911467075348, train_loss: 0.17469997704029083\n",
            "18310 val_loss: 0.2990614175796509, train_loss: 0.17461273074150085\n",
            "18320 val_loss: 0.3062132000923157, train_loss: 0.1736600250005722\n",
            "18330 val_loss: 0.3050960302352905, train_loss: 0.17286330461502075\n",
            "18340 val_loss: 0.3040795624256134, train_loss: 0.17282310128211975\n",
            "18350 val_loss: 0.3032997250556946, train_loss: 0.1718926578760147\n",
            "18360 val_loss: 0.30471161007881165, train_loss: 0.1721685826778412\n",
            "18370 val_loss: 0.3087793290615082, train_loss: 0.172697976231575\n",
            "18380 val_loss: 0.3040316104888916, train_loss: 0.1723901778459549\n",
            "18390 val_loss: 0.30690234899520874, train_loss: 0.17178986966609955\n",
            "18400 val_loss: 0.2969741225242615, train_loss: 0.17069867253303528\n",
            "18410 val_loss: 0.29628443717956543, train_loss: 0.17035917937755585\n",
            "18420 val_loss: 0.298214316368103, train_loss: 0.16967886686325073\n",
            "18430 val_loss: 0.31134191155433655, train_loss: 0.17090150713920593\n",
            "18440 val_loss: 0.30028459429740906, train_loss: 0.1687915325164795\n",
            "18450 val_loss: 0.29512935876846313, train_loss: 0.16851826012134552\n",
            "18460 val_loss: 0.30543825030326843, train_loss: 0.1682819426059723\n",
            "18470 val_loss: 0.30990782380104065, train_loss: 0.16842231154441833\n",
            "18480 val_loss: 0.30663663148880005, train_loss: 0.16716796159744263\n",
            "18490 val_loss: 0.2992984652519226, train_loss: 0.1662565916776657\n",
            "18500 val_loss: 0.29672735929489136, train_loss: 0.16547897458076477\n",
            "18510 val_loss: 0.3064087927341461, train_loss: 0.16625620424747467\n",
            "18520 val_loss: 0.29807645082473755, train_loss: 0.16479124128818512\n",
            "18530 val_loss: 0.2927858233451843, train_loss: 0.1644161343574524\n",
            "18540 val_loss: 0.300126314163208, train_loss: 0.16381236910820007\n",
            "18550 val_loss: 0.2918436527252197, train_loss: 0.16298219561576843\n",
            "18560 val_loss: 0.29462897777557373, train_loss: 0.16167929768562317\n",
            "18570 val_loss: 0.29113873839378357, train_loss: 0.16278965771198273\n",
            "18580 val_loss: 0.2948317229747772, train_loss: 0.1608475148677826\n",
            "18590 val_loss: 0.2984527051448822, train_loss: 0.16015270352363586\n",
            "18600 val_loss: 0.29742300510406494, train_loss: 0.15937380492687225\n",
            "18610 val_loss: 0.2891627550125122, train_loss: 0.1587492823600769\n",
            "18620 val_loss: 0.2911878228187561, train_loss: 0.15794211626052856\n",
            "18630 val_loss: 0.30338120460510254, train_loss: 0.15808925032615662\n",
            "18640 val_loss: 0.2964070439338684, train_loss: 0.15667323768138885\n",
            "18650 val_loss: 0.29915517568588257, train_loss: 0.15666460990905762\n",
            "18660 val_loss: 0.30252525210380554, train_loss: 0.1568087488412857\n",
            "18670 val_loss: 0.2942540645599365, train_loss: 0.1538894772529602\n",
            "18680 val_loss: 0.2911858856678009, train_loss: 0.15278220176696777\n",
            "18690 val_loss: 0.30027908086776733, train_loss: 0.15449373424053192\n",
            "18700 val_loss: 0.2932681441307068, train_loss: 0.15111911296844482\n",
            "18710 val_loss: 0.290229856967926, train_loss: 0.15009447932243347\n",
            "18720 val_loss: 0.285300612449646, train_loss: 0.1494002789258957\n",
            "18730 val_loss: 0.294514536857605, train_loss: 0.15000490844249725\n",
            "18740 val_loss: 0.2887730300426483, train_loss: 0.14828574657440186\n",
            "18750 val_loss: 0.2853354811668396, train_loss: 0.14770081639289856\n",
            "18760 val_loss: 0.2775329649448395, train_loss: 0.14871874451637268\n",
            "18770 val_loss: 0.2841276526451111, train_loss: 0.14540338516235352\n",
            "18780 val_loss: 0.27554765343666077, train_loss: 0.14594042301177979\n",
            "18790 val_loss: 0.2827889919281006, train_loss: 0.14400005340576172\n",
            "18800 val_loss: 0.2798070013523102, train_loss: 0.14315542578697205\n",
            "18810 val_loss: 0.27651169896125793, train_loss: 0.14238958060741425\n",
            "18820 val_loss: 0.2727692127227783, train_loss: 0.14159594476222992\n",
            "18830 val_loss: 0.27523699402809143, train_loss: 0.14064475893974304\n",
            "18840 val_loss: 0.2748870253562927, train_loss: 0.13935768604278564\n",
            "18850 val_loss: 0.2786557376384735, train_loss: 0.1394031047821045\n",
            "18860 val_loss: 0.2700170576572418, train_loss: 0.1381993442773819\n",
            "18870 val_loss: 0.27533936500549316, train_loss: 0.1379563957452774\n",
            "18880 val_loss: 0.2781457006931305, train_loss: 0.13756203651428223\n",
            "18890 val_loss: 0.27490726113319397, train_loss: 0.1367531269788742\n",
            "18900 val_loss: 0.2693593204021454, train_loss: 0.13528762757778168\n",
            "18910 val_loss: 0.26554521918296814, train_loss: 0.13643589615821838\n",
            "18920 val_loss: 0.2668592035770416, train_loss: 0.13487602770328522\n",
            "18930 val_loss: 0.26721110939979553, train_loss: 0.13325268030166626\n",
            "18940 val_loss: 0.2654317617416382, train_loss: 0.1327531486749649\n",
            "18950 val_loss: 0.2660655379295349, train_loss: 0.13188308477401733\n",
            "18960 val_loss: 0.2736574709415436, train_loss: 0.13323387503623962\n",
            "18970 val_loss: 0.2653370797634125, train_loss: 0.13052043318748474\n",
            "18980 val_loss: 0.26253214478492737, train_loss: 0.13006481528282166\n",
            "18990 val_loss: 0.26299548149108887, train_loss: 0.12914270162582397\n",
            "19000 val_loss: 0.25909069180488586, train_loss: 0.12985095381736755\n",
            "19010 val_loss: 0.26324233412742615, train_loss: 0.12761270999908447\n",
            "19020 val_loss: 0.2595016360282898, train_loss: 0.127776637673378\n",
            "19030 val_loss: 0.2640531361103058, train_loss: 0.12690258026123047\n",
            "19040 val_loss: 0.2636044919490814, train_loss: 0.12534356117248535\n",
            "19050 val_loss: 0.2580019533634186, train_loss: 0.12477031350135803\n",
            "19060 val_loss: 0.254225492477417, train_loss: 0.12580718100070953\n",
            "19070 val_loss: 0.260510116815567, train_loss: 0.12357113510370255\n",
            "19080 val_loss: 0.2685406804084778, train_loss: 0.12365929037332535\n",
            "19090 val_loss: 0.25991731882095337, train_loss: 0.12135501950979233\n",
            "19100 val_loss: 0.2675726115703583, train_loss: 0.12195063382387161\n",
            "19110 val_loss: 0.2639850080013275, train_loss: 0.11912183463573456\n",
            "19120 val_loss: 0.2627977728843689, train_loss: 0.11831629276275635\n",
            "19130 val_loss: 0.26104769110679626, train_loss: 0.11750800162553787\n",
            "19140 val_loss: 0.26304560899734497, train_loss: 0.1175282746553421\n",
            "19150 val_loss: 0.26290011405944824, train_loss: 0.11646167933940887\n",
            "19160 val_loss: 0.25406184792518616, train_loss: 0.11597166955471039\n",
            "19170 val_loss: 0.2693134844303131, train_loss: 0.1201840192079544\n",
            "19180 val_loss: 0.25394967198371887, train_loss: 0.11489568650722504\n",
            "19190 val_loss: 0.25185298919677734, train_loss: 0.11761843413114548\n",
            "19200 val_loss: 0.2521015703678131, train_loss: 0.11557067930698395\n",
            "19210 val_loss: 0.25574567914009094, train_loss: 0.11328668892383575\n",
            "19220 val_loss: 0.2556426525115967, train_loss: 0.1134755089879036\n",
            "19230 val_loss: 0.25991329550743103, train_loss: 0.11338469386100769\n",
            "19240 val_loss: 0.24717524647712708, train_loss: 0.11334830522537231\n",
            "19250 val_loss: 0.2527129352092743, train_loss: 0.11053367704153061\n",
            "19260 val_loss: 0.2483459860086441, train_loss: 0.11045214533805847\n",
            "19270 val_loss: 0.2512795031070709, train_loss: 0.1086137518286705\n",
            "19280 val_loss: 0.24560625851154327, train_loss: 0.11068602651357651\n",
            "19290 val_loss: 0.24450838565826416, train_loss: 0.11554155498743057\n",
            "19300 val_loss: 0.24767862260341644, train_loss: 0.10794045031070709\n",
            "19310 val_loss: 0.24340187013149261, train_loss: 0.1080097183585167\n",
            "19320 val_loss: 0.252288281917572, train_loss: 0.11142472177743912\n",
            "19330 val_loss: 0.24722549319267273, train_loss: 0.10764462500810623\n",
            "19340 val_loss: 0.24830223619937897, train_loss: 0.10571672767400742\n",
            "19350 val_loss: 0.24437302350997925, train_loss: 0.10868936032056808\n",
            "19360 val_loss: 0.24734751880168915, train_loss: 0.1064528226852417\n",
            "19370 val_loss: 0.24580876529216766, train_loss: 0.11557455360889435\n",
            "19380 val_loss: 0.2395467311143875, train_loss: 0.10725624859333038\n",
            "19390 val_loss: 0.2415512651205063, train_loss: 0.1034318283200264\n",
            "19400 val_loss: 0.24472522735595703, train_loss: 0.103148452937603\n",
            "19410 val_loss: 0.2537331283092499, train_loss: 0.10525622963905334\n",
            "19420 val_loss: 0.2461574822664261, train_loss: 0.10424917936325073\n",
            "19430 val_loss: 0.25036951899528503, train_loss: 0.10417170077562332\n",
            "19440 val_loss: 0.24259932339191437, train_loss: 0.09942836314439774\n",
            "19450 val_loss: 0.25514090061187744, train_loss: 0.10651171952486038\n",
            "19460 val_loss: 0.25059694051742554, train_loss: 0.09920798242092133\n",
            "19470 val_loss: 0.23769815266132355, train_loss: 0.10054728388786316\n",
            "19480 val_loss: 0.25810912251472473, train_loss: 0.11413943767547607\n",
            "19490 val_loss: 0.23458008468151093, train_loss: 0.10365543514490128\n",
            "19500 val_loss: 0.25216540694236755, train_loss: 0.10642338544130325\n",
            "19510 val_loss: 0.24074967205524445, train_loss: 0.09860144555568695\n",
            "19520 val_loss: 0.24120719730854034, train_loss: 0.10897082835435867\n",
            "19530 val_loss: 0.2423589825630188, train_loss: 0.09718240797519684\n",
            "19540 val_loss: 0.23630458116531372, train_loss: 0.09615054726600647\n",
            "19550 val_loss: 0.23773640394210815, train_loss: 0.09402337670326233\n",
            "19560 val_loss: 0.23417851328849792, train_loss: 0.09518249332904816\n",
            "19570 val_loss: 0.23551541566848755, train_loss: 0.09333587437868118\n",
            "19580 val_loss: 0.23033669590950012, train_loss: 0.09346077591180801\n",
            "19590 val_loss: 0.23675081133842468, train_loss: 0.09092379361391068\n",
            "19600 val_loss: 0.2369321882724762, train_loss: 0.09504269808530807\n",
            "19610 val_loss: 0.23537366092205048, train_loss: 0.09462747722864151\n",
            "19620 val_loss: 0.23172135651111603, train_loss: 0.0895349457859993\n",
            "19630 val_loss: 0.23119036853313446, train_loss: 0.08888473361730576\n",
            "19640 val_loss: 0.22817234694957733, train_loss: 0.09548326581716537\n",
            "19650 val_loss: 0.2247486561536789, train_loss: 0.08940505236387253\n",
            "19660 val_loss: 0.23828615248203278, train_loss: 0.09394830465316772\n",
            "19670 val_loss: 0.2303587794303894, train_loss: 0.09171734750270844\n",
            "19680 val_loss: 0.22858238220214844, train_loss: 0.08789297938346863\n",
            "19690 val_loss: 0.22507116198539734, train_loss: 0.08908528834581375\n",
            "19700 val_loss: 0.2256414294242859, train_loss: 0.08727887272834778\n",
            "19710 val_loss: 0.22587285935878754, train_loss: 0.08833641558885574\n",
            "19720 val_loss: 0.23193654417991638, train_loss: 0.08731655031442642\n",
            "19730 val_loss: 0.22897888720035553, train_loss: 0.08544613420963287\n",
            "19740 val_loss: 0.22417867183685303, train_loss: 0.08747376501560211\n",
            "19750 val_loss: 0.22118942439556122, train_loss: 0.08592996001243591\n",
            "19760 val_loss: 0.22603243589401245, train_loss: 0.08901649713516235\n",
            "19770 val_loss: 0.22273513674736023, train_loss: 0.08648526668548584\n",
            "19780 val_loss: 0.22014158964157104, train_loss: 0.08482177555561066\n",
            "19790 val_loss: 0.22135131061077118, train_loss: 0.084319569170475\n",
            "19800 val_loss: 0.22222259640693665, train_loss: 0.0824875757098198\n",
            "19810 val_loss: 0.22937536239624023, train_loss: 0.09307791292667389\n",
            "19820 val_loss: 0.21964561939239502, train_loss: 0.0837208703160286\n",
            "19830 val_loss: 0.23629440367221832, train_loss: 0.08732821047306061\n",
            "19840 val_loss: 0.22739002108573914, train_loss: 0.08091934025287628\n",
            "19850 val_loss: 0.22126786410808563, train_loss: 0.08164447546005249\n",
            "19860 val_loss: 0.2393335998058319, train_loss: 0.09979979693889618\n",
            "19870 val_loss: 0.22222064435482025, train_loss: 0.08225462585687637\n",
            "19880 val_loss: 0.22829250991344452, train_loss: 0.08654255419969559\n",
            "19890 val_loss: 0.21548764407634735, train_loss: 0.08117301017045975\n",
            "19900 val_loss: 0.2230592966079712, train_loss: 0.07936209440231323\n",
            "19910 val_loss: 0.23424534499645233, train_loss: 0.08623656630516052\n",
            "19920 val_loss: 0.22110185027122498, train_loss: 0.08198697865009308\n",
            "19930 val_loss: 0.22895826399326324, train_loss: 0.08924736082553864\n",
            "19940 val_loss: 0.2186202108860016, train_loss: 0.07781759649515152\n",
            "19950 val_loss: 0.21677982807159424, train_loss: 0.07835893332958221\n",
            "19960 val_loss: 0.21753458678722382, train_loss: 0.07902277261018753\n",
            "19970 val_loss: 0.21585334837436676, train_loss: 0.07730985432863235\n",
            "19980 val_loss: 0.22388489544391632, train_loss: 0.08265181630849838\n",
            "19990 val_loss: 0.21556542813777924, train_loss: 0.08121339231729507\n",
            "20000 val_loss: 0.2142122983932495, train_loss: 0.07740622758865356\n",
            "20010 val_loss: 0.22692246735095978, train_loss: 0.08629351109266281\n",
            "20020 val_loss: 0.2131931483745575, train_loss: 0.0761922299861908\n",
            "20030 val_loss: 0.21494413912296295, train_loss: 0.075398750603199\n",
            "20040 val_loss: 0.21923549473285675, train_loss: 0.08023586869239807\n",
            "20050 val_loss: 0.2180020660161972, train_loss: 0.07886692136526108\n",
            "20060 val_loss: 0.21102264523506165, train_loss: 0.0749947652220726\n",
            "20070 val_loss: 0.21379807591438293, train_loss: 0.07911723852157593\n",
            "20080 val_loss: 0.21307888627052307, train_loss: 0.07275917381048203\n",
            "20090 val_loss: 0.21950285136699677, train_loss: 0.08459475636482239\n",
            "20100 val_loss: 0.2120479792356491, train_loss: 0.0725143551826477\n",
            "20110 val_loss: 0.21626393496990204, train_loss: 0.07429040968418121\n",
            "20120 val_loss: 0.21305611729621887, train_loss: 0.07260183990001678\n",
            "20130 val_loss: 0.21196885406970978, train_loss: 0.07456585764884949\n",
            "20140 val_loss: 0.21101851761341095, train_loss: 0.0713638886809349\n",
            "20150 val_loss: 0.20990128815174103, train_loss: 0.07083835452795029\n",
            "20160 val_loss: 0.20606032013893127, train_loss: 0.0690082237124443\n",
            "20170 val_loss: 0.2063685655593872, train_loss: 0.0716961920261383\n",
            "20180 val_loss: 0.20681288838386536, train_loss: 0.07110028713941574\n",
            "20190 val_loss: 0.2088053822517395, train_loss: 0.07025910168886185\n",
            "20200 val_loss: 0.2104189693927765, train_loss: 0.0684632733464241\n",
            "20210 val_loss: 0.21081534028053284, train_loss: 0.06888681650161743\n",
            "20220 val_loss: 0.20720697939395905, train_loss: 0.0682530477643013\n",
            "20230 val_loss: 0.20562303066253662, train_loss: 0.06769553571939468\n",
            "20240 val_loss: 0.21247375011444092, train_loss: 0.06622938066720963\n",
            "20250 val_loss: 0.2094363421201706, train_loss: 0.06650804728269577\n",
            "20260 val_loss: 0.2211410254240036, train_loss: 0.07311546802520752\n",
            "20270 val_loss: 0.2135189324617386, train_loss: 0.06892771273851395\n",
            "20280 val_loss: 0.20770995318889618, train_loss: 0.0670681893825531\n",
            "20290 val_loss: 0.21187612414360046, train_loss: 0.06846899539232254\n",
            "20300 val_loss: 0.20873205363750458, train_loss: 0.06646495312452316\n",
            "20310 val_loss: 0.21187075972557068, train_loss: 0.06487766653299332\n",
            "20320 val_loss: 0.20933891832828522, train_loss: 0.0640651285648346\n",
            "20330 val_loss: 0.20682044327259064, train_loss: 0.06731249392032623\n",
            "20340 val_loss: 0.2049078643321991, train_loss: 0.06574781239032745\n",
            "20350 val_loss: 0.2092999964952469, train_loss: 0.06911507248878479\n",
            "20360 val_loss: 0.20275409519672394, train_loss: 0.06790575385093689\n",
            "20370 val_loss: 0.20211900770664215, train_loss: 0.06554253399372101\n",
            "20380 val_loss: 0.20928113162517548, train_loss: 0.06841021031141281\n",
            "20390 val_loss: 0.2026141881942749, train_loss: 0.06411858648061752\n",
            "20400 val_loss: 0.22081023454666138, train_loss: 0.07169915735721588\n",
            "20410 val_loss: 0.20196948945522308, train_loss: 0.0640217736363411\n",
            "20420 val_loss: 0.21253763139247894, train_loss: 0.06579410284757614\n",
            "20430 val_loss: 0.2036084681749344, train_loss: 0.06312017887830734\n",
            "20440 val_loss: 0.20410659909248352, train_loss: 0.06479178369045258\n",
            "20450 val_loss: 0.20410533249378204, train_loss: 0.06459589302539825\n",
            "20460 val_loss: 0.20993445813655853, train_loss: 0.06632285565137863\n",
            "20470 val_loss: 0.2010386735200882, train_loss: 0.0632585883140564\n",
            "20480 val_loss: 0.19604696333408356, train_loss: 0.06079595535993576\n",
            "20490 val_loss: 0.20515108108520508, train_loss: 0.06558652967214584\n",
            "20500 val_loss: 0.1972186267375946, train_loss: 0.06078407168388367\n",
            "20510 val_loss: 0.19742223620414734, train_loss: 0.06645263731479645\n",
            "20520 val_loss: 0.19692131876945496, train_loss: 0.06357599049806595\n",
            "20530 val_loss: 0.19996574521064758, train_loss: 0.06147127225995064\n",
            "20540 val_loss: 0.21371768414974213, train_loss: 0.065672867000103\n",
            "20550 val_loss: 0.19948741793632507, train_loss: 0.06143411248922348\n",
            "20560 val_loss: 0.1993052363395691, train_loss: 0.06396187096834183\n",
            "20570 val_loss: 0.22140157222747803, train_loss: 0.07354770600795746\n",
            "20580 val_loss: 0.19646266102790833, train_loss: 0.05859176814556122\n",
            "20590 val_loss: 0.19937172532081604, train_loss: 0.05739050358533859\n",
            "20600 val_loss: 0.22139757871627808, train_loss: 0.06742537766695023\n",
            "20610 val_loss: 0.2137581706047058, train_loss: 0.06819673627614975\n",
            "20620 val_loss: 0.20332935452461243, train_loss: 0.0625457763671875\n",
            "20630 val_loss: 0.19879931211471558, train_loss: 0.060597244650125504\n",
            "20640 val_loss: 0.19494912028312683, train_loss: 0.06003241986036301\n",
            "20650 val_loss: 0.19858619570732117, train_loss: 0.06332606822252274\n",
            "20660 val_loss: 0.18776968121528625, train_loss: 0.06033996120095253\n",
            "20670 val_loss: 0.19306962192058563, train_loss: 0.057914119213819504\n",
            "20680 val_loss: 0.21152514219284058, train_loss: 0.06321951001882553\n",
            "20690 val_loss: 0.19625194370746613, train_loss: 0.057984624058008194\n",
            "20700 val_loss: 0.19665062427520752, train_loss: 0.05596664175391197\n",
            "20710 val_loss: 0.21203327178955078, train_loss: 0.06389488279819489\n",
            "20720 val_loss: 0.2011955827474594, train_loss: 0.05959612876176834\n",
            "20730 val_loss: 0.19465681910514832, train_loss: 0.05628528445959091\n",
            "20740 val_loss: 0.19547957181930542, train_loss: 0.0550290122628212\n",
            "20750 val_loss: 0.18569689989089966, train_loss: 0.05653942748904228\n",
            "20760 val_loss: 0.20274557173252106, train_loss: 0.057445116341114044\n",
            "20770 val_loss: 0.1950746774673462, train_loss: 0.0562455989420414\n",
            "20780 val_loss: 0.19303295016288757, train_loss: 0.054165665060281754\n",
            "20790 val_loss: 0.19079144299030304, train_loss: 0.05472069978713989\n",
            "20800 val_loss: 0.19273728132247925, train_loss: 0.05491773784160614\n",
            "20810 val_loss: 0.1879415363073349, train_loss: 0.05381220206618309\n",
            "20820 val_loss: 0.1888253390789032, train_loss: 0.05253651365637779\n",
            "20830 val_loss: 0.1886630356311798, train_loss: 0.052742812782526016\n",
            "20840 val_loss: 0.19249647855758667, train_loss: 0.05416838452219963\n",
            "20850 val_loss: 0.19990789890289307, train_loss: 0.05442060902714729\n",
            "20860 val_loss: 0.19926492869853973, train_loss: 0.05545301362872124\n",
            "20870 val_loss: 0.18972299993038177, train_loss: 0.051995642483234406\n",
            "20880 val_loss: 0.20440074801445007, train_loss: 0.05550128594040871\n",
            "20890 val_loss: 0.20022423565387726, train_loss: 0.06019479036331177\n",
            "20900 val_loss: 0.20909525454044342, train_loss: 0.06521861255168915\n",
            "20910 val_loss: 0.1880016177892685, train_loss: 0.05190526321530342\n",
            "20920 val_loss: 0.2145562618970871, train_loss: 0.05791492015123367\n",
            "20930 val_loss: 0.19293183088302612, train_loss: 0.05215417966246605\n",
            "20940 val_loss: 0.19911424815654755, train_loss: 0.05277126282453537\n",
            "20950 val_loss: 0.18968915939331055, train_loss: 0.051627080887556076\n",
            "20960 val_loss: 0.21432088315486908, train_loss: 0.06298347562551498\n",
            "20970 val_loss: 0.20279809832572937, train_loss: 0.057880762964487076\n",
            "20980 val_loss: 0.1835189312696457, train_loss: 0.05300460383296013\n",
            "20990 val_loss: 0.18901710212230682, train_loss: 0.050791315734386444\n",
            "21000 val_loss: 0.22336483001708984, train_loss: 0.06591327488422394\n",
            "21010 val_loss: 0.21211983263492584, train_loss: 0.059803154319524765\n",
            "21020 val_loss: 0.2025531828403473, train_loss: 0.05301439017057419\n",
            "21030 val_loss: 0.18246327340602875, train_loss: 0.0510389544069767\n",
            "21040 val_loss: 0.19184143841266632, train_loss: 0.053920678794384\n",
            "21050 val_loss: 0.18552753329277039, train_loss: 0.05221077427268028\n",
            "21060 val_loss: 0.1932467222213745, train_loss: 0.05033336207270622\n",
            "21070 val_loss: 0.18144337832927704, train_loss: 0.04985317587852478\n",
            "21080 val_loss: 0.19465048611164093, train_loss: 0.04934260621666908\n",
            "21090 val_loss: 0.20911039412021637, train_loss: 0.05554107576608658\n",
            "21100 val_loss: 0.19087883830070496, train_loss: 0.05024208500981331\n",
            "21110 val_loss: 0.18880301713943481, train_loss: 0.0479394756257534\n",
            "21120 val_loss: 0.20563706755638123, train_loss: 0.05354464426636696\n",
            "21130 val_loss: 0.1846756935119629, train_loss: 0.04819441959261894\n",
            "21140 val_loss: 0.2122994214296341, train_loss: 0.06077955663204193\n",
            "21150 val_loss: 0.18034431338310242, train_loss: 0.05098380520939827\n",
            "21160 val_loss: 0.1845397651195526, train_loss: 0.04795759171247482\n",
            "21170 val_loss: 0.18500855565071106, train_loss: 0.04780189320445061\n",
            "21180 val_loss: 0.18655705451965332, train_loss: 0.04702320322394371\n",
            "21190 val_loss: 0.1820707470178604, train_loss: 0.047212157398462296\n",
            "21200 val_loss: 0.19924411177635193, train_loss: 0.05142531543970108\n",
            "21210 val_loss: 0.18251264095306396, train_loss: 0.04650850594043732\n",
            "21220 val_loss: 0.18502908945083618, train_loss: 0.04874833673238754\n",
            "21230 val_loss: 0.1945483386516571, train_loss: 0.05224584415555\n",
            "21240 val_loss: 0.19103720784187317, train_loss: 0.04661928862333298\n",
            "21250 val_loss: 0.19072116911411285, train_loss: 0.04725421220064163\n",
            "21260 val_loss: 0.19439268112182617, train_loss: 0.050737541168928146\n",
            "21270 val_loss: 0.18072956800460815, train_loss: 0.04717876389622688\n",
            "21280 val_loss: 0.18974187970161438, train_loss: 0.04691172018647194\n",
            "21290 val_loss: 0.1863321214914322, train_loss: 0.04641425982117653\n",
            "21300 val_loss: 0.18625624477863312, train_loss: 0.04674772173166275\n",
            "21310 val_loss: 0.19796206057071686, train_loss: 0.04997216910123825\n",
            "21320 val_loss: 0.18650023639202118, train_loss: 0.04651681333780289\n",
            "21330 val_loss: 0.19409018754959106, train_loss: 0.046113934367895126\n",
            "21340 val_loss: 0.1925075799226761, train_loss: 0.04877801239490509\n",
            "21350 val_loss: 0.19461925327777863, train_loss: 0.04726573824882507\n",
            "21360 val_loss: 0.18529941141605377, train_loss: 0.0448596328496933\n",
            "21370 val_loss: 0.19486752152442932, train_loss: 0.04478782042860985\n",
            "21380 val_loss: 0.19654828310012817, train_loss: 0.04554484784603119\n",
            "21390 val_loss: 0.18441735208034515, train_loss: 0.045254260301589966\n",
            "21400 val_loss: 0.18050584197044373, train_loss: 0.0445636548101902\n",
            "21410 val_loss: 0.18727396428585052, train_loss: 0.045293644070625305\n",
            "21420 val_loss: 0.18023240566253662, train_loss: 0.04489288106560707\n",
            "21430 val_loss: 0.20543420314788818, train_loss: 0.04777685925364494\n",
            "21440 val_loss: 0.1947384774684906, train_loss: 0.04584747552871704\n",
            "21450 val_loss: 0.18246230483055115, train_loss: 0.04294440150260925\n",
            "21460 val_loss: 0.1815158575773239, train_loss: 0.04393596947193146\n",
            "21470 val_loss: 0.1847248375415802, train_loss: 0.043340202420949936\n",
            "21480 val_loss: 0.18723420798778534, train_loss: 0.04750993847846985\n",
            "21490 val_loss: 0.18378162384033203, train_loss: 0.04341750219464302\n",
            "21500 val_loss: 0.18247966468334198, train_loss: 0.04382573440670967\n",
            "21510 val_loss: 0.1957772970199585, train_loss: 0.04987386241555214\n",
            "21520 val_loss: 0.18775756657123566, train_loss: 0.044609613716602325\n",
            "21530 val_loss: 0.1821403056383133, train_loss: 0.042187947779893875\n",
            "21540 val_loss: 0.18144752085208893, train_loss: 0.04392435774207115\n",
            "21550 val_loss: 0.17967884242534637, train_loss: 0.04165305942296982\n",
            "21560 val_loss: 0.18737691640853882, train_loss: 0.042265959084033966\n",
            "21570 val_loss: 0.1984218806028366, train_loss: 0.044525522738695145\n",
            "21580 val_loss: 0.19616387784481049, train_loss: 0.0423336997628212\n",
            "21590 val_loss: 0.2133394032716751, train_loss: 0.0503169409930706\n",
            "21600 val_loss: 0.19216632843017578, train_loss: 0.04299857094883919\n",
            "21610 val_loss: 0.18548648059368134, train_loss: 0.04175172001123428\n",
            "21620 val_loss: 0.1996644288301468, train_loss: 0.04500684514641762\n",
            "21630 val_loss: 0.19828873872756958, train_loss: 0.044052381068468094\n",
            "21640 val_loss: 0.18850737810134888, train_loss: 0.04111421853303909\n",
            "21650 val_loss: 0.20674900710582733, train_loss: 0.04556594043970108\n",
            "21660 val_loss: 0.2089541107416153, train_loss: 0.047561340034008026\n",
            "21670 val_loss: 0.18433994054794312, train_loss: 0.04113561287522316\n",
            "21680 val_loss: 0.18555329740047455, train_loss: 0.04206773638725281\n",
            "21690 val_loss: 0.18354856967926025, train_loss: 0.040562912821769714\n",
            "21700 val_loss: 0.18028345704078674, train_loss: 0.04097726568579674\n",
            "21710 val_loss: 0.18389658629894257, train_loss: 0.040859777480363846\n",
            "21720 val_loss: 0.18228670954704285, train_loss: 0.04023872688412666\n",
            "21730 val_loss: 0.1889088898897171, train_loss: 0.03902179375290871\n",
            "21740 val_loss: 0.19812849164009094, train_loss: 0.043918509036302567\n",
            "21750 val_loss: 0.1857667714357376, train_loss: 0.039281535893678665\n",
            "21760 val_loss: 0.1801697462797165, train_loss: 0.03917139396071434\n",
            "21770 val_loss: 0.19129422307014465, train_loss: 0.03901650011539459\n",
            "21780 val_loss: 0.18230554461479187, train_loss: 0.03920698165893555\n",
            "21790 val_loss: 0.18380753695964813, train_loss: 0.04088407754898071\n",
            "21800 val_loss: 0.18563465774059296, train_loss: 0.03868094086647034\n",
            "21810 val_loss: 0.1811467558145523, train_loss: 0.0400039404630661\n",
            "21820 val_loss: 0.18579278886318207, train_loss: 0.037468329071998596\n",
            "21830 val_loss: 0.18132027983665466, train_loss: 0.03834110498428345\n",
            "21840 val_loss: 0.18856337666511536, train_loss: 0.040809210389852524\n",
            "21850 val_loss: 0.19625602662563324, train_loss: 0.044464752078056335\n",
            "21860 val_loss: 0.17944326996803284, train_loss: 0.0398549847304821\n",
            "21870 val_loss: 0.19035232067108154, train_loss: 0.03814893215894699\n",
            "21880 val_loss: 0.1925145983695984, train_loss: 0.03811883553862572\n",
            "21890 val_loss: 0.18628530204296112, train_loss: 0.03821467608213425\n",
            "21900 val_loss: 0.18692830204963684, train_loss: 0.036929477006196976\n",
            "21910 val_loss: 0.18766863644123077, train_loss: 0.03794410452246666\n",
            "21920 val_loss: 0.18076279759407043, train_loss: 0.037690769881010056\n",
            "21930 val_loss: 0.1846965104341507, train_loss: 0.04020892456173897\n",
            "21940 val_loss: 0.19454050064086914, train_loss: 0.03723513334989548\n",
            "21950 val_loss: 0.18046033382415771, train_loss: 0.03766873851418495\n",
            "21960 val_loss: 0.18591034412384033, train_loss: 0.03797132894396782\n",
            "21970 val_loss: 0.18414384126663208, train_loss: 0.03669862076640129\n",
            "21980 val_loss: 0.20577162504196167, train_loss: 0.039837222546339035\n",
            "21990 val_loss: 0.1859876811504364, train_loss: 0.03697643801569939\n",
            "22000 val_loss: 0.19465310871601105, train_loss: 0.042033955454826355\n",
            "22010 val_loss: 0.20016002655029297, train_loss: 0.03912501782178879\n",
            "22020 val_loss: 0.19840848445892334, train_loss: 0.038331009447574615\n",
            "22030 val_loss: 0.19133733212947845, train_loss: 0.0444413386285305\n",
            "22040 val_loss: 0.17817480862140656, train_loss: 0.0369812548160553\n",
            "22050 val_loss: 0.18853142857551575, train_loss: 0.03795123100280762\n",
            "22060 val_loss: 0.18746964633464813, train_loss: 0.03867015615105629\n",
            "22070 val_loss: 0.1952780932188034, train_loss: 0.03851054236292839\n",
            "22080 val_loss: 0.19370368123054504, train_loss: 0.03669119253754616\n",
            "22090 val_loss: 0.18796102702617645, train_loss: 0.03647175803780556\n",
            "22100 val_loss: 0.1896742582321167, train_loss: 0.03578297048807144\n",
            "22110 val_loss: 0.18900839984416962, train_loss: 0.03543771430850029\n",
            "22120 val_loss: 0.17769978940486908, train_loss: 0.036211248487234116\n",
            "22130 val_loss: 0.17443720996379852, train_loss: 0.038897063583135605\n",
            "22140 val_loss: 0.1810339242219925, train_loss: 0.03574972599744797\n",
            "22150 val_loss: 0.192079097032547, train_loss: 0.03597375750541687\n",
            "22160 val_loss: 0.18982353806495667, train_loss: 0.04019470512866974\n",
            "22170 val_loss: 0.1882600486278534, train_loss: 0.03386629745364189\n",
            "22180 val_loss: 0.20322231948375702, train_loss: 0.036861710250377655\n",
            "22190 val_loss: 0.18860092759132385, train_loss: 0.0339353121817112\n",
            "22200 val_loss: 0.1995185911655426, train_loss: 0.037473585456609726\n",
            "22210 val_loss: 0.19925205409526825, train_loss: 0.035266753286123276\n",
            "22220 val_loss: 0.18847404420375824, train_loss: 0.03336285054683685\n",
            "22230 val_loss: 0.18515342473983765, train_loss: 0.03316742181777954\n",
            "22240 val_loss: 0.18600477278232574, train_loss: 0.03538259118795395\n",
            "22250 val_loss: 0.23297838866710663, train_loss: 0.048375699669122696\n",
            "22260 val_loss: 0.18220731616020203, train_loss: 0.03399215638637543\n",
            "22270 val_loss: 0.18248778581619263, train_loss: 0.03455841541290283\n",
            "22280 val_loss: 0.1921953707933426, train_loss: 0.03388720378279686\n",
            "22290 val_loss: 0.21106702089309692, train_loss: 0.042325809597969055\n",
            "22300 val_loss: 0.2125294953584671, train_loss: 0.03947797417640686\n",
            "22310 val_loss: 0.1973458081483841, train_loss: 0.03656424209475517\n",
            "22320 val_loss: 0.1943235844373703, train_loss: 0.03468039259314537\n",
            "22330 val_loss: 0.19341400265693665, train_loss: 0.034885626286268234\n",
            "22340 val_loss: 0.18794505298137665, train_loss: 0.033095747232437134\n",
            "22350 val_loss: 0.18007376790046692, train_loss: 0.03331456705927849\n",
            "22360 val_loss: 0.193732351064682, train_loss: 0.03309149295091629\n",
            "22370 val_loss: 0.1859084516763687, train_loss: 0.03246970847249031\n",
            "22380 val_loss: 0.20356573164463043, train_loss: 0.03406175971031189\n",
            "22390 val_loss: 0.20382706820964813, train_loss: 0.03895633667707443\n",
            "22400 val_loss: 0.1822194755077362, train_loss: 0.033773377537727356\n",
            "22410 val_loss: 0.17433221638202667, train_loss: 0.03378383442759514\n",
            "22420 val_loss: 0.19691628217697144, train_loss: 0.035026758909225464\n",
            "22430 val_loss: 0.1804412603378296, train_loss: 0.033121030777692795\n",
            "22440 val_loss: 0.17861860990524292, train_loss: 0.03358922526240349\n",
            "22450 val_loss: 0.17732849717140198, train_loss: 0.031826164573431015\n",
            "22460 val_loss: 0.23302650451660156, train_loss: 0.05310353636741638\n",
            "22470 val_loss: 0.1836894154548645, train_loss: 0.032245710492134094\n",
            "22480 val_loss: 0.18310803174972534, train_loss: 0.033136192709207535\n",
            "22490 val_loss: 0.17997176945209503, train_loss: 0.03276144340634346\n",
            "22500 val_loss: 0.20844538509845734, train_loss: 0.037048112601041794\n",
            "22510 val_loss: 0.18320180475711823, train_loss: 0.03162773698568344\n",
            "22520 val_loss: 0.17481663823127747, train_loss: 0.03262079879641533\n",
            "22530 val_loss: 0.18507112562656403, train_loss: 0.03220612183213234\n",
            "22540 val_loss: 0.22045910358428955, train_loss: 0.039596110582351685\n",
            "22550 val_loss: 0.18507978320121765, train_loss: 0.03197959065437317\n",
            "22560 val_loss: 0.1870168149471283, train_loss: 0.031776994466781616\n",
            "22570 val_loss: 0.18825097382068634, train_loss: 0.03255356475710869\n",
            "22580 val_loss: 0.18803207576274872, train_loss: 0.03118644841015339\n",
            "22590 val_loss: 0.1822802722454071, train_loss: 0.03130527585744858\n",
            "22600 val_loss: 0.1941775381565094, train_loss: 0.031375203281641006\n",
            "22610 val_loss: 0.18322789669036865, train_loss: 0.03109568916261196\n",
            "22620 val_loss: 0.188035249710083, train_loss: 0.030978988856077194\n",
            "22630 val_loss: 0.17834091186523438, train_loss: 0.03153526037931442\n",
            "22640 val_loss: 0.18152737617492676, train_loss: 0.030319998040795326\n",
            "22650 val_loss: 0.1896190494298935, train_loss: 0.03142966702580452\n",
            "22660 val_loss: 0.1814541518688202, train_loss: 0.03125453740358353\n",
            "22670 val_loss: 0.22117237746715546, train_loss: 0.03719373047351837\n",
            "22680 val_loss: 0.18006011843681335, train_loss: 0.030113158747553825\n",
            "22690 val_loss: 0.1911579966545105, train_loss: 0.031243255361914635\n",
            "22700 val_loss: 0.18660935759544373, train_loss: 0.029831567779183388\n",
            "22710 val_loss: 0.1867118924856186, train_loss: 0.029943762347102165\n",
            "22720 val_loss: 0.18587589263916016, train_loss: 0.029836544767022133\n",
            "22730 val_loss: 0.18460282683372498, train_loss: 0.029824957251548767\n",
            "22740 val_loss: 0.19500038027763367, train_loss: 0.03029305301606655\n",
            "22750 val_loss: 0.1790052205324173, train_loss: 0.029448971152305603\n",
            "22760 val_loss: 0.19415916502475739, train_loss: 0.03036738745868206\n",
            "22770 val_loss: 0.1894785761833191, train_loss: 0.028975948691368103\n",
            "22780 val_loss: 0.200058713555336, train_loss: 0.029887866228818893\n",
            "22790 val_loss: 0.17852027714252472, train_loss: 0.028987932950258255\n",
            "22800 val_loss: 0.18262271583080292, train_loss: 0.029545331373810768\n",
            "22810 val_loss: 0.19340337812900543, train_loss: 0.029083339497447014\n",
            "22820 val_loss: 0.18820010125637054, train_loss: 0.028582952916622162\n",
            "22830 val_loss: 0.192174032330513, train_loss: 0.028920339420437813\n",
            "22840 val_loss: 0.19298943877220154, train_loss: 0.028602728620171547\n",
            "22850 val_loss: 0.18156498670578003, train_loss: 0.02897322177886963\n",
            "22860 val_loss: 0.21415889263153076, train_loss: 0.03347509354352951\n",
            "22870 val_loss: 0.18012627959251404, train_loss: 0.030703630298376083\n",
            "22880 val_loss: 0.18229784071445465, train_loss: 0.02802041545510292\n",
            "22890 val_loss: 0.2105812281370163, train_loss: 0.030540505424141884\n",
            "22900 val_loss: 0.2201056182384491, train_loss: 0.03580079600214958\n",
            "22910 val_loss: 0.1830599009990692, train_loss: 0.028386304154992104\n",
            "22920 val_loss: 0.18697531521320343, train_loss: 0.028441833332180977\n",
            "22930 val_loss: 0.18695737421512604, train_loss: 0.03193003684282303\n",
            "22940 val_loss: 0.1824939250946045, train_loss: 0.028517620638012886\n",
            "22950 val_loss: 0.19260752201080322, train_loss: 0.028599407523870468\n",
            "22960 val_loss: 0.18420375883579254, train_loss: 0.028109826147556305\n",
            "22970 val_loss: 0.19334116578102112, train_loss: 0.02797018550336361\n",
            "22980 val_loss: 0.18210802972316742, train_loss: 0.02997518889605999\n",
            "22990 val_loss: 0.1939469575881958, train_loss: 0.027331378310918808\n",
            "23000 val_loss: 0.19334831833839417, train_loss: 0.027469037100672722\n",
            "23010 val_loss: 0.1824759989976883, train_loss: 0.02775731310248375\n",
            "23020 val_loss: 0.19221827387809753, train_loss: 0.028947101905941963\n",
            "23030 val_loss: 0.20306642353534698, train_loss: 0.027949800714850426\n",
            "23040 val_loss: 0.18523819744586945, train_loss: 0.027266383171081543\n",
            "23050 val_loss: 0.20576874911785126, train_loss: 0.029082147404551506\n",
            "23060 val_loss: 0.2009274661540985, train_loss: 0.027186261489987373\n",
            "23070 val_loss: 0.20194782316684723, train_loss: 0.034842606633901596\n",
            "23080 val_loss: 0.21333195269107819, train_loss: 0.02919091284275055\n",
            "23090 val_loss: 0.21022769808769226, train_loss: 0.027335619553923607\n",
            "23100 val_loss: 0.2028677761554718, train_loss: 0.028136318549513817\n",
            "23110 val_loss: 0.18221740424633026, train_loss: 0.026937315240502357\n",
            "23120 val_loss: 0.185824915766716, train_loss: 0.026694538071751595\n",
            "23130 val_loss: 0.215891495347023, train_loss: 0.02968456782400608\n",
            "23140 val_loss: 0.19289454817771912, train_loss: 0.028088588267564774\n",
            "23150 val_loss: 0.20529524981975555, train_loss: 0.02848866768181324\n",
            "23160 val_loss: 0.18764400482177734, train_loss: 0.026077240705490112\n",
            "23170 val_loss: 0.17734654247760773, train_loss: 0.027684364467859268\n",
            "23180 val_loss: 0.1930118054151535, train_loss: 0.02670353092253208\n",
            "23190 val_loss: 0.21838156878948212, train_loss: 0.02943936362862587\n",
            "23200 val_loss: 0.1972687989473343, train_loss: 0.026148676872253418\n",
            "23210 val_loss: 0.199275940656662, train_loss: 0.025877580046653748\n",
            "23220 val_loss: 0.1905984878540039, train_loss: 0.026702219620347023\n",
            "23230 val_loss: 0.19785210490226746, train_loss: 0.026913536712527275\n",
            "23240 val_loss: 0.19206593930721283, train_loss: 0.026934485882520676\n",
            "23250 val_loss: 0.21065035462379456, train_loss: 0.02911161631345749\n",
            "23260 val_loss: 0.18530936539173126, train_loss: 0.026545325294137\n",
            "23270 val_loss: 0.22482971847057343, train_loss: 0.030939271673560143\n",
            "23280 val_loss: 0.18878786265850067, train_loss: 0.025500742718577385\n",
            "23290 val_loss: 0.18780453503131866, train_loss: 0.03857891261577606\n",
            "23300 val_loss: 0.18246601521968842, train_loss: 0.02554282918572426\n",
            "23310 val_loss: 0.1920674443244934, train_loss: 0.025475531816482544\n",
            "23320 val_loss: 0.2143632173538208, train_loss: 0.029599864035844803\n",
            "23330 val_loss: 0.1864926666021347, train_loss: 0.0256318561732769\n",
            "23340 val_loss: 0.18344388902187347, train_loss: 0.029119079932570457\n",
            "23350 val_loss: 0.1985863894224167, train_loss: 0.0261215977370739\n",
            "23360 val_loss: 0.19755159318447113, train_loss: 0.025358619168400764\n",
            "23370 val_loss: 0.18791979551315308, train_loss: 0.026293836534023285\n",
            "23380 val_loss: 0.20254459977149963, train_loss: 0.028562244027853012\n",
            "23390 val_loss: 0.20452263951301575, train_loss: 0.02595570683479309\n",
            "23400 val_loss: 0.20603811740875244, train_loss: 0.027915827929973602\n",
            "23410 val_loss: 0.20199550688266754, train_loss: 0.025517180562019348\n",
            "23420 val_loss: 0.1931818276643753, train_loss: 0.02509506605565548\n",
            "23430 val_loss: 0.18202781677246094, train_loss: 0.02550389990210533\n",
            "23440 val_loss: 0.22248445451259613, train_loss: 0.027438005432486534\n",
            "23450 val_loss: 0.19337418675422668, train_loss: 0.024802595376968384\n",
            "23460 val_loss: 0.20414084196090698, train_loss: 0.02498677372932434\n",
            "23470 val_loss: 0.18953262269496918, train_loss: 0.024082960560917854\n",
            "23480 val_loss: 0.2256900668144226, train_loss: 0.02809201180934906\n",
            "23490 val_loss: 0.18431514501571655, train_loss: 0.025357823818922043\n",
            "23500 val_loss: 0.19442041218280792, train_loss: 0.031168203800916672\n",
            "23510 val_loss: 0.18144913017749786, train_loss: 0.025077009573578835\n",
            "23520 val_loss: 0.20330029726028442, train_loss: 0.02461186982691288\n",
            "23530 val_loss: 0.1994251310825348, train_loss: 0.02434619329869747\n",
            "23540 val_loss: 0.19177791476249695, train_loss: 0.02364319935441017\n",
            "23550 val_loss: 0.18747474253177643, train_loss: 0.0236563291400671\n",
            "23560 val_loss: 0.17871297895908356, train_loss: 0.023649094626307487\n",
            "23570 val_loss: 0.18885429203510284, train_loss: 0.023155294358730316\n",
            "23580 val_loss: 0.2227664738893509, train_loss: 0.025673935189843178\n",
            "23590 val_loss: 0.1952841430902481, train_loss: 0.024561546742916107\n",
            "23600 val_loss: 0.1976993829011917, train_loss: 0.024161148816347122\n",
            "23610 val_loss: 0.2015230804681778, train_loss: 0.02433604933321476\n",
            "23620 val_loss: 0.1921386420726776, train_loss: 0.02440272830426693\n",
            "23630 val_loss: 0.185200035572052, train_loss: 0.02429051138460636\n",
            "23640 val_loss: 0.1778990924358368, train_loss: 0.024377409368753433\n",
            "23650 val_loss: 0.19021721184253693, train_loss: 0.023308593779802322\n",
            "23660 val_loss: 0.19268426299095154, train_loss: 0.02300151064991951\n",
            "23670 val_loss: 0.19142796099185944, train_loss: 0.02335408702492714\n",
            "23680 val_loss: 0.20063820481300354, train_loss: 0.022482655942440033\n",
            "23690 val_loss: 0.20841889083385468, train_loss: 0.02335091307759285\n",
            "23700 val_loss: 0.2048206627368927, train_loss: 0.023280933499336243\n",
            "23710 val_loss: 0.19271212816238403, train_loss: 0.023126747459173203\n",
            "23720 val_loss: 0.20531263947486877, train_loss: 0.022666960954666138\n",
            "23730 val_loss: 0.19331489503383636, train_loss: 0.022804878652095795\n",
            "23740 val_loss: 0.18784978985786438, train_loss: 0.022873228415846825\n",
            "23750 val_loss: 0.19418877363204956, train_loss: 0.022046174854040146\n",
            "23760 val_loss: 0.1949337273836136, train_loss: 0.02202734723687172\n",
            "23770 val_loss: 0.22297625243663788, train_loss: 0.023859165608882904\n",
            "23780 val_loss: 0.1912110149860382, train_loss: 0.02206386812031269\n",
            "23790 val_loss: 0.18840210139751434, train_loss: 0.02222357504069805\n",
            "23800 val_loss: 0.2007051408290863, train_loss: 0.0320001021027565\n",
            "23810 val_loss: 0.2035467028617859, train_loss: 0.022826025262475014\n",
            "23820 val_loss: 0.20504800975322723, train_loss: 0.022779585793614388\n",
            "23830 val_loss: 0.21505112946033478, train_loss: 0.0234820693731308\n",
            "23840 val_loss: 0.1911291778087616, train_loss: 0.02245083637535572\n",
            "23850 val_loss: 0.22307486832141876, train_loss: 0.02334139123558998\n",
            "23860 val_loss: 0.2052610069513321, train_loss: 0.022144248709082603\n",
            "23870 val_loss: 0.1920841932296753, train_loss: 0.022673455998301506\n",
            "23880 val_loss: 0.20086036622524261, train_loss: 0.021725589409470558\n",
            "23890 val_loss: 0.19594065845012665, train_loss: 0.02292959950864315\n",
            "23900 val_loss: 0.19632495939731598, train_loss: 0.021821483969688416\n",
            "23910 val_loss: 0.1904827505350113, train_loss: 0.021390484645962715\n",
            "23920 val_loss: 0.1993229240179062, train_loss: 0.021616846323013306\n",
            "23930 val_loss: 0.18611161410808563, train_loss: 0.022348197177052498\n",
            "23940 val_loss: 0.20680761337280273, train_loss: 0.021579233929514885\n",
            "23950 val_loss: 0.2039712518453598, train_loss: 0.02235073409974575\n",
            "23960 val_loss: 0.20924554765224457, train_loss: 0.02204916439950466\n",
            "23970 val_loss: 0.2033117562532425, train_loss: 0.02351268008351326\n",
            "23980 val_loss: 0.19424061477184296, train_loss: 0.02134212851524353\n",
            "23990 val_loss: 0.1845337599515915, train_loss: 0.022153329104185104\n",
            "24000 val_loss: 0.19944779574871063, train_loss: 0.02254779264330864\n",
            "24010 val_loss: 0.19048811495304108, train_loss: 0.021064160391688347\n",
            "24020 val_loss: 0.24397173523902893, train_loss: 0.032959599047899246\n",
            "24030 val_loss: 0.2104559689760208, train_loss: 0.022184032946825027\n",
            "24040 val_loss: 0.19543607532978058, train_loss: 0.021373167634010315\n",
            "24050 val_loss: 0.20461459457874298, train_loss: 0.02175881154835224\n",
            "24060 val_loss: 0.19934971630573273, train_loss: 0.02066466584801674\n",
            "24070 val_loss: 0.20267443358898163, train_loss: 0.020688746124505997\n",
            "24080 val_loss: 0.21775463223457336, train_loss: 0.023178959265351295\n",
            "24090 val_loss: 0.19813281297683716, train_loss: 0.02088465541601181\n",
            "24100 val_loss: 0.19772231578826904, train_loss: 0.021482175216078758\n",
            "24110 val_loss: 0.20627377927303314, train_loss: 0.021468212828040123\n",
            "24120 val_loss: 0.19047468900680542, train_loss: 0.022123772650957108\n",
            "24130 val_loss: 0.20326198637485504, train_loss: 0.02071344293653965\n",
            "24140 val_loss: 0.2145865112543106, train_loss: 0.020935537293553352\n",
            "24150 val_loss: 0.2299434393644333, train_loss: 0.02330659329891205\n",
            "24160 val_loss: 0.23738527297973633, train_loss: 0.026030078530311584\n",
            "24170 val_loss: 0.2502651810646057, train_loss: 0.03156176209449768\n",
            "24180 val_loss: 0.20485687255859375, train_loss: 0.020691726356744766\n",
            "24190 val_loss: 0.1959196925163269, train_loss: 0.020861387252807617\n",
            "24200 val_loss: 0.19245295226573944, train_loss: 0.020118119195103645\n",
            "24210 val_loss: 0.19425013661384583, train_loss: 0.020382480695843697\n",
            "24220 val_loss: 0.21579548716545105, train_loss: 0.02289309725165367\n",
            "24230 val_loss: 0.2019656002521515, train_loss: 0.020324572920799255\n",
            "24240 val_loss: 0.18423056602478027, train_loss: 0.02154463902115822\n",
            "24250 val_loss: 0.192023366689682, train_loss: 0.02195890247821808\n",
            "24260 val_loss: 0.1951923370361328, train_loss: 0.019840339198708534\n",
            "24270 val_loss: 0.19187228381633759, train_loss: 0.01994096115231514\n",
            "24280 val_loss: 0.18528488278388977, train_loss: 0.019815191626548767\n",
            "24290 val_loss: 0.21602512896060944, train_loss: 0.021322105079889297\n",
            "24300 val_loss: 0.1873435080051422, train_loss: 0.01960744522511959\n",
            "24310 val_loss: 0.19688370823860168, train_loss: 0.019920412451028824\n",
            "24320 val_loss: 0.19494113326072693, train_loss: 0.020214343443512917\n",
            "24330 val_loss: 0.22997726500034332, train_loss: 0.022920796647667885\n",
            "24340 val_loss: 0.21209046244621277, train_loss: 0.020693572238087654\n",
            "24350 val_loss: 0.22856882214546204, train_loss: 0.02196456305682659\n",
            "24360 val_loss: 0.20136569440364838, train_loss: 0.01954684965312481\n",
            "24370 val_loss: 0.20162786543369293, train_loss: 0.019452912732958794\n",
            "24380 val_loss: 0.2337685525417328, train_loss: 0.02247491106390953\n",
            "24390 val_loss: 0.21336005628108978, train_loss: 0.020603908225893974\n",
            "24400 val_loss: 0.19554445147514343, train_loss: 0.020052378997206688\n",
            "24410 val_loss: 0.2473575919866562, train_loss: 0.024660659953951836\n",
            "24420 val_loss: 0.20527036488056183, train_loss: 0.01993480511009693\n",
            "24430 val_loss: 0.1952129304409027, train_loss: 0.02009442448616028\n",
            "24440 val_loss: 0.1960199922323227, train_loss: 0.020475849509239197\n",
            "24450 val_loss: 0.22704671323299408, train_loss: 0.02090410329401493\n",
            "24460 val_loss: 0.2357349842786789, train_loss: 0.02470865286886692\n",
            "24470 val_loss: 0.216922789812088, train_loss: 0.020532917231321335\n",
            "24480 val_loss: 0.1940399408340454, train_loss: 0.01916283182799816\n",
            "24490 val_loss: 0.2141740471124649, train_loss: 0.020298883318901062\n",
            "24500 val_loss: 0.2796192765235901, train_loss: 0.037127748131752014\n",
            "24510 val_loss: 0.2121996134519577, train_loss: 0.019674722105264664\n",
            "24520 val_loss: 0.20930689573287964, train_loss: 0.019043032079935074\n",
            "24530 val_loss: 0.1932002753019333, train_loss: 0.018819263204932213\n",
            "24540 val_loss: 0.18517695367336273, train_loss: 0.019098423421382904\n",
            "24550 val_loss: 0.2036137878894806, train_loss: 0.019807571545243263\n",
            "24560 val_loss: 0.18260863423347473, train_loss: 0.019201816990971565\n",
            "24570 val_loss: 0.21798545122146606, train_loss: 0.020231669768691063\n",
            "24580 val_loss: 0.21888837218284607, train_loss: 0.02076021581888199\n",
            "24590 val_loss: 0.20981009304523468, train_loss: 0.0191353652626276\n",
            "24600 val_loss: 0.22433072328567505, train_loss: 0.020649613812565804\n",
            "24610 val_loss: 0.20332863926887512, train_loss: 0.018842818215489388\n",
            "24620 val_loss: 0.20884093642234802, train_loss: 0.03212040662765503\n",
            "24630 val_loss: 0.22511743009090424, train_loss: 0.020258130505681038\n",
            "24640 val_loss: 0.19720397889614105, train_loss: 0.01862080954015255\n",
            "24650 val_loss: 0.21141698956489563, train_loss: 0.019313229247927666\n",
            "24660 val_loss: 0.2048581838607788, train_loss: 0.018477676436305046\n",
            "24670 val_loss: 0.21991468966007233, train_loss: 0.019316447898745537\n",
            "24680 val_loss: 0.207621231675148, train_loss: 0.01826854981482029\n",
            "24690 val_loss: 0.18335826694965363, train_loss: 0.020830854773521423\n",
            "24700 val_loss: 0.2127261906862259, train_loss: 0.018582776188850403\n",
            "24710 val_loss: 0.1876964569091797, train_loss: 0.019380059093236923\n",
            "24720 val_loss: 0.19848787784576416, train_loss: 0.018839886412024498\n",
            "24730 val_loss: 0.2324863225221634, train_loss: 0.022148873656988144\n",
            "24740 val_loss: 0.22260752320289612, train_loss: 0.021660592406988144\n",
            "24750 val_loss: 0.20825029909610748, train_loss: 0.01867786794900894\n",
            "24760 val_loss: 0.24230659008026123, train_loss: 0.022821439430117607\n",
            "24770 val_loss: 0.23290234804153442, train_loss: 0.02241450734436512\n",
            "24780 val_loss: 0.1961425393819809, train_loss: 0.01909557916224003\n",
            "24790 val_loss: 0.21057605743408203, train_loss: 0.01895906962454319\n",
            "24800 val_loss: 0.20877300202846527, train_loss: 0.01844150573015213\n",
            "24810 val_loss: 0.20142138004302979, train_loss: 0.018015680834650993\n",
            "24820 val_loss: 0.20316264033317566, train_loss: 0.01766761764883995\n",
            "24830 val_loss: 0.2039232701063156, train_loss: 0.018273962661623955\n",
            "24840 val_loss: 0.2191760390996933, train_loss: 0.018678538501262665\n",
            "24850 val_loss: 0.18989861011505127, train_loss: 0.01833973079919815\n",
            "24860 val_loss: 0.2183839976787567, train_loss: 0.017830047756433487\n",
            "24870 val_loss: 0.2080557942390442, train_loss: 0.020405389368534088\n",
            "24880 val_loss: 0.1930009126663208, train_loss: 0.018612392246723175\n",
            "24890 val_loss: 0.21288147568702698, train_loss: 0.017742473632097244\n",
            "24900 val_loss: 0.21515223383903503, train_loss: 0.018309568986296654\n",
            "24910 val_loss: 0.20766031742095947, train_loss: 0.019564472138881683\n",
            "24920 val_loss: 0.21186576783657074, train_loss: 0.01774974912405014\n",
            "24930 val_loss: 0.21518342196941376, train_loss: 0.017887698486447334\n",
            "24940 val_loss: 0.23141267895698547, train_loss: 0.02079312689602375\n",
            "24950 val_loss: 0.21059343218803406, train_loss: 0.018210778012871742\n",
            "24960 val_loss: 0.19999127089977264, train_loss: 0.017439724877476692\n",
            "24970 val_loss: 0.19164323806762695, train_loss: 0.017809255048632622\n",
            "24980 val_loss: 0.1771194040775299, train_loss: 0.01882016845047474\n",
            "24990 val_loss: 0.21245449781417847, train_loss: 0.018641967326402664\n",
            "25000 val_loss: 0.22351516783237457, train_loss: 0.0189619529992342\n",
            "25010 val_loss: 0.22304977476596832, train_loss: 0.018154732882976532\n",
            "25020 val_loss: 0.21782588958740234, train_loss: 0.017994755879044533\n",
            "25030 val_loss: 0.199592724442482, train_loss: 0.018752356991171837\n",
            "25040 val_loss: 0.20087668299674988, train_loss: 0.018504474312067032\n",
            "25050 val_loss: 0.20328456163406372, train_loss: 0.020538851618766785\n",
            "25060 val_loss: 0.20563824474811554, train_loss: 0.018953368067741394\n",
            "25070 val_loss: 0.19968077540397644, train_loss: 0.017758192494511604\n",
            "25080 val_loss: 0.1943918913602829, train_loss: 0.017927484586834908\n",
            "25090 val_loss: 0.21794192492961884, train_loss: 0.01780012995004654\n",
            "25100 val_loss: 0.2125941663980484, train_loss: 0.017359614372253418\n",
            "25110 val_loss: 0.23566019535064697, train_loss: 0.018615486100316048\n",
            "25120 val_loss: 0.20954188704490662, train_loss: 0.017501773312687874\n",
            "25130 val_loss: 0.2529234290122986, train_loss: 0.02558257058262825\n",
            "25140 val_loss: 0.18867121636867523, train_loss: 0.018913164734840393\n",
            "25150 val_loss: 0.19607755541801453, train_loss: 0.01827908493578434\n",
            "25160 val_loss: 0.20893530547618866, train_loss: 0.018613839522004128\n",
            "25170 val_loss: 0.2066412717103958, train_loss: 0.017879128456115723\n",
            "25180 val_loss: 0.2087247669696808, train_loss: 0.017264749854803085\n",
            "25190 val_loss: 0.2037142515182495, train_loss: 0.018237357959151268\n",
            "25200 val_loss: 0.25055769085884094, train_loss: 0.02241811901330948\n",
            "25210 val_loss: 0.20530062913894653, train_loss: 0.017125438898801804\n",
            "25220 val_loss: 0.2475871592760086, train_loss: 0.01850057952105999\n",
            "25230 val_loss: 0.20636606216430664, train_loss: 0.01756562851369381\n",
            "25240 val_loss: 0.22654177248477936, train_loss: 0.017252065241336823\n",
            "25250 val_loss: 0.21819718182086945, train_loss: 0.016687244176864624\n",
            "25260 val_loss: 0.19992126524448395, train_loss: 0.016709942370653152\n",
            "25270 val_loss: 0.20408537983894348, train_loss: 0.0190594345331192\n",
            "25280 val_loss: 0.23733456432819366, train_loss: 0.020300524309277534\n",
            "25290 val_loss: 0.21845725178718567, train_loss: 0.01694650389254093\n",
            "25300 val_loss: 0.2231999635696411, train_loss: 0.017348719760775566\n",
            "25310 val_loss: 0.2539766728878021, train_loss: 0.02081506885588169\n",
            "25320 val_loss: 0.22285301983356476, train_loss: 0.01726977527141571\n",
            "25330 val_loss: 0.20663143694400787, train_loss: 0.01649685576558113\n",
            "25340 val_loss: 0.20343796908855438, train_loss: 0.017001325264573097\n",
            "25350 val_loss: 0.25098106265068054, train_loss: 0.021380752325057983\n",
            "25360 val_loss: 0.21275365352630615, train_loss: 0.016826195642352104\n",
            "25370 val_loss: 0.1909143328666687, train_loss: 0.018741974607110023\n",
            "25380 val_loss: 0.2202473133802414, train_loss: 0.01782231032848358\n",
            "25390 val_loss: 0.21262329816818237, train_loss: 0.01655072160065174\n",
            "25400 val_loss: 0.21517299115657806, train_loss: 0.016661906614899635\n",
            "25410 val_loss: 0.20423775911331177, train_loss: 0.0169761311262846\n",
            "25420 val_loss: 0.22547399997711182, train_loss: 0.016244636848568916\n",
            "25430 val_loss: 0.2042454481124878, train_loss: 0.016253693029284477\n",
            "25440 val_loss: 0.22741076350212097, train_loss: 0.017952287569642067\n",
            "25450 val_loss: 0.19066989421844482, train_loss: 0.018445240333676338\n",
            "25460 val_loss: 0.20029853284358978, train_loss: 0.0172988660633564\n",
            "25470 val_loss: 0.20886312425136566, train_loss: 0.016942482441663742\n",
            "25480 val_loss: 0.2053726464509964, train_loss: 0.01821233332157135\n",
            "25490 val_loss: 0.23272371292114258, train_loss: 0.017473530024290085\n",
            "25500 val_loss: 0.20326487720012665, train_loss: 0.017366919666528702\n",
            "25510 val_loss: 0.19620881974697113, train_loss: 0.016672451049089432\n",
            "25520 val_loss: 0.19912759959697723, train_loss: 0.017163818702101707\n",
            "25530 val_loss: 0.23575258255004883, train_loss: 0.017903171479701996\n",
            "25540 val_loss: 0.20485635101795197, train_loss: 0.016456475481390953\n",
            "25550 val_loss: 0.22520503401756287, train_loss: 0.017909934744238853\n",
            "25560 val_loss: 0.24875123798847198, train_loss: 0.0192874688655138\n",
            "25570 val_loss: 0.2149345576763153, train_loss: 0.016187995672225952\n",
            "25580 val_loss: 0.22139498591423035, train_loss: 0.016008611768484116\n",
            "25590 val_loss: 0.21463124454021454, train_loss: 0.015668241307139397\n",
            "25600 val_loss: 0.20574985444545746, train_loss: 0.01581311784684658\n",
            "25610 val_loss: 0.20807620882987976, train_loss: 0.01775006204843521\n",
            "25620 val_loss: 0.23280777037143707, train_loss: 0.018674885854125023\n",
            "25630 val_loss: 0.20449316501617432, train_loss: 0.016410214826464653\n",
            "25640 val_loss: 0.21583527326583862, train_loss: 0.015509014017879963\n",
            "25650 val_loss: 0.21710725128650665, train_loss: 0.01608542539179325\n",
            "25660 val_loss: 0.20735974609851837, train_loss: 0.015289796516299248\n",
            "25670 val_loss: 0.2165994942188263, train_loss: 0.015549920499324799\n",
            "25680 val_loss: 0.20048461854457855, train_loss: 0.01659436710178852\n",
            "25690 val_loss: 0.21361973881721497, train_loss: 0.015415720641613007\n",
            "25700 val_loss: 0.2662009596824646, train_loss: 0.024938203394412994\n",
            "25710 val_loss: 0.22698384523391724, train_loss: 0.016010968014597893\n",
            "25720 val_loss: 0.23878994584083557, train_loss: 0.016534410417079926\n",
            "25730 val_loss: 0.20945203304290771, train_loss: 0.015518497675657272\n",
            "25740 val_loss: 0.19482773542404175, train_loss: 0.015722820535302162\n",
            "25750 val_loss: 0.19517028331756592, train_loss: 0.015775956213474274\n",
            "25760 val_loss: 0.2243017703294754, train_loss: 0.0174733716994524\n",
            "25770 val_loss: 0.20271332561969757, train_loss: 0.01569775491952896\n",
            "25780 val_loss: 0.20291411876678467, train_loss: 0.01594824530184269\n",
            "25790 val_loss: 0.24539339542388916, train_loss: 0.01777901127934456\n",
            "25800 val_loss: 0.2078504115343094, train_loss: 0.015690216794610023\n",
            "25810 val_loss: 0.2262081801891327, train_loss: 0.01610729843378067\n",
            "25820 val_loss: 0.21404972672462463, train_loss: 0.015476559288799763\n",
            "25830 val_loss: 0.20762205123901367, train_loss: 0.015706708654761314\n",
            "25840 val_loss: 0.24131104350090027, train_loss: 0.017969584092497826\n",
            "25850 val_loss: 0.21581675112247467, train_loss: 0.015797005966305733\n",
            "25860 val_loss: 0.2024424821138382, train_loss: 0.016968291252851486\n",
            "25870 val_loss: 0.2251279503107071, train_loss: 0.01571761444211006\n",
            "25880 val_loss: 0.24263417720794678, train_loss: 0.01781393773853779\n",
            "25890 val_loss: 0.25627291202545166, train_loss: 0.01919565722346306\n",
            "25900 val_loss: 0.19773682951927185, train_loss: 0.016220584511756897\n",
            "25910 val_loss: 0.21950851380825043, train_loss: 0.015238432213664055\n",
            "25920 val_loss: 0.23228459060192108, train_loss: 0.01567966863512993\n",
            "25930 val_loss: 0.2398512065410614, train_loss: 0.015047787688672543\n",
            "25940 val_loss: 0.2547290027141571, train_loss: 0.017586341127753258\n",
            "25950 val_loss: 0.23410388827323914, train_loss: 0.01513319555670023\n",
            "25960 val_loss: 0.2251410037279129, train_loss: 0.014664736576378345\n",
            "25970 val_loss: 0.21488766372203827, train_loss: 0.01480907667428255\n",
            "25980 val_loss: 0.23570312559604645, train_loss: 0.015685860067605972\n",
            "25990 val_loss: 0.23735877871513367, train_loss: 0.017624955624341965\n",
            "26000 val_loss: 0.21084162592887878, train_loss: 0.015550171956419945\n",
            "26010 val_loss: 0.2197820544242859, train_loss: 0.015134760178625584\n",
            "26020 val_loss: 0.21388886868953705, train_loss: 0.015001008287072182\n",
            "26030 val_loss: 0.22002150118350983, train_loss: 0.01497102901339531\n",
            "26040 val_loss: 0.20287933945655823, train_loss: 0.015434306114912033\n",
            "26050 val_loss: 0.22592861950397491, train_loss: 0.014979366213083267\n",
            "26060 val_loss: 0.2247989922761917, train_loss: 0.015199434012174606\n",
            "26070 val_loss: 0.20298324525356293, train_loss: 0.015562816523015499\n",
            "26080 val_loss: 0.22299225628376007, train_loss: 0.01523634698241949\n",
            "26090 val_loss: 0.21111071109771729, train_loss: 0.014786922372877598\n",
            "26100 val_loss: 0.21046216785907745, train_loss: 0.015130497515201569\n",
            "26110 val_loss: 0.20660707354545593, train_loss: 0.01479358784854412\n",
            "26120 val_loss: 0.2479150891304016, train_loss: 0.01668027602136135\n",
            "26130 val_loss: 0.23392680287361145, train_loss: 0.0151749849319458\n",
            "26140 val_loss: 0.20176084339618683, train_loss: 0.015493925660848618\n",
            "26150 val_loss: 0.2206963151693344, train_loss: 0.014600327238440514\n",
            "26160 val_loss: 0.20726801455020905, train_loss: 0.016712281852960587\n",
            "26170 val_loss: 0.2138693928718567, train_loss: 0.014648353680968285\n",
            "26180 val_loss: 0.18821851909160614, train_loss: 0.016302166506648064\n",
            "26190 val_loss: 0.21421171724796295, train_loss: 0.014364891685545444\n",
            "26200 val_loss: 0.224387988448143, train_loss: 0.014774389564990997\n",
            "26210 val_loss: 0.22249573469161987, train_loss: 0.014873153530061245\n",
            "26220 val_loss: 0.23598769307136536, train_loss: 0.01566988229751587\n",
            "26230 val_loss: 0.24532178044319153, train_loss: 0.01665481925010681\n",
            "26240 val_loss: 0.23700574040412903, train_loss: 0.015906868502497673\n",
            "26250 val_loss: 0.1918516904115677, train_loss: 0.01534039992839098\n",
            "26260 val_loss: 0.24250371754169464, train_loss: 0.01593511737883091\n",
            "26270 val_loss: 0.24057629704475403, train_loss: 0.016755323857069016\n",
            "26280 val_loss: 0.22635850310325623, train_loss: 0.015301723964512348\n",
            "26290 val_loss: 0.2323550432920456, train_loss: 0.014997565187513828\n",
            "26300 val_loss: 0.2665626108646393, train_loss: 0.021371159702539444\n",
            "26310 val_loss: 0.1950330287218094, train_loss: 0.014860693365335464\n",
            "26320 val_loss: 0.21294525265693665, train_loss: 0.014635558240115643\n",
            "26330 val_loss: 0.2030610740184784, train_loss: 0.01448180340230465\n",
            "26340 val_loss: 0.22020223736763, train_loss: 0.014682948589324951\n",
            "26350 val_loss: 0.20608890056610107, train_loss: 0.015079447068274021\n",
            "26360 val_loss: 0.2192981094121933, train_loss: 0.01413038931787014\n",
            "26370 val_loss: 0.2206515371799469, train_loss: 0.014197236858308315\n",
            "26380 val_loss: 0.1975792497396469, train_loss: 0.014801555313169956\n",
            "26390 val_loss: 0.2143913060426712, train_loss: 0.013780648820102215\n",
            "26400 val_loss: 0.22696876525878906, train_loss: 0.013995012268424034\n",
            "26410 val_loss: 0.20585602521896362, train_loss: 0.01380818709731102\n",
            "26420 val_loss: 0.25152984261512756, train_loss: 0.016340110450983047\n",
            "26430 val_loss: 0.23476341366767883, train_loss: 0.014131159521639347\n",
            "26440 val_loss: 0.20648527145385742, train_loss: 0.014350867830216885\n",
            "26450 val_loss: 0.22185131907463074, train_loss: 0.013652337715029716\n",
            "26460 val_loss: 0.2844443917274475, train_loss: 0.021335499361157417\n",
            "26470 val_loss: 0.22154365479946136, train_loss: 0.013529609888792038\n",
            "26480 val_loss: 0.22018654644489288, train_loss: 0.013578666374087334\n",
            "26490 val_loss: 0.22805768251419067, train_loss: 0.013658412732183933\n",
            "26500 val_loss: 0.24946576356887817, train_loss: 0.015219959430396557\n",
            "26510 val_loss: 0.20858269929885864, train_loss: 0.014854105189442635\n",
            "26520 val_loss: 0.2387305498123169, train_loss: 0.014775986783206463\n",
            "26530 val_loss: 0.21463532745838165, train_loss: 0.013702241703867912\n",
            "26540 val_loss: 0.20767977833747864, train_loss: 0.01463621947914362\n",
            "26550 val_loss: 0.23337888717651367, train_loss: 0.014113119803369045\n",
            "26560 val_loss: 0.24478206038475037, train_loss: 0.015381316654384136\n",
            "26570 val_loss: 0.22343957424163818, train_loss: 0.01412801444530487\n",
            "26580 val_loss: 0.19863201677799225, train_loss: 0.015484238043427467\n",
            "26590 val_loss: 0.21421435475349426, train_loss: 0.015428829938173294\n",
            "26600 val_loss: 0.19726020097732544, train_loss: 0.016278821974992752\n",
            "26610 val_loss: 0.25483834743499756, train_loss: 0.016423800960183144\n",
            "26620 val_loss: 0.24440926313400269, train_loss: 0.014041312970221043\n",
            "26630 val_loss: 0.2674027979373932, train_loss: 0.017519261687994003\n",
            "26640 val_loss: 0.22573140263557434, train_loss: 0.01809556968510151\n",
            "26650 val_loss: 0.2552874684333801, train_loss: 0.018807489424943924\n",
            "26660 val_loss: 0.21794457733631134, train_loss: 0.014868230558931828\n",
            "26670 val_loss: 0.21468938887119293, train_loss: 0.014260394498705864\n",
            "26680 val_loss: 0.22616150975227356, train_loss: 0.014439553953707218\n",
            "26690 val_loss: 0.22968071699142456, train_loss: 0.014657353051006794\n",
            "26700 val_loss: 0.19596512615680695, train_loss: 0.015443040058016777\n",
            "26710 val_loss: 0.2171963006258011, train_loss: 0.013914743438363075\n",
            "26720 val_loss: 0.21088236570358276, train_loss: 0.013854077085852623\n",
            "26730 val_loss: 0.24494725465774536, train_loss: 0.021058758720755577\n",
            "26740 val_loss: 0.2007644921541214, train_loss: 0.014579028822481632\n",
            "26750 val_loss: 0.20437943935394287, train_loss: 0.01470636110752821\n",
            "26760 val_loss: 0.24462273716926575, train_loss: 0.015260087326169014\n",
            "26770 val_loss: 0.2813498079776764, train_loss: 0.019850624725222588\n",
            "26780 val_loss: 0.22217023372650146, train_loss: 0.013969417661428452\n",
            "26790 val_loss: 0.21565748751163483, train_loss: 0.01375272311270237\n",
            "26800 val_loss: 0.22913558781147003, train_loss: 0.013565842993557453\n",
            "26810 val_loss: 0.2166667878627777, train_loss: 0.013627557083964348\n",
            "26820 val_loss: 0.2000419944524765, train_loss: 0.016148043796420097\n",
            "26830 val_loss: 0.21259534358978271, train_loss: 0.013275070115923882\n",
            "26840 val_loss: 0.2183082401752472, train_loss: 0.013810587115585804\n",
            "26850 val_loss: 0.20429852604866028, train_loss: 0.01541957352310419\n",
            "26860 val_loss: 0.2007024884223938, train_loss: 0.013781814835965633\n",
            "26870 val_loss: 0.21199803054332733, train_loss: 0.012848244979977608\n",
            "26880 val_loss: 0.20264838635921478, train_loss: 0.01490300428122282\n",
            "26890 val_loss: 0.246942400932312, train_loss: 0.013669644482433796\n",
            "26900 val_loss: 0.19454994797706604, train_loss: 0.015598746947944164\n",
            "26910 val_loss: 0.23755277693271637, train_loss: 0.014812484383583069\n",
            "26920 val_loss: 0.21735993027687073, train_loss: 0.013313151895999908\n",
            "26930 val_loss: 0.221652552485466, train_loss: 0.013307062909007072\n",
            "26940 val_loss: 0.24357527494430542, train_loss: 0.014276941306889057\n",
            "26950 val_loss: 0.25576695799827576, train_loss: 0.015548222698271275\n",
            "26960 val_loss: 0.24210704863071442, train_loss: 0.014410892501473427\n",
            "26970 val_loss: 0.2483862042427063, train_loss: 0.014091080985963345\n",
            "26980 val_loss: 0.2132580429315567, train_loss: 0.013596968725323677\n",
            "26990 val_loss: 0.2186812460422516, train_loss: 0.01380484364926815\n",
            "27000 val_loss: 0.2180871069431305, train_loss: 0.013639160431921482\n",
            "27010 val_loss: 0.24257580935955048, train_loss: 0.014295042492449284\n",
            "27020 val_loss: 0.29316622018814087, train_loss: 0.022833580151200294\n",
            "27030 val_loss: 0.22033292055130005, train_loss: 0.013188929297029972\n",
            "27040 val_loss: 0.21898610889911652, train_loss: 0.013185378164052963\n",
            "27050 val_loss: 0.22731803357601166, train_loss: 0.013075434602797031\n",
            "27060 val_loss: 0.2127007246017456, train_loss: 0.013007665053009987\n",
            "27070 val_loss: 0.2356526106595993, train_loss: 0.01340301800519228\n",
            "27080 val_loss: 0.23635639250278473, train_loss: 0.013294048607349396\n",
            "27090 val_loss: 0.20297372341156006, train_loss: 0.014532176777720451\n",
            "27100 val_loss: 0.2081812024116516, train_loss: 0.013684529811143875\n",
            "27110 val_loss: 0.2398778796195984, train_loss: 0.013473636470735073\n",
            "27120 val_loss: 0.2474399358034134, train_loss: 0.014800853095948696\n",
            "27130 val_loss: 0.21975873410701752, train_loss: 0.013600914739072323\n",
            "27140 val_loss: 0.21363557875156403, train_loss: 0.0139272166416049\n",
            "27150 val_loss: 0.22760334610939026, train_loss: 0.013358943164348602\n",
            "27160 val_loss: 0.23545601963996887, train_loss: 0.013561258092522621\n",
            "27170 val_loss: 0.24867641925811768, train_loss: 0.015465467236936092\n",
            "27180 val_loss: 0.23424895107746124, train_loss: 0.01401551067829132\n",
            "27190 val_loss: 0.26104339957237244, train_loss: 0.01631253771483898\n",
            "27200 val_loss: 0.22508342564105988, train_loss: 0.013441773131489754\n",
            "27210 val_loss: 0.2240329086780548, train_loss: 0.013207508251070976\n",
            "27220 val_loss: 0.21183498203754425, train_loss: 0.014116287231445312\n",
            "27230 val_loss: 0.2169645130634308, train_loss: 0.013282593339681625\n",
            "27240 val_loss: 0.23380930721759796, train_loss: 0.013363354839384556\n",
            "27250 val_loss: 0.20490621030330658, train_loss: 0.014810992404818535\n",
            "27260 val_loss: 0.22978046536445618, train_loss: 0.013790310360491276\n",
            "27270 val_loss: 0.2707146108150482, train_loss: 0.017489613965153694\n",
            "27280 val_loss: 0.24152976274490356, train_loss: 0.014093571342527866\n",
            "27290 val_loss: 0.21551479399204254, train_loss: 0.013903546147048473\n",
            "27300 val_loss: 0.21577198803424835, train_loss: 0.013409349136054516\n",
            "27310 val_loss: 0.20815394818782806, train_loss: 0.01352738682180643\n",
            "27320 val_loss: 0.2510243058204651, train_loss: 0.014594633132219315\n",
            "27330 val_loss: 0.2412131130695343, train_loss: 0.013585232198238373\n",
            "27340 val_loss: 0.21158722043037415, train_loss: 0.014357436448335648\n",
            "27350 val_loss: 0.2996453642845154, train_loss: 0.023118725046515465\n",
            "27360 val_loss: 0.22326260805130005, train_loss: 0.013289247639477253\n",
            "27370 val_loss: 0.24778702855110168, train_loss: 0.014285096898674965\n",
            "27380 val_loss: 0.2182537019252777, train_loss: 0.01318258885294199\n",
            "27390 val_loss: 0.2539929747581482, train_loss: 0.014398051425814629\n",
            "27400 val_loss: 0.25905275344848633, train_loss: 0.014750332571566105\n",
            "27410 val_loss: 0.23904019594192505, train_loss: 0.013149858452379704\n",
            "27420 val_loss: 0.20545342564582825, train_loss: 0.01309563685208559\n",
            "27430 val_loss: 0.2781483829021454, train_loss: 0.01646999828517437\n",
            "27440 val_loss: 0.24818284809589386, train_loss: 0.014326825737953186\n",
            "27450 val_loss: 0.22405818104743958, train_loss: 0.012333981692790985\n",
            "27460 val_loss: 0.24677856266498566, train_loss: 0.013025173917412758\n",
            "27470 val_loss: 0.21648909151554108, train_loss: 0.013198645785450935\n",
            "27480 val_loss: 0.20937959849834442, train_loss: 0.013851262629032135\n",
            "27490 val_loss: 0.2244209498167038, train_loss: 0.019983762875199318\n",
            "27500 val_loss: 0.2414013147354126, train_loss: 0.012817062437534332\n",
            "27510 val_loss: 0.21219651401042938, train_loss: 0.014454204589128494\n",
            "27520 val_loss: 0.22017624974250793, train_loss: 0.012615066021680832\n",
            "27530 val_loss: 0.2141737937927246, train_loss: 0.015103746205568314\n",
            "27540 val_loss: 0.2220662236213684, train_loss: 0.013644035905599594\n",
            "27550 val_loss: 0.21939533948898315, train_loss: 0.012463970109820366\n",
            "27560 val_loss: 0.23555469512939453, train_loss: 0.012634222395718098\n",
            "27570 val_loss: 0.21304282546043396, train_loss: 0.012402880005538464\n",
            "27580 val_loss: 0.2228366732597351, train_loss: 0.012252114713191986\n",
            "27590 val_loss: 0.29316288232803345, train_loss: 0.022596722468733788\n",
            "27600 val_loss: 0.22476759552955627, train_loss: 0.012800060212612152\n",
            "27610 val_loss: 0.23101380467414856, train_loss: 0.013147984631359577\n",
            "27620 val_loss: 0.21245288848876953, train_loss: 0.01372249610722065\n",
            "27630 val_loss: 0.2354034185409546, train_loss: 0.01248820312321186\n",
            "27640 val_loss: 0.28666526079177856, train_loss: 0.018894357606768608\n",
            "27650 val_loss: 0.24755823612213135, train_loss: 0.013983641751110554\n",
            "27660 val_loss: 0.20836856961250305, train_loss: 0.013860831037163734\n",
            "27670 val_loss: 0.2196289747953415, train_loss: 0.012130817398428917\n",
            "27680 val_loss: 0.23475633561611176, train_loss: 0.011940385214984417\n",
            "27690 val_loss: 0.24866607785224915, train_loss: 0.012878482230007648\n",
            "27700 val_loss: 0.24146999418735504, train_loss: 0.012838178314268589\n",
            "27710 val_loss: 0.24681104719638824, train_loss: 0.013116594403982162\n",
            "27720 val_loss: 0.21817931532859802, train_loss: 0.012713531963527203\n",
            "27730 val_loss: 0.2303416132926941, train_loss: 0.012465781532227993\n",
            "27740 val_loss: 0.25354140996932983, train_loss: 0.013606767170131207\n",
            "27750 val_loss: 0.23398849368095398, train_loss: 0.01218429859727621\n",
            "27760 val_loss: 0.23013700544834137, train_loss: 0.012498648837208748\n",
            "27770 val_loss: 0.21069574356079102, train_loss: 0.013223919086158276\n",
            "27780 val_loss: 0.2269650250673294, train_loss: 0.012582024559378624\n",
            "27790 val_loss: 0.21942421793937683, train_loss: 0.012534192763268948\n",
            "27800 val_loss: 0.2122439444065094, train_loss: 0.013868885114789009\n",
            "27810 val_loss: 0.26825958490371704, train_loss: 0.036644093692302704\n",
            "27820 val_loss: 0.21395717561244965, train_loss: 0.01308601163327694\n",
            "27830 val_loss: 0.24382846057415009, train_loss: 0.013514944352209568\n",
            "27840 val_loss: 0.238128662109375, train_loss: 0.013002760708332062\n",
            "27850 val_loss: 0.2180875837802887, train_loss: 0.012894398532807827\n",
            "27860 val_loss: 0.2223782241344452, train_loss: 0.012545880861580372\n",
            "27870 val_loss: 0.24465703964233398, train_loss: 0.012561958283185959\n",
            "27880 val_loss: 0.22651061415672302, train_loss: 0.01231586653739214\n",
            "27890 val_loss: 0.2203768789768219, train_loss: 0.012476039119064808\n",
            "27900 val_loss: 0.21577322483062744, train_loss: 0.014010968618094921\n",
            "27910 val_loss: 0.2245890498161316, train_loss: 0.012714247219264507\n",
            "27920 val_loss: 0.23821547627449036, train_loss: 0.012508881278336048\n",
            "27930 val_loss: 0.23548300564289093, train_loss: 0.012761605903506279\n",
            "27940 val_loss: 0.23146286606788635, train_loss: 0.012192480266094208\n",
            "27950 val_loss: 0.2250562459230423, train_loss: 0.013284587301313877\n",
            "27960 val_loss: 0.22249525785446167, train_loss: 0.01238142978399992\n",
            "27970 val_loss: 0.2526171803474426, train_loss: 0.012986995279788971\n",
            "27980 val_loss: 0.31599289178848267, train_loss: 0.024173034355044365\n",
            "27990 val_loss: 0.2329021692276001, train_loss: 0.012059415690600872\n",
            "28000 val_loss: 0.22823454439640045, train_loss: 0.012041173875331879\n",
            "28010 val_loss: 0.25048938393592834, train_loss: 0.011998727917671204\n",
            "28020 val_loss: 0.2415127456188202, train_loss: 0.011697132140398026\n",
            "28030 val_loss: 0.23126862943172455, train_loss: 0.011761413887143135\n",
            "28040 val_loss: 0.23244249820709229, train_loss: 0.01141868345439434\n",
            "28050 val_loss: 0.23806780576705933, train_loss: 0.012337532825767994\n",
            "28060 val_loss: 0.23177674412727356, train_loss: 0.011965756304562092\n",
            "28070 val_loss: 0.2718396782875061, train_loss: 0.01505509577691555\n",
            "28080 val_loss: 0.21532045304775238, train_loss: 0.012178082019090652\n",
            "28090 val_loss: 0.22182032465934753, train_loss: 0.012073541060090065\n",
            "28100 val_loss: 0.23440377414226532, train_loss: 0.012292314320802689\n",
            "28110 val_loss: 0.23799344897270203, train_loss: 0.01182909682393074\n",
            "28120 val_loss: 0.22943557798862457, train_loss: 0.011630531400442123\n",
            "28130 val_loss: 0.22570618987083435, train_loss: 0.011786540038883686\n",
            "28140 val_loss: 0.22937293350696564, train_loss: 0.011443999595940113\n",
            "28150 val_loss: 0.24220502376556396, train_loss: 0.011378176510334015\n",
            "28160 val_loss: 0.23085936903953552, train_loss: 0.01092222798615694\n",
            "28170 val_loss: 0.21083375811576843, train_loss: 0.012140258215367794\n",
            "28180 val_loss: 0.23272649943828583, train_loss: 0.011652893386781216\n",
            "28190 val_loss: 0.2729185223579407, train_loss: 0.014807085506618023\n",
            "28200 val_loss: 0.2292393445968628, train_loss: 0.012072299607098103\n",
            "28210 val_loss: 0.24544395506381989, train_loss: 0.012028230354189873\n",
            "28220 val_loss: 0.21730320155620575, train_loss: 0.01266392320394516\n",
            "28230 val_loss: 0.22303803265094757, train_loss: 0.011669936589896679\n",
            "28240 val_loss: 0.22077782452106476, train_loss: 0.011435486376285553\n",
            "28250 val_loss: 0.24745504558086395, train_loss: 0.013227183371782303\n",
            "28260 val_loss: 0.283820778131485, train_loss: 0.016902534291148186\n",
            "28270 val_loss: 0.23529468476772308, train_loss: 0.011318886652588844\n",
            "28280 val_loss: 0.2384086400270462, train_loss: 0.011275258846580982\n",
            "28290 val_loss: 0.2371588945388794, train_loss: 0.012025979347527027\n",
            "28300 val_loss: 0.26765888929367065, train_loss: 0.014174357056617737\n",
            "28310 val_loss: 0.227351576089859, train_loss: 0.011609085835516453\n",
            "28320 val_loss: 0.22191649675369263, train_loss: 0.0112455477938056\n",
            "28330 val_loss: 0.21907441318035126, train_loss: 0.012070193886756897\n",
            "28340 val_loss: 0.21242129802703857, train_loss: 0.011819167993962765\n",
            "28350 val_loss: 0.2287079244852066, train_loss: 0.011321434751152992\n",
            "28360 val_loss: 0.2573815584182739, train_loss: 0.012171232141554356\n",
            "28370 val_loss: 0.2866917550563812, train_loss: 0.015156079083681107\n",
            "28380 val_loss: 0.25716495513916016, train_loss: 0.012322819791734219\n",
            "28390 val_loss: 0.22777007520198822, train_loss: 0.01148590724915266\n",
            "28400 val_loss: 0.2436039298772812, train_loss: 0.011148393154144287\n",
            "28410 val_loss: 0.22039635479450226, train_loss: 0.011598003096878529\n",
            "28420 val_loss: 0.2397659868001938, train_loss: 0.01109120063483715\n",
            "28430 val_loss: 0.22643055021762848, train_loss: 0.012987053953111172\n",
            "28440 val_loss: 0.23608830571174622, train_loss: 0.010815567336976528\n",
            "28450 val_loss: 0.2512646019458771, train_loss: 0.011097944341599941\n",
            "28460 val_loss: 0.23388542234897614, train_loss: 0.010879729874432087\n",
            "28470 val_loss: 0.22765406966209412, train_loss: 0.012697052210569382\n",
            "28480 val_loss: 0.20943252742290497, train_loss: 0.012105368077754974\n",
            "28490 val_loss: 0.22612622380256653, train_loss: 0.011896155774593353\n",
            "28500 val_loss: 0.24803292751312256, train_loss: 0.019041355699300766\n",
            "28510 val_loss: 0.2318820059299469, train_loss: 0.010978727601468563\n",
            "28520 val_loss: 0.2388150542974472, train_loss: 0.010584648698568344\n",
            "28530 val_loss: 0.24798011779785156, train_loss: 0.010869515128433704\n",
            "28540 val_loss: 0.23100130259990692, train_loss: 0.011064059101045132\n",
            "28550 val_loss: 0.25168365240097046, train_loss: 0.01143461000174284\n",
            "28560 val_loss: 0.24203269183635712, train_loss: 0.010531997308135033\n",
            "28570 val_loss: 0.24385157227516174, train_loss: 0.010774422436952591\n",
            "28580 val_loss: 0.26843366026878357, train_loss: 0.012996876612305641\n",
            "28590 val_loss: 0.21297132968902588, train_loss: 0.01300869882106781\n",
            "28600 val_loss: 0.22904863953590393, train_loss: 0.01047674473375082\n",
            "28610 val_loss: 0.20808181166648865, train_loss: 0.012700674124062061\n",
            "28620 val_loss: 0.2262783944606781, train_loss: 0.010774337686598301\n",
            "28630 val_loss: 0.23426291346549988, train_loss: 0.010882663540542126\n",
            "28640 val_loss: 0.2470896989107132, train_loss: 0.01075048092752695\n",
            "28650 val_loss: 0.2462189942598343, train_loss: 0.015528029762208462\n",
            "28660 val_loss: 0.23992983996868134, train_loss: 0.010108796879649162\n",
            "28670 val_loss: 0.2166571319103241, train_loss: 0.011805996298789978\n",
            "28680 val_loss: 0.283427357673645, train_loss: 0.016230257228016853\n",
            "28690 val_loss: 0.24849627912044525, train_loss: 0.013307437300682068\n",
            "28700 val_loss: 0.2326417863368988, train_loss: 0.01074844691902399\n",
            "28710 val_loss: 0.23007385432720184, train_loss: 0.011381290853023529\n",
            "28720 val_loss: 0.23183777928352356, train_loss: 0.010581828653812408\n",
            "28730 val_loss: 0.2747720181941986, train_loss: 0.0134579474106431\n",
            "28740 val_loss: 0.26000329852104187, train_loss: 0.01065621804445982\n",
            "28750 val_loss: 0.23111048340797424, train_loss: 0.010911799967288971\n",
            "28760 val_loss: 0.23435606062412262, train_loss: 0.010449282824993134\n",
            "28770 val_loss: 0.21054545044898987, train_loss: 0.012431115843355656\n",
            "28780 val_loss: 0.227833092212677, train_loss: 0.01085086353123188\n",
            "28790 val_loss: 0.23297218978405, train_loss: 0.010864710435271263\n",
            "28800 val_loss: 0.23773786425590515, train_loss: 0.014467514120042324\n",
            "28810 val_loss: 0.22210802137851715, train_loss: 0.011428658850491047\n",
            "28820 val_loss: 0.2569301724433899, train_loss: 0.011401322670280933\n",
            "28830 val_loss: 0.22488325834274292, train_loss: 0.010548925027251244\n",
            "28840 val_loss: 0.2217644304037094, train_loss: 0.011033868417143822\n",
            "28850 val_loss: 0.2337437868118286, train_loss: 0.010942758060991764\n",
            "28860 val_loss: 0.23119576275348663, train_loss: 0.010602169670164585\n",
            "28870 val_loss: 0.26008400321006775, train_loss: 0.010733210481703281\n",
            "28880 val_loss: 0.25937706232070923, train_loss: 0.018398581072688103\n",
            "28890 val_loss: 0.24507735669612885, train_loss: 0.010503007099032402\n",
            "28900 val_loss: 0.21671684086322784, train_loss: 0.014787264168262482\n",
            "28910 val_loss: 0.22149936854839325, train_loss: 0.010778077878057957\n",
            "28920 val_loss: 0.22371985018253326, train_loss: 0.010215726681053638\n",
            "28930 val_loss: 0.2369198501110077, train_loss: 0.009772990830242634\n",
            "28940 val_loss: 0.23975637555122375, train_loss: 0.01042857300490141\n",
            "28950 val_loss: 0.22540126740932465, train_loss: 0.010250449180603027\n",
            "28960 val_loss: 0.23979395627975464, train_loss: 0.010203259065747261\n",
            "28970 val_loss: 0.22038114070892334, train_loss: 0.010748015716671944\n",
            "28980 val_loss: 0.23981545865535736, train_loss: 0.010179462842643261\n",
            "28990 val_loss: 0.22177188098430634, train_loss: 0.01093994826078415\n",
            "29000 val_loss: 0.26995378732681274, train_loss: 0.010678483173251152\n",
            "29010 val_loss: 0.23879805207252502, train_loss: 0.010832996107637882\n",
            "29020 val_loss: 0.2280087172985077, train_loss: 0.010834824293851852\n",
            "29030 val_loss: 0.22827868163585663, train_loss: 0.012449752539396286\n",
            "29040 val_loss: 0.2230265736579895, train_loss: 0.011463748291134834\n",
            "29050 val_loss: 0.24421782791614532, train_loss: 0.01048594992607832\n",
            "29060 val_loss: 0.22681018710136414, train_loss: 0.010837738402187824\n",
            "29070 val_loss: 0.23401066660881042, train_loss: 0.010881248861551285\n",
            "29080 val_loss: 0.22048884630203247, train_loss: 0.010839629918336868\n",
            "29090 val_loss: 0.2204335331916809, train_loss: 0.011960172094404697\n",
            "29100 val_loss: 0.28675970435142517, train_loss: 0.014519925229251385\n",
            "29110 val_loss: 0.24434155225753784, train_loss: 0.009942663833498955\n",
            "29120 val_loss: 0.2501941919326782, train_loss: 0.010599501430988312\n",
            "29130 val_loss: 0.2393292933702469, train_loss: 0.01029963605105877\n",
            "29140 val_loss: 0.24663092195987701, train_loss: 0.0101925665512681\n",
            "29150 val_loss: 0.251704603433609, train_loss: 0.010026507079601288\n",
            "29160 val_loss: 0.24704456329345703, train_loss: 0.010336518287658691\n",
            "29170 val_loss: 0.22333920001983643, train_loss: 0.010457539930939674\n",
            "29180 val_loss: 0.23736855387687683, train_loss: 0.010466489009559155\n",
            "29190 val_loss: 0.24583083391189575, train_loss: 0.010245474986732006\n",
            "29200 val_loss: 0.2224079966545105, train_loss: 0.01132842805236578\n",
            "29210 val_loss: 0.23277585208415985, train_loss: 0.009946400299668312\n",
            "29220 val_loss: 0.2167617529630661, train_loss: 0.017483944073319435\n",
            "29230 val_loss: 0.22555425763130188, train_loss: 0.009759575128555298\n",
            "29240 val_loss: 0.24124999344348907, train_loss: 0.00964247528463602\n",
            "29250 val_loss: 0.24474786221981049, train_loss: 0.009597493335604668\n",
            "29260 val_loss: 0.22745725512504578, train_loss: 0.009747253730893135\n",
            "29270 val_loss: 0.24437478184700012, train_loss: 0.010241244919598103\n",
            "29280 val_loss: 0.233468696475029, train_loss: 0.010388935916125774\n",
            "29290 val_loss: 0.22992147505283356, train_loss: 0.00990885030478239\n",
            "29300 val_loss: 0.22029967606067657, train_loss: 0.011224698275327682\n",
            "29310 val_loss: 0.23103180527687073, train_loss: 0.009900872595608234\n",
            "29320 val_loss: 0.2475859373807907, train_loss: 0.009532797150313854\n",
            "29330 val_loss: 0.2451288104057312, train_loss: 0.009682996198534966\n",
            "29340 val_loss: 0.23232026398181915, train_loss: 0.009719098918139935\n",
            "29350 val_loss: 0.23259660601615906, train_loss: 0.011063449084758759\n",
            "29360 val_loss: 0.2040242701768875, train_loss: 0.011841611936688423\n",
            "29370 val_loss: 0.2669115662574768, train_loss: 0.010858554393053055\n",
            "29380 val_loss: 0.24540579319000244, train_loss: 0.009534329175949097\n",
            "29390 val_loss: 0.2215864062309265, train_loss: 0.010245704092085361\n",
            "29400 val_loss: 0.27219098806381226, train_loss: 0.011403893120586872\n",
            "29410 val_loss: 0.30029749870300293, train_loss: 0.014919034205377102\n",
            "29420 val_loss: 0.23110567033290863, train_loss: 0.0098508819937706\n",
            "29430 val_loss: 0.2538084089756012, train_loss: 0.010500597767531872\n",
            "29440 val_loss: 0.19649212062358856, train_loss: 0.016961459070444107\n",
            "29450 val_loss: 0.22301343083381653, train_loss: 0.010559371672570705\n",
            "29460 val_loss: 0.21952611207962036, train_loss: 0.012657483108341694\n",
            "29470 val_loss: 0.2556033134460449, train_loss: 0.009748443029820919\n",
            "29480 val_loss: 0.241343155503273, train_loss: 0.009783553890883923\n",
            "29490 val_loss: 0.2447093278169632, train_loss: 0.012723772786557674\n",
            "29500 val_loss: 0.24000363051891327, train_loss: 0.009775745682418346\n",
            "29510 val_loss: 0.24663561582565308, train_loss: 0.00968562625348568\n",
            "29520 val_loss: 0.2276330441236496, train_loss: 0.00980355218052864\n",
            "29530 val_loss: 0.23147660493850708, train_loss: 0.010678893886506557\n",
            "29540 val_loss: 0.24643534421920776, train_loss: 0.01027088426053524\n",
            "29550 val_loss: 0.22794058918952942, train_loss: 0.010693006217479706\n",
            "29560 val_loss: 0.24114124476909637, train_loss: 0.009311973117291927\n",
            "29570 val_loss: 0.24279721081256866, train_loss: 0.009116427972912788\n",
            "29580 val_loss: 0.28067314624786377, train_loss: 0.011280596256256104\n",
            "29590 val_loss: 0.2525733411312103, train_loss: 0.009268337860703468\n",
            "29600 val_loss: 0.24435265362262726, train_loss: 0.008892876096069813\n",
            "29610 val_loss: 0.28819185495376587, train_loss: 0.011818313971161842\n",
            "29620 val_loss: 0.23151645064353943, train_loss: 0.0091503094881773\n",
            "29630 val_loss: 0.23847366869449615, train_loss: 0.008987241424620152\n",
            "29640 val_loss: 0.2583199143409729, train_loss: 0.01102053839713335\n",
            "29650 val_loss: 0.224081352353096, train_loss: 0.011185159906744957\n",
            "29660 val_loss: 0.2511454224586487, train_loss: 0.008869724348187447\n",
            "29670 val_loss: 0.21406185626983643, train_loss: 0.014278353191912174\n",
            "29680 val_loss: 0.21874158084392548, train_loss: 0.011654739268124104\n",
            "29690 val_loss: 0.2518722116947174, train_loss: 0.009311668574810028\n",
            "29700 val_loss: 0.23553162813186646, train_loss: 0.010220483876764774\n",
            "29710 val_loss: 0.27425551414489746, train_loss: 0.010884559713304043\n",
            "29720 val_loss: 0.24539868533611298, train_loss: 0.00934868399053812\n",
            "29730 val_loss: 0.24091511964797974, train_loss: 0.011205382645130157\n",
            "29740 val_loss: 0.23238308727741241, train_loss: 0.009607478976249695\n",
            "29750 val_loss: 0.25112906098365784, train_loss: 0.010870245285332203\n",
            "29760 val_loss: 0.22222182154655457, train_loss: 0.011760536581277847\n",
            "29770 val_loss: 0.23573970794677734, train_loss: 0.008868036791682243\n",
            "29780 val_loss: 0.28853389620780945, train_loss: 0.011814935132861137\n",
            "29790 val_loss: 0.2581488788127899, train_loss: 0.009534554556012154\n",
            "29800 val_loss: 0.22637823224067688, train_loss: 0.009522962383925915\n",
            "29810 val_loss: 0.31286242604255676, train_loss: 0.0160567257553339\n",
            "29820 val_loss: 0.2530825734138489, train_loss: 0.00973630789667368\n",
            "29830 val_loss: 0.2409476488828659, train_loss: 0.009288029745221138\n",
            "29840 val_loss: 0.2571420669555664, train_loss: 0.009100054390728474\n",
            "29850 val_loss: 0.2337694615125656, train_loss: 0.00929203163832426\n",
            "29860 val_loss: 0.2487511932849884, train_loss: 0.009465236216783524\n",
            "29870 val_loss: 0.2412945181131363, train_loss: 0.009308583103120327\n",
            "29880 val_loss: 0.23276767134666443, train_loss: 0.0121836569160223\n",
            "29890 val_loss: 0.30157554149627686, train_loss: 0.01741868071258068\n",
            "29900 val_loss: 0.254365473985672, train_loss: 0.010512728244066238\n",
            "29910 val_loss: 0.26967012882232666, train_loss: 0.009148146025836468\n",
            "29920 val_loss: 0.23933574557304382, train_loss: 0.008781790733337402\n",
            "29930 val_loss: 0.25093382596969604, train_loss: 0.008864054456353188\n",
            "29940 val_loss: 0.24314060807228088, train_loss: 0.009347094222903252\n",
            "29950 val_loss: 0.24546879529953003, train_loss: 0.009416839107871056\n",
            "29960 val_loss: 0.23654097318649292, train_loss: 0.009545067325234413\n",
            "29970 val_loss: 0.2444600760936737, train_loss: 0.009397552348673344\n",
            "29980 val_loss: 0.23417751491069794, train_loss: 0.00937753077596426\n",
            "29990 val_loss: 0.2773958742618561, train_loss: 0.01167330052703619\n",
            "30000 val_loss: 0.2503533959388733, train_loss: 0.009894604794681072\n",
            "30010 val_loss: 0.21776898205280304, train_loss: 0.011641224846243858\n",
            "30020 val_loss: 0.2465837299823761, train_loss: 0.009540453553199768\n",
            "30030 val_loss: 0.22211295366287231, train_loss: 0.013169371522963047\n",
            "30040 val_loss: 0.3171556890010834, train_loss: 0.032198574393987656\n",
            "30050 val_loss: 0.2423073947429657, train_loss: 0.009693795815110207\n",
            "30060 val_loss: 0.21667073667049408, train_loss: 0.011132290586829185\n",
            "30070 val_loss: 0.24073319137096405, train_loss: 0.009283792227506638\n",
            "30080 val_loss: 0.24208593368530273, train_loss: 0.00923267100006342\n",
            "30090 val_loss: 0.2344485968351364, train_loss: 0.01012348011136055\n",
            "30100 val_loss: 0.28201839327812195, train_loss: 0.011475427076220512\n",
            "30110 val_loss: 0.28301018476486206, train_loss: 0.01149863749742508\n",
            "30120 val_loss: 0.23538155853748322, train_loss: 0.009219292551279068\n",
            "30130 val_loss: 0.23383744060993195, train_loss: 0.009136087261140347\n",
            "30140 val_loss: 0.25323960185050964, train_loss: 0.008735631592571735\n",
            "30150 val_loss: 0.26931169629096985, train_loss: 0.009780963882803917\n",
            "30160 val_loss: 0.24840493500232697, train_loss: 0.008721532300114632\n",
            "30170 val_loss: 0.27258747816085815, train_loss: 0.009914233349263668\n",
            "30180 val_loss: 0.2395516335964203, train_loss: 0.008847180753946304\n",
            "30190 val_loss: 0.26015591621398926, train_loss: 0.008702890947461128\n",
            "30200 val_loss: 0.23764459788799286, train_loss: 0.008826103992760181\n",
            "30210 val_loss: 0.24692188203334808, train_loss: 0.008558853529393673\n",
            "30220 val_loss: 0.24276889860630035, train_loss: 0.00857099425047636\n",
            "30230 val_loss: 0.23254673182964325, train_loss: 0.00885043479502201\n",
            "30240 val_loss: 0.23295468091964722, train_loss: 0.009083127602934837\n",
            "30250 val_loss: 0.2561394274234772, train_loss: 0.008995086885988712\n",
            "30260 val_loss: 0.2576676905155182, train_loss: 0.009030167944729328\n",
            "30270 val_loss: 0.25720199942588806, train_loss: 0.009748093783855438\n",
            "30280 val_loss: 0.23789019882678986, train_loss: 0.008824922144412994\n",
            "30290 val_loss: 0.22523516416549683, train_loss: 0.011030851863324642\n",
            "30300 val_loss: 0.22863882780075073, train_loss: 0.010205249302089214\n",
            "30310 val_loss: 0.23324716091156006, train_loss: 0.010127601213753223\n",
            "30320 val_loss: 0.2618495523929596, train_loss: 0.009138010442256927\n",
            "30330 val_loss: 0.25000035762786865, train_loss: 0.008960726670920849\n",
            "30340 val_loss: 0.2602238059043884, train_loss: 0.008712837472558022\n",
            "30350 val_loss: 0.2743756175041199, train_loss: 0.008599208667874336\n",
            "30360 val_loss: 0.24239878356456757, train_loss: 0.011099270544946194\n",
            "30370 val_loss: 0.25807449221611023, train_loss: 0.00880217831581831\n",
            "30380 val_loss: 0.2573002278804779, train_loss: 0.008505471982061863\n",
            "30390 val_loss: 0.2607438564300537, train_loss: 0.008453446440398693\n",
            "30400 val_loss: 0.25548407435417175, train_loss: 0.008414837531745434\n",
            "30410 val_loss: 0.2541995942592621, train_loss: 0.008157093077898026\n",
            "30420 val_loss: 0.2677328586578369, train_loss: 0.008013740181922913\n",
            "30430 val_loss: 0.261627733707428, train_loss: 0.007975433953106403\n",
            "30440 val_loss: 0.24771006405353546, train_loss: 0.008314352482557297\n",
            "30450 val_loss: 0.2301589846611023, train_loss: 0.009245363064110279\n",
            "30460 val_loss: 0.2510029077529907, train_loss: 0.008426324464380741\n",
            "30470 val_loss: 0.2506222724914551, train_loss: 0.008651331067085266\n",
            "30480 val_loss: 0.21926705539226532, train_loss: 0.01180136576294899\n",
            "30490 val_loss: 0.23001201450824738, train_loss: 0.010680238716304302\n",
            "30500 val_loss: 0.24627785384655, train_loss: 0.00847578700631857\n",
            "30510 val_loss: 0.2680053412914276, train_loss: 0.012116244062781334\n",
            "30520 val_loss: 0.2388085424900055, train_loss: 0.012063650414347649\n",
            "30530 val_loss: 0.2494755983352661, train_loss: 0.008261383511126041\n",
            "30540 val_loss: 0.31929245591163635, train_loss: 0.013884452171623707\n",
            "30550 val_loss: 0.28547561168670654, train_loss: 0.01176317036151886\n",
            "30560 val_loss: 0.2385367453098297, train_loss: 0.008199777454137802\n",
            "30570 val_loss: 0.256262868642807, train_loss: 0.00822675134986639\n",
            "30580 val_loss: 0.24416589736938477, train_loss: 0.010573195293545723\n",
            "30590 val_loss: 0.2534238398075104, train_loss: 0.00817401334643364\n",
            "30600 val_loss: 0.2560340464115143, train_loss: 0.00809220690280199\n",
            "30610 val_loss: 0.2540557384490967, train_loss: 0.008152231574058533\n",
            "30620 val_loss: 0.2531645894050598, train_loss: 0.008464853279292583\n",
            "30630 val_loss: 0.26681995391845703, train_loss: 0.008250366896390915\n",
            "30640 val_loss: 0.2531605362892151, train_loss: 0.008191201835870743\n",
            "30650 val_loss: 0.29978618025779724, train_loss: 0.010489800944924355\n",
            "30660 val_loss: 0.25723716616630554, train_loss: 0.008033961057662964\n",
            "30670 val_loss: 0.2562777101993561, train_loss: 0.008262800984084606\n",
            "30680 val_loss: 0.2400505691766739, train_loss: 0.009488626383244991\n",
            "30690 val_loss: 0.7181488275527954, train_loss: 0.28934481739997864\n",
            "30700 val_loss: 0.2218325287103653, train_loss: 0.02368675358593464\n",
            "30710 val_loss: 0.2257562130689621, train_loss: 0.017562000080943108\n",
            "30720 val_loss: 0.2340618520975113, train_loss: 0.014710461720824242\n",
            "30730 val_loss: 0.25487279891967773, train_loss: 0.013014794327318668\n",
            "30740 val_loss: 0.29745641350746155, train_loss: 0.0183380339294672\n",
            "30750 val_loss: 0.24028144776821136, train_loss: 0.011271334253251553\n",
            "30760 val_loss: 0.23023183643817902, train_loss: 0.011167740449309349\n",
            "30770 val_loss: 0.2507982850074768, train_loss: 0.010396260768175125\n",
            "30780 val_loss: 0.22647792100906372, train_loss: 0.011398514732718468\n",
            "30790 val_loss: 0.23308393359184265, train_loss: 0.010552879422903061\n",
            "30800 val_loss: 0.25050684809684753, train_loss: 0.009251895360648632\n",
            "30810 val_loss: 0.2629982531070709, train_loss: 0.009474464692175388\n",
            "30820 val_loss: 0.26519474387168884, train_loss: 0.009296898730099201\n",
            "30830 val_loss: 0.24831049144268036, train_loss: 0.00889594666659832\n",
            "30840 val_loss: 0.2262815535068512, train_loss: 0.009966070763766766\n",
            "30850 val_loss: 0.2626558542251587, train_loss: 0.008803903125226498\n",
            "30860 val_loss: 0.290849894285202, train_loss: 0.011467634700238705\n",
            "30870 val_loss: 0.27577319741249084, train_loss: 0.009848050773143768\n",
            "30880 val_loss: 0.24148382246494293, train_loss: 0.008536544628441334\n",
            "30890 val_loss: 0.2299928218126297, train_loss: 0.009889609180390835\n",
            "30900 val_loss: 0.25281137228012085, train_loss: 0.008208813145756721\n",
            "30910 val_loss: 0.3374022841453552, train_loss: 0.01858009584248066\n",
            "30920 val_loss: 0.24190668761730194, train_loss: 0.0093636903911829\n",
            "30930 val_loss: 0.2775561511516571, train_loss: 0.009184015914797783\n",
            "30940 val_loss: 0.24098388850688934, train_loss: 0.008810980245471\n",
            "30950 val_loss: 0.2743326723575592, train_loss: 0.008553845807909966\n",
            "30960 val_loss: 0.2590148448944092, train_loss: 0.0080808624625206\n",
            "30970 val_loss: 0.26903703808784485, train_loss: 0.008923402056097984\n",
            "30980 val_loss: 0.2560710608959198, train_loss: 0.008452332578599453\n",
            "30990 val_loss: 0.25249457359313965, train_loss: 0.00802007969468832\n",
            "31000 val_loss: 0.18652082979679108, train_loss: 0.016580350697040558\n",
            "31010 val_loss: 0.2541494071483612, train_loss: 0.008347047492861748\n",
            "31020 val_loss: 0.2327485978603363, train_loss: 0.010354714468121529\n",
            "31030 val_loss: 0.2809427082538605, train_loss: 0.009678428992629051\n",
            "31040 val_loss: 0.25260698795318604, train_loss: 0.00826216023415327\n",
            "31050 val_loss: 0.24942836165428162, train_loss: 0.00866999477148056\n",
            "31060 val_loss: 0.26172512769699097, train_loss: 0.008942537941038609\n",
            "31070 val_loss: 0.2431364804506302, train_loss: 0.011812482960522175\n",
            "31080 val_loss: 0.27660489082336426, train_loss: 0.0089766476303339\n",
            "31090 val_loss: 0.26453280448913574, train_loss: 0.008146143518388271\n",
            "31100 val_loss: 0.25817301869392395, train_loss: 0.008732139132916927\n",
            "31110 val_loss: 0.23881596326828003, train_loss: 0.008943011984229088\n",
            "31120 val_loss: 0.256924033164978, train_loss: 0.008366632275283337\n",
            "31130 val_loss: 0.2625376284122467, train_loss: 0.008504725992679596\n",
            "31140 val_loss: 0.23708070814609528, train_loss: 0.010625196620821953\n",
            "31150 val_loss: 0.3100261092185974, train_loss: 0.011593068949878216\n",
            "31160 val_loss: 0.279493123292923, train_loss: 0.008783997036516666\n",
            "31170 val_loss: 0.24458035826683044, train_loss: 0.010163458064198494\n",
            "31180 val_loss: 0.251457154750824, train_loss: 0.008235707879066467\n",
            "31190 val_loss: 0.2689701318740845, train_loss: 0.008226382546126842\n",
            "31200 val_loss: 0.24527743458747864, train_loss: 0.009515848942101002\n",
            "31210 val_loss: 0.2482047975063324, train_loss: 0.007908876053988934\n",
            "31220 val_loss: 0.2702631950378418, train_loss: 0.010491606779396534\n",
            "31230 val_loss: 0.2565579414367676, train_loss: 0.00898752361536026\n",
            "31240 val_loss: 0.2792210280895233, train_loss: 0.008530449122190475\n",
            "31250 val_loss: 0.2579003870487213, train_loss: 0.012708084657788277\n",
            "31260 val_loss: 0.2666848599910736, train_loss: 0.00831188540905714\n",
            "31270 val_loss: 0.23469635844230652, train_loss: 0.009360721334815025\n",
            "31280 val_loss: 0.2221938818693161, train_loss: 0.010417429730296135\n",
            "31290 val_loss: 0.292382150888443, train_loss: 0.00959738064557314\n",
            "31300 val_loss: 0.2454625964164734, train_loss: 0.00868601631373167\n",
            "31310 val_loss: 0.2592332065105438, train_loss: 0.009996740147471428\n",
            "31320 val_loss: 0.2701833248138428, train_loss: 0.008083288557827473\n",
            "31330 val_loss: 0.27286767959594727, train_loss: 0.00802979338914156\n",
            "31340 val_loss: 0.25748348236083984, train_loss: 0.007519491016864777\n",
            "31350 val_loss: 0.2611366808414459, train_loss: 0.0076597752049565315\n",
            "31360 val_loss: 0.3147173523902893, train_loss: 0.012885180301964283\n",
            "31370 val_loss: 0.25835689902305603, train_loss: 0.00799124501645565\n",
            "31380 val_loss: 0.3015635907649994, train_loss: 0.010160445235669613\n",
            "31390 val_loss: 0.27275538444519043, train_loss: 0.0077515700832009315\n",
            "31400 val_loss: 0.25794005393981934, train_loss: 0.00729175191372633\n",
            "31410 val_loss: 0.25457996129989624, train_loss: 0.007328438572585583\n",
            "31420 val_loss: 0.25459611415863037, train_loss: 0.019209599122405052\n",
            "31430 val_loss: 0.26080450415611267, train_loss: 0.007975141517817974\n",
            "31440 val_loss: 0.23566758632659912, train_loss: 0.009348809719085693\n",
            "31450 val_loss: 0.24709095060825348, train_loss: 0.00809080246835947\n",
            "31460 val_loss: 0.3277815580368042, train_loss: 0.01404370553791523\n",
            "31470 val_loss: 0.23614490032196045, train_loss: 0.009299658238887787\n",
            "31480 val_loss: 0.25444984436035156, train_loss: 0.007572340313345194\n",
            "31490 val_loss: 0.2357083261013031, train_loss: 0.009190143086016178\n",
            "31500 val_loss: 0.2392692118883133, train_loss: 0.010104089044034481\n",
            "31510 val_loss: 0.24562422931194305, train_loss: 0.007737074978649616\n",
            "31520 val_loss: 0.2908662259578705, train_loss: 0.008559711277484894\n",
            "31530 val_loss: 0.23568183183670044, train_loss: 0.00913227815181017\n",
            "31540 val_loss: 0.26592767238616943, train_loss: 0.007207732647657394\n",
            "31550 val_loss: 0.23056958615779877, train_loss: 0.00969134084880352\n",
            "31560 val_loss: 0.32149985432624817, train_loss: 0.011658991686999798\n",
            "31570 val_loss: 0.25624364614486694, train_loss: 0.007186099421232939\n",
            "31580 val_loss: 0.2732815146446228, train_loss: 0.007007318548858166\n",
            "31590 val_loss: 0.26981762051582336, train_loss: 0.007057559676468372\n",
            "31600 val_loss: 0.2531379163265228, train_loss: 0.007893510162830353\n",
            "31610 val_loss: 0.3403773903846741, train_loss: 0.012976692989468575\n",
            "31620 val_loss: 0.25050458312034607, train_loss: 0.015679383650422096\n",
            "31630 val_loss: 0.4162570834159851, train_loss: 0.10706620663404465\n",
            "31640 val_loss: 0.1914972960948944, train_loss: 0.01482574176043272\n",
            "31650 val_loss: 0.22742055356502533, train_loss: 0.011533022858202457\n",
            "31660 val_loss: 0.22640037536621094, train_loss: 0.010549669153988361\n",
            "31670 val_loss: 0.23094399273395538, train_loss: 0.00966623518615961\n",
            "31680 val_loss: 0.2518540620803833, train_loss: 0.008486969396471977\n",
            "31690 val_loss: 0.2581839859485626, train_loss: 0.008251944556832314\n",
            "31700 val_loss: 0.2514423131942749, train_loss: 0.00786454975605011\n",
            "31710 val_loss: 0.25058406591415405, train_loss: 0.011394767090678215\n",
            "31720 val_loss: 0.22163884341716766, train_loss: 0.011749157682061195\n",
            "31730 val_loss: 0.2559959590435028, train_loss: 0.007348224055022001\n",
            "31740 val_loss: 0.3163856565952301, train_loss: 0.011129082180559635\n",
            "31750 val_loss: 0.25757473707199097, train_loss: 0.016156146302819252\n",
            "31760 val_loss: 0.2487645447254181, train_loss: 0.007525771856307983\n",
            "31770 val_loss: 0.24824973940849304, train_loss: 0.00748760299757123\n",
            "31780 val_loss: 0.25504928827285767, train_loss: 0.00920078158378601\n",
            "31790 val_loss: 0.2502424418926239, train_loss: 0.008626765571534634\n",
            "31800 val_loss: 0.264393150806427, train_loss: 0.007166825234889984\n",
            "31810 val_loss: 0.26979607343673706, train_loss: 0.007419595494866371\n",
            "31820 val_loss: 0.2734627425670624, train_loss: 0.007253789808601141\n",
            "31830 val_loss: 0.31736046075820923, train_loss: 0.04565587639808655\n",
            "31840 val_loss: 0.2542015314102173, train_loss: 0.0075788479298353195\n",
            "31850 val_loss: 0.3462664484977722, train_loss: 0.016766183078289032\n",
            "31860 val_loss: 0.23105785250663757, train_loss: 0.009234332479536533\n",
            "31870 val_loss: 0.3376902639865875, train_loss: 0.014155765995383263\n",
            "31880 val_loss: 0.28149178624153137, train_loss: 0.007979744113981724\n",
            "31890 val_loss: 0.25672176480293274, train_loss: 0.008129226975142956\n",
            "31900 val_loss: 0.27163514494895935, train_loss: 0.007300638593733311\n",
            "31910 val_loss: 0.2953944802284241, train_loss: 0.007934989407658577\n",
            "31920 val_loss: 0.2770800292491913, train_loss: 0.007078774739056826\n",
            "31930 val_loss: 0.24822598695755005, train_loss: 0.007415469735860825\n",
            "31940 val_loss: 0.23900152742862701, train_loss: 0.011491493321955204\n",
            "31950 val_loss: 0.3086708188056946, train_loss: 0.010144820436835289\n",
            "31960 val_loss: 0.25311440229415894, train_loss: 0.007319767028093338\n",
            "31970 val_loss: 0.2807953357696533, train_loss: 0.007089702878147364\n",
            "31980 val_loss: 0.24021881818771362, train_loss: 0.007897419854998589\n",
            "31990 val_loss: 0.30311182141304016, train_loss: 0.00946737825870514\n",
            "32000 val_loss: 0.29706478118896484, train_loss: 0.014022179879248142\n",
            "32010 val_loss: 0.2440534085035324, train_loss: 0.010534575209021568\n",
            "32020 val_loss: 0.27277448773384094, train_loss: 0.007734634913504124\n",
            "32030 val_loss: 0.27621835470199585, train_loss: 0.014785515144467354\n",
            "32040 val_loss: 0.2973874807357788, train_loss: 0.008139975368976593\n",
            "32050 val_loss: 0.2789990305900574, train_loss: 0.007410150486975908\n",
            "32060 val_loss: 0.293539822101593, train_loss: 0.007870289497077465\n",
            "32070 val_loss: 0.3051222562789917, train_loss: 0.008698074147105217\n",
            "32080 val_loss: 0.2519766390323639, train_loss: 0.00951468851417303\n",
            "32090 val_loss: 0.2710875868797302, train_loss: 0.007826239801943302\n",
            "32100 val_loss: 0.28239038586616516, train_loss: 0.007149477489292622\n",
            "32110 val_loss: 0.283627450466156, train_loss: 0.007548745255917311\n",
            "32120 val_loss: 0.2695472538471222, train_loss: 0.011182633228600025\n",
            "32130 val_loss: 0.2614946961402893, train_loss: 0.008004452101886272\n",
            "32140 val_loss: 0.32213282585144043, train_loss: 0.010630259290337563\n",
            "32150 val_loss: 0.2636871337890625, train_loss: 0.007375812623649836\n",
            "32160 val_loss: 0.2546207010746002, train_loss: 0.007464513648301363\n",
            "32170 val_loss: 0.2559807002544403, train_loss: 0.00731272716075182\n",
            "32180 val_loss: 0.26715993881225586, train_loss: 0.006893799174576998\n",
            "32190 val_loss: 0.2751215994358063, train_loss: 0.00717517314478755\n",
            "32200 val_loss: 0.26809343695640564, train_loss: 0.007414518389850855\n",
            "32210 val_loss: 0.2777882218360901, train_loss: 0.00757942209020257\n",
            "32220 val_loss: 0.26068320870399475, train_loss: 0.007256418466567993\n",
            "32230 val_loss: 0.2750224769115448, train_loss: 0.007232292555272579\n",
            "32240 val_loss: 0.25741106271743774, train_loss: 0.0075208875350654125\n",
            "32250 val_loss: 0.27228718996047974, train_loss: 0.007074342109262943\n",
            "32260 val_loss: 0.2726927399635315, train_loss: 0.006724299397319555\n",
            "32270 val_loss: 0.27967679500579834, train_loss: 0.006703989114612341\n",
            "32280 val_loss: 0.25041672587394714, train_loss: 0.007180748973041773\n",
            "32290 val_loss: 0.2652552127838135, train_loss: 0.006854273844510317\n",
            "32300 val_loss: 0.2703673243522644, train_loss: 0.0065365987829864025\n",
            "32310 val_loss: 0.29060453176498413, train_loss: 0.007609224878251553\n",
            "32320 val_loss: 0.23982658982276917, train_loss: 0.008047791197896004\n",
            "32330 val_loss: 0.25465863943099976, train_loss: 0.006657005753368139\n",
            "32340 val_loss: 0.24877089262008667, train_loss: 0.007834694348275661\n",
            "32350 val_loss: 0.2854252755641937, train_loss: 0.0065206727012991905\n",
            "32360 val_loss: 0.3015056848526001, train_loss: 0.007897901348769665\n",
            "32370 val_loss: 0.27354374527931213, train_loss: 0.006868201307952404\n",
            "32380 val_loss: 0.27640295028686523, train_loss: 0.006654784549027681\n",
            "32390 val_loss: 0.286738783121109, train_loss: 0.013162910006940365\n",
            "32400 val_loss: 0.2965075969696045, train_loss: 0.007371882442384958\n",
            "32410 val_loss: 0.3119297921657562, train_loss: 0.008197534829378128\n",
            "32420 val_loss: 0.3152261972427368, train_loss: 0.006755145266652107\n",
            "32430 val_loss: 0.2552925646305084, train_loss: 0.008694697171449661\n",
            "32440 val_loss: 0.2738742232322693, train_loss: 0.012801753357052803\n",
            "32450 val_loss: 0.31615525484085083, train_loss: 0.008739056065678596\n",
            "32460 val_loss: 0.27498161792755127, train_loss: 0.006551981437951326\n",
            "32470 val_loss: 0.26036590337753296, train_loss: 0.0075085898861289024\n",
            "32480 val_loss: 0.2980857491493225, train_loss: 0.007617503870278597\n",
            "32490 val_loss: 0.2727735936641693, train_loss: 0.0066778105683624744\n",
            "32500 val_loss: 0.3090357184410095, train_loss: 0.008293124847114086\n",
            "32510 val_loss: 0.2593148946762085, train_loss: 0.007262766361236572\n",
            "32520 val_loss: 0.2764846086502075, train_loss: 0.006374840624630451\n",
            "32530 val_loss: 0.26606956124305725, train_loss: 0.0066952211782336235\n",
            "32540 val_loss: 0.26700228452682495, train_loss: 0.007088910788297653\n",
            "32550 val_loss: 0.19597607851028442, train_loss: 0.014459963887929916\n",
            "32560 val_loss: 0.27413803339004517, train_loss: 0.007605987135320902\n",
            "32570 val_loss: 0.24936211109161377, train_loss: 0.008396917954087257\n",
            "32580 val_loss: 0.2745455205440521, train_loss: 0.0068066418170928955\n",
            "32590 val_loss: 0.2798965573310852, train_loss: 0.007169004064053297\n",
            "32600 val_loss: 0.3303464651107788, train_loss: 0.011661822907626629\n",
            "32610 val_loss: 0.2607588768005371, train_loss: 0.007234963122755289\n",
            "32620 val_loss: 0.2574861943721771, train_loss: 0.00674559036269784\n",
            "32630 val_loss: 0.30216896533966064, train_loss: 0.008629145100712776\n",
            "32640 val_loss: 0.2615060806274414, train_loss: 0.00697298115119338\n",
            "32650 val_loss: 0.2793881893157959, train_loss: 0.00737188383936882\n",
            "32660 val_loss: 0.27481722831726074, train_loss: 0.006895109545439482\n",
            "32670 val_loss: 0.2655455768108368, train_loss: 0.006579105276614428\n",
            "32680 val_loss: 0.2866175174713135, train_loss: 0.007143082097172737\n",
            "32690 val_loss: 0.2733146846294403, train_loss: 0.0064389328472316265\n",
            "32700 val_loss: 0.29150933027267456, train_loss: 0.007329839281737804\n",
            "32710 val_loss: 0.25719302892684937, train_loss: 0.006766762584447861\n",
            "32720 val_loss: 0.2248046100139618, train_loss: 0.012202620506286621\n",
            "32730 val_loss: 0.29400819540023804, train_loss: 0.008433681912720203\n",
            "32740 val_loss: 0.2987116277217865, train_loss: 0.007222332060337067\n",
            "32750 val_loss: 0.2916486859321594, train_loss: 0.006993826013058424\n",
            "32760 val_loss: 0.3250744342803955, train_loss: 0.04670966789126396\n",
            "32770 val_loss: 0.19315455853939056, train_loss: 0.02322166971862316\n",
            "32780 val_loss: 0.18729160726070404, train_loss: 0.01818508841097355\n",
            "32790 val_loss: 0.20446304976940155, train_loss: 0.01733235828578472\n",
            "32800 val_loss: 0.22741447389125824, train_loss: 0.01412438228726387\n",
            "32810 val_loss: 0.2349565625190735, train_loss: 0.011625795625150204\n",
            "32820 val_loss: 0.2879093587398529, train_loss: 0.01295508909970522\n",
            "32830 val_loss: 0.25482267141342163, train_loss: 0.009093724191188812\n",
            "32840 val_loss: 0.2355092316865921, train_loss: 0.013977058231830597\n",
            "32850 val_loss: 0.2653120458126068, train_loss: 0.00812895130366087\n",
            "32860 val_loss: 0.24721142649650574, train_loss: 0.008284811861813068\n",
            "32870 val_loss: 0.23119290173053741, train_loss: 0.012521794065833092\n",
            "32880 val_loss: 0.2745932638645172, train_loss: 0.007543915417045355\n",
            "32890 val_loss: 0.2580356001853943, train_loss: 0.007561626378446817\n",
            "32900 val_loss: 0.29112008213996887, train_loss: 0.014996577054262161\n",
            "32910 val_loss: 0.2677340507507324, train_loss: 0.0070674535818398\n",
            "32920 val_loss: 0.26327890157699585, train_loss: 0.006947098299860954\n",
            "32930 val_loss: 0.32469552755355835, train_loss: 0.010907068848609924\n",
            "32940 val_loss: 0.26768162846565247, train_loss: 0.006569878663867712\n",
            "32950 val_loss: 0.2723023295402527, train_loss: 0.006661105435341597\n",
            "32960 val_loss: 0.28921499848365784, train_loss: 0.007223294582217932\n",
            "32970 val_loss: 0.2715197801589966, train_loss: 0.006575156934559345\n",
            "32980 val_loss: 0.2783396244049072, train_loss: 0.006527547724545002\n",
            "32990 val_loss: 0.2598366141319275, train_loss: 0.009739656001329422\n",
            "33000 val_loss: 0.2578675448894501, train_loss: 0.007193936500698328\n",
            "33010 val_loss: 0.2628287672996521, train_loss: 0.0071994224563241005\n",
            "33020 val_loss: 0.2410457283258438, train_loss: 0.008702103979885578\n",
            "33030 val_loss: 0.2616848945617676, train_loss: 0.006931509356945753\n",
            "33040 val_loss: 0.2711277902126312, train_loss: 0.0067030019126832485\n",
            "33050 val_loss: 0.28178179264068604, train_loss: 0.006713564973324537\n",
            "33060 val_loss: 0.2629421353340149, train_loss: 0.006605651695281267\n",
            "33070 val_loss: 0.28753501176834106, train_loss: 0.006537186913192272\n",
            "33080 val_loss: 0.2934398651123047, train_loss: 0.006527429912239313\n",
            "33090 val_loss: 0.25838449597358704, train_loss: 0.006867796182632446\n",
            "33100 val_loss: 0.29171663522720337, train_loss: 0.00815897062420845\n",
            "33110 val_loss: 0.23181699216365814, train_loss: 0.011547038331627846\n",
            "33120 val_loss: 0.25226080417633057, train_loss: 0.008869295008480549\n",
            "33130 val_loss: 0.27812689542770386, train_loss: 0.008201300166547298\n",
            "33140 val_loss: 0.29116302728652954, train_loss: 0.008133103139698505\n",
            "33150 val_loss: 0.2509354054927826, train_loss: 0.008084254339337349\n",
            "33160 val_loss: 0.25798869132995605, train_loss: 0.01029988843947649\n",
            "33170 val_loss: 0.30829548835754395, train_loss: 0.008344719186425209\n",
            "33180 val_loss: 0.29311519861221313, train_loss: 0.007027043960988522\n",
            "33190 val_loss: 0.2715538740158081, train_loss: 0.01562449149787426\n",
            "33200 val_loss: 0.26283925771713257, train_loss: 0.006910357624292374\n",
            "33210 val_loss: 0.2823871374130249, train_loss: 0.006681128870695829\n",
            "33220 val_loss: 0.24718502163887024, train_loss: 0.008174913935363293\n",
            "33230 val_loss: 0.26421529054641724, train_loss: 0.0069886501878499985\n",
            "33240 val_loss: 0.2672249972820282, train_loss: 0.006685763597488403\n",
            "33250 val_loss: 0.30594295263290405, train_loss: 0.008048293180763721\n",
            "33260 val_loss: 0.24895590543746948, train_loss: 0.007712384220212698\n",
            "33270 val_loss: 0.3288842439651489, train_loss: 0.009458395652472973\n",
            "33280 val_loss: 0.30562934279441833, train_loss: 0.00687095383182168\n",
            "33290 val_loss: 0.30006226897239685, train_loss: 0.007066675461828709\n",
            "33300 val_loss: 0.28568875789642334, train_loss: 0.0061037493869662285\n",
            "33310 val_loss: 0.24575087428092957, train_loss: 0.00845932587981224\n",
            "33320 val_loss: 0.2687138020992279, train_loss: 0.0109143340960145\n",
            "33330 val_loss: 0.3357430100440979, train_loss: 0.012212458066642284\n",
            "33340 val_loss: 0.2569842040538788, train_loss: 0.006853258702903986\n",
            "33350 val_loss: 0.251215398311615, train_loss: 0.0135219506919384\n",
            "33360 val_loss: 0.26626408100128174, train_loss: 0.0062651257030665874\n",
            "33370 val_loss: 0.2518383264541626, train_loss: 0.008098218590021133\n",
            "33380 val_loss: 0.2900148034095764, train_loss: 0.006281644571572542\n",
            "33390 val_loss: 0.3401872217655182, train_loss: 0.028529834002256393\n",
            "33400 val_loss: 0.3128472566604614, train_loss: 0.01243553962558508\n",
            "33410 val_loss: 0.31489333510398865, train_loss: 0.008443082682788372\n",
            "33420 val_loss: 0.2751232981681824, train_loss: 0.006094958633184433\n",
            "33430 val_loss: 0.2783811390399933, train_loss: 0.00591201800853014\n",
            "33440 val_loss: 0.3507164716720581, train_loss: 0.013275676406919956\n",
            "33450 val_loss: 0.2743864357471466, train_loss: 0.005730276927351952\n",
            "33460 val_loss: 0.2432093620300293, train_loss: 0.009799636900424957\n",
            "33470 val_loss: 0.28198060393333435, train_loss: 0.005755200050771236\n",
            "33480 val_loss: 0.2794784903526306, train_loss: 0.005776158533990383\n",
            "33490 val_loss: 0.24992018938064575, train_loss: 0.007263955194503069\n",
            "33500 val_loss: 0.3106641173362732, train_loss: 0.007150943856686354\n",
            "33510 val_loss: 0.3227709233760834, train_loss: 0.00865904800593853\n",
            "33520 val_loss: 0.2773239314556122, train_loss: 0.0065397764556109905\n",
            "33530 val_loss: 0.26667293906211853, train_loss: 0.006334866862744093\n",
            "33540 val_loss: 0.2988559901714325, train_loss: 0.006481250748038292\n",
            "33550 val_loss: 0.27576351165771484, train_loss: 0.006012906786054373\n",
            "33560 val_loss: 0.2661064565181732, train_loss: 0.006154084578156471\n",
            "33570 val_loss: 0.2513863146305084, train_loss: 0.00842935498803854\n",
            "33580 val_loss: 0.8494126200675964, train_loss: 0.3179916739463806\n",
            "33590 val_loss: 0.1878720074892044, train_loss: 0.016841623932123184\n",
            "33600 val_loss: 0.19695508480072021, train_loss: 0.014005254954099655\n",
            "33610 val_loss: 0.21566365659236908, train_loss: 0.012895334511995316\n",
            "33620 val_loss: 0.24796679615974426, train_loss: 0.010180633515119553\n",
            "33630 val_loss: 0.2654731571674347, train_loss: 0.009211902506649494\n",
            "33640 val_loss: 0.257739782333374, train_loss: 0.008173532783985138\n",
            "33650 val_loss: 0.25446709990501404, train_loss: 0.00771547993645072\n",
            "33660 val_loss: 0.23486514389514923, train_loss: 0.00830791611224413\n",
            "33670 val_loss: 0.2422429919242859, train_loss: 0.008327015675604343\n",
            "33680 val_loss: 0.29095157980918884, train_loss: 0.007935576140880585\n",
            "33690 val_loss: 0.2680918276309967, train_loss: 0.00645036157220602\n",
            "33700 val_loss: 0.2506829798221588, train_loss: 0.006620428990572691\n",
            "33710 val_loss: 0.23555807769298553, train_loss: 0.009745556861162186\n",
            "33720 val_loss: 0.2673019766807556, train_loss: 0.0062534986063838005\n",
            "33730 val_loss: 0.3001178205013275, train_loss: 0.006803812924772501\n",
            "33740 val_loss: 0.27627524733543396, train_loss: 0.006368640344589949\n",
            "33750 val_loss: 0.2843071520328522, train_loss: 0.006453629583120346\n",
            "33760 val_loss: 0.2553999423980713, train_loss: 0.0065111517906188965\n",
            "33770 val_loss: 0.2220422476530075, train_loss: 0.012480661273002625\n",
            "33780 val_loss: 0.27652284502983093, train_loss: 0.006831471808254719\n",
            "33790 val_loss: 0.26891666650772095, train_loss: 0.006220864597707987\n",
            "33800 val_loss: 0.24421270191669464, train_loss: 0.009107105433940887\n",
            "33810 val_loss: 0.26886600255966187, train_loss: 0.018291987478733063\n",
            "33820 val_loss: 0.2588272988796234, train_loss: 0.007391308434307575\n",
            "33830 val_loss: 0.2565728724002838, train_loss: 0.006685894913971424\n",
            "33840 val_loss: 0.2906510531902313, train_loss: 0.01111016795039177\n",
            "33850 val_loss: 0.2702181935310364, train_loss: 0.00647876039147377\n",
            "33860 val_loss: 0.2915543019771576, train_loss: 0.006485513877123594\n",
            "33870 val_loss: 0.2696587145328522, train_loss: 0.005920328665524721\n",
            "33880 val_loss: 0.26607009768486023, train_loss: 0.005973688326776028\n",
            "33890 val_loss: 0.2856209874153137, train_loss: 0.0068189180456101894\n",
            "33900 val_loss: 0.2786368429660797, train_loss: 0.005841630510985851\n",
            "33910 val_loss: 0.2662239372730255, train_loss: 0.006169834174215794\n",
            "33920 val_loss: 0.27534574270248413, train_loss: 0.006051803007721901\n",
            "33930 val_loss: 0.2868632972240448, train_loss: 0.0061032711528241634\n",
            "33940 val_loss: 0.26608413457870483, train_loss: 0.005969021003693342\n",
            "33950 val_loss: 0.30662357807159424, train_loss: 0.007184305228292942\n",
            "33960 val_loss: 0.22832004725933075, train_loss: 0.009601687081158161\n",
            "33970 val_loss: 0.23829768598079681, train_loss: 0.00922258198261261\n",
            "33980 val_loss: 0.24473823606967926, train_loss: 0.014093323610723019\n",
            "33990 val_loss: 0.26388490200042725, train_loss: 0.006639695260673761\n",
            "34000 val_loss: 0.2510839104652405, train_loss: 0.008458932861685753\n",
            "34010 val_loss: 0.25985798239707947, train_loss: 0.006418901961296797\n",
            "34020 val_loss: 0.2673112154006958, train_loss: 0.009477711282670498\n",
            "34030 val_loss: 0.3038252294063568, train_loss: 0.006581631954759359\n",
            "34040 val_loss: 0.2965332567691803, train_loss: 0.006015587132424116\n",
            "34050 val_loss: 0.28909626603126526, train_loss: 0.005425363313406706\n",
            "34060 val_loss: 0.27858468890190125, train_loss: 0.005515448283404112\n",
            "34070 val_loss: 0.2811870574951172, train_loss: 0.0070533775724470615\n",
            "34080 val_loss: 0.269071102142334, train_loss: 0.006481348071247339\n",
            "34090 val_loss: 0.30941468477249146, train_loss: 0.006386327091604471\n",
            "34100 val_loss: 0.2972617447376251, train_loss: 0.005764041095972061\n",
            "34110 val_loss: 0.28158342838287354, train_loss: 0.005521813873201609\n",
            "34120 val_loss: 0.2940092086791992, train_loss: 0.01165454089641571\n",
            "34130 val_loss: 0.33061444759368896, train_loss: 0.008855998516082764\n",
            "34140 val_loss: 0.27874165773391724, train_loss: 0.005604986101388931\n",
            "34150 val_loss: 0.2791901230812073, train_loss: 0.005662711802870035\n",
            "34160 val_loss: 0.2931661307811737, train_loss: 0.005548552144318819\n",
            "34170 val_loss: 0.27337104082107544, train_loss: 0.005620910320430994\n",
            "34180 val_loss: 0.2682325541973114, train_loss: 0.00621966365724802\n",
            "34190 val_loss: 0.2600664496421814, train_loss: 0.00979971420019865\n",
            "34200 val_loss: 0.2500769793987274, train_loss: 0.007805025205016136\n",
            "34210 val_loss: 0.30595001578330994, train_loss: 0.006229208316653967\n",
            "34220 val_loss: 0.28857657313346863, train_loss: 0.005805633030831814\n",
            "34230 val_loss: 0.2684928774833679, train_loss: 0.01153312623500824\n",
            "34240 val_loss: 0.2828506827354431, train_loss: 0.005548607558012009\n",
            "34250 val_loss: 0.2755239009857178, train_loss: 0.005976155865937471\n",
            "34260 val_loss: 0.32428061962127686, train_loss: 0.011024180799722672\n",
            "34270 val_loss: 0.29368335008621216, train_loss: 0.005373730324208736\n",
            "34280 val_loss: 0.29467201232910156, train_loss: 0.0054433271288871765\n",
            "34290 val_loss: 0.28597235679626465, train_loss: 0.00547758536413312\n",
            "34300 val_loss: 0.27647286653518677, train_loss: 0.005546653643250465\n",
            "34310 val_loss: 0.27291980385780334, train_loss: 0.006114461459219456\n",
            "34320 val_loss: 0.300254762172699, train_loss: 0.005881174001842737\n",
            "34330 val_loss: 0.34656620025634766, train_loss: 0.009369058534502983\n",
            "34340 val_loss: 0.3833928406238556, train_loss: 0.01840277574956417\n",
            "34350 val_loss: 0.28663307428359985, train_loss: 0.005879485048353672\n",
            "34360 val_loss: 0.2728182375431061, train_loss: 0.008457398973405361\n",
            "34370 val_loss: 0.2746541500091553, train_loss: 0.006132372189313173\n",
            "34380 val_loss: 0.2896985411643982, train_loss: 0.005579234566539526\n",
            "34390 val_loss: 0.277286171913147, train_loss: 0.008140104822814465\n",
            "34400 val_loss: 0.26758620142936707, train_loss: 0.01024705171585083\n",
            "34410 val_loss: 0.31881874799728394, train_loss: 0.006503645330667496\n",
            "34420 val_loss: 0.2727048397064209, train_loss: 0.006613613571971655\n",
            "34430 val_loss: 0.2843664586544037, train_loss: 0.0054739732295274734\n",
            "34440 val_loss: 0.29001885652542114, train_loss: 0.005391889251768589\n",
            "34450 val_loss: 0.3120787441730499, train_loss: 0.006203505676239729\n",
            "34460 val_loss: 0.2819804251194, train_loss: 0.005159574560821056\n",
            "34470 val_loss: 0.2983623743057251, train_loss: 0.0053485180251300335\n",
            "34480 val_loss: 0.2861912250518799, train_loss: 0.005264104809612036\n",
            "34490 val_loss: 0.27833476662635803, train_loss: 0.005376003682613373\n",
            "34500 val_loss: 0.29313743114471436, train_loss: 0.005594958551228046\n",
            "34510 val_loss: 0.2779209017753601, train_loss: 0.006150808185338974\n",
            "34520 val_loss: 0.27533766627311707, train_loss: 0.006006291136145592\n",
            "34530 val_loss: 0.3201940655708313, train_loss: 0.007374075707048178\n",
            "34540 val_loss: 0.33311256766319275, train_loss: 0.0076278927735984325\n",
            "34550 val_loss: 0.23635748028755188, train_loss: 0.00969115924090147\n",
            "34560 val_loss: 0.3051483631134033, train_loss: 0.007661950774490833\n",
            "34570 val_loss: 0.27624979615211487, train_loss: 0.0061308047734200954\n",
            "34580 val_loss: 0.28106507658958435, train_loss: 0.005878271535038948\n",
            "34590 val_loss: 0.31278038024902344, train_loss: 0.0070128957740962505\n",
            "34600 val_loss: 0.24921928346157074, train_loss: 0.007441036403179169\n",
            "34610 val_loss: 0.24511069059371948, train_loss: 0.010090848430991173\n",
            "34620 val_loss: 0.27891919016838074, train_loss: 0.008364273235201836\n",
            "34630 val_loss: 0.289762407541275, train_loss: 0.005501877516508102\n",
            "34640 val_loss: 0.284320592880249, train_loss: 0.005407914984971285\n",
            "34650 val_loss: 0.30104249715805054, train_loss: 0.0061863381415605545\n",
            "34660 val_loss: 0.2791288197040558, train_loss: 0.005760446656495333\n",
            "34670 val_loss: 0.2664608061313629, train_loss: 0.006176668684929609\n",
            "34680 val_loss: 0.28815075755119324, train_loss: 0.00547561701387167\n",
            "34690 val_loss: 0.29070335626602173, train_loss: 0.005392954684793949\n",
            "34700 val_loss: 0.26127707958221436, train_loss: 0.007504443638026714\n",
            "34710 val_loss: 0.25971540808677673, train_loss: 0.009824392385780811\n",
            "34720 val_loss: 0.2577107846736908, train_loss: 0.010314195416867733\n",
            "34730 val_loss: 0.35581690073013306, train_loss: 0.01827879436314106\n",
            "34740 val_loss: 0.30519866943359375, train_loss: 0.006392788607627153\n",
            "34750 val_loss: 0.30307531356811523, train_loss: 0.005759738385677338\n",
            "34760 val_loss: 0.2785204350948334, train_loss: 0.005352244712412357\n",
            "34770 val_loss: 0.2820993959903717, train_loss: 0.0054867262952029705\n",
            "34780 val_loss: 0.3330501616001129, train_loss: 0.008038990199565887\n",
            "34790 val_loss: 0.26071465015411377, train_loss: 0.006436133291572332\n",
            "34800 val_loss: 0.27844494581222534, train_loss: 0.005364028736948967\n",
            "34810 val_loss: 0.3319723904132843, train_loss: 0.0079808896407485\n",
            "34820 val_loss: 0.2689586877822876, train_loss: 0.008700798265635967\n",
            "34830 val_loss: 0.30935341119766235, train_loss: 0.006219442468136549\n",
            "34840 val_loss: 0.2669665217399597, train_loss: 0.0066637019626796246\n",
            "34850 val_loss: 0.26119160652160645, train_loss: 0.007447106298059225\n",
            "34860 val_loss: 0.2595250606536865, train_loss: 0.008854229003190994\n",
            "34870 val_loss: 0.2633190155029297, train_loss: 0.014919715002179146\n",
            "34880 val_loss: 0.2457992434501648, train_loss: 0.00898935180157423\n",
            "34890 val_loss: 0.2837720513343811, train_loss: 0.005303722340613604\n",
            "34900 val_loss: 0.2968352138996124, train_loss: 0.0053263562731444836\n",
            "34910 val_loss: 0.28338372707366943, train_loss: 0.005335533991456032\n",
            "34920 val_loss: 0.26591160893440247, train_loss: 0.00592372240498662\n",
            "34930 val_loss: 0.2883399426937103, train_loss: 0.004926273133605719\n",
            "34940 val_loss: 0.26435387134552, train_loss: 0.0056452276185154915\n",
            "34950 val_loss: 0.2909109890460968, train_loss: 0.005041863303631544\n",
            "34960 val_loss: 0.25972914695739746, train_loss: 0.006861335132271051\n",
            "34970 val_loss: 0.3018325865268707, train_loss: 0.005251236725598574\n",
            "34980 val_loss: 0.293581485748291, train_loss: 0.006564639043062925\n",
            "34990 val_loss: 0.35782352089881897, train_loss: 0.012937069870531559\n",
            "35000 val_loss: 0.2552374005317688, train_loss: 0.006479333154857159\n",
            "35010 val_loss: 0.30269521474838257, train_loss: 0.005441341083496809\n",
            "35020 val_loss: 0.2736815810203552, train_loss: 0.005618092138320208\n",
            "35030 val_loss: 0.3225001096725464, train_loss: 0.0065901451744139194\n",
            "35040 val_loss: 0.29020318388938904, train_loss: 0.005332454573363066\n",
            "35050 val_loss: 0.28059351444244385, train_loss: 0.006203935947269201\n",
            "35060 val_loss: 0.2793315052986145, train_loss: 0.005486424546688795\n",
            "35070 val_loss: 0.27536657452583313, train_loss: 0.008253047242760658\n",
            "35080 val_loss: 0.295678049325943, train_loss: 0.004909764509648085\n",
            "35090 val_loss: 0.2915510833263397, train_loss: 0.006152061279863119\n",
            "35100 val_loss: 0.27821457386016846, train_loss: 0.006600359454751015\n",
            "35110 val_loss: 0.30607688426971436, train_loss: 0.008044685237109661\n",
            "35120 val_loss: 0.2795189917087555, train_loss: 0.0056391204707324505\n",
            "35130 val_loss: 0.28017914295196533, train_loss: 0.0055321031250059605\n",
            "35140 val_loss: 0.27536246180534363, train_loss: 0.005724018439650536\n",
            "35150 val_loss: 0.2935480773448944, train_loss: 0.005243548192083836\n",
            "35160 val_loss: 0.3130931854248047, train_loss: 0.006717391312122345\n",
            "35170 val_loss: 0.2901318669319153, train_loss: 0.008397853001952171\n",
            "35180 val_loss: 0.33539527654647827, train_loss: 0.006527454126626253\n",
            "35190 val_loss: 0.3005627691745758, train_loss: 0.005014333873987198\n",
            "35200 val_loss: 0.27935126423835754, train_loss: 0.006763261742889881\n",
            "35210 val_loss: 0.3409498631954193, train_loss: 0.007790515664964914\n",
            "35220 val_loss: 0.2648363709449768, train_loss: 0.0074447328224778175\n",
            "35230 val_loss: 0.30044102668762207, train_loss: 0.005523910280317068\n",
            "35240 val_loss: 0.2919120490550995, train_loss: 0.005116540938615799\n",
            "35250 val_loss: 0.29413801431655884, train_loss: 0.004929049406200647\n",
            "35260 val_loss: 0.3325423300266266, train_loss: 0.0069779520854353905\n",
            "35270 val_loss: 0.30686110258102417, train_loss: 0.004923899658024311\n",
            "35280 val_loss: 0.2890424132347107, train_loss: 0.00512038404121995\n",
            "35290 val_loss: 0.2764231860637665, train_loss: 0.0058435797691345215\n",
            "35300 val_loss: 0.2951657772064209, train_loss: 0.004921027459204197\n",
            "35310 val_loss: 0.3082742989063263, train_loss: 0.005100058391690254\n",
            "35320 val_loss: 0.2850443124771118, train_loss: 0.005025877151638269\n",
            "35330 val_loss: 0.27633652091026306, train_loss: 0.005223688203841448\n",
            "35340 val_loss: 0.30423077940940857, train_loss: 0.005130843259394169\n",
            "35350 val_loss: 0.37802737951278687, train_loss: 0.01302708126604557\n",
            "35360 val_loss: 0.30592212080955505, train_loss: 0.005086955148726702\n",
            "35370 val_loss: 0.30327874422073364, train_loss: 0.004781749099493027\n",
            "35380 val_loss: 0.3734653890132904, train_loss: 0.02871651016175747\n",
            "35390 val_loss: 0.29310375452041626, train_loss: 0.005484433379024267\n",
            "35400 val_loss: 0.27174079418182373, train_loss: 0.006931941024959087\n",
            "35410 val_loss: 0.28336793184280396, train_loss: 0.006029343232512474\n",
            "35420 val_loss: 0.31961092352867126, train_loss: 0.005492717027664185\n",
            "35430 val_loss: 0.29404187202453613, train_loss: 0.0054593379609286785\n",
            "35440 val_loss: 0.3063255548477173, train_loss: 0.005180170759558678\n",
            "35450 val_loss: 0.26842325925827026, train_loss: 0.008469528518617153\n",
            "35460 val_loss: 0.315723717212677, train_loss: 0.005211434327065945\n",
            "35470 val_loss: 0.28692159056663513, train_loss: 0.006834747735410929\n",
            "35480 val_loss: 0.3000517785549164, train_loss: 0.00513897929340601\n",
            "35490 val_loss: 0.30182287096977234, train_loss: 0.010117042809724808\n",
            "35500 val_loss: 0.28752583265304565, train_loss: 0.005125913303345442\n",
            "35510 val_loss: 0.2900189757347107, train_loss: 0.004925229586660862\n",
            "35520 val_loss: 0.2801072597503662, train_loss: 0.005725356284528971\n",
            "35530 val_loss: 0.3099316954612732, train_loss: 0.005291088484227657\n",
            "35540 val_loss: 0.3138207495212555, train_loss: 0.0050617726519703865\n",
            "35550 val_loss: 0.2775014042854309, train_loss: 0.006132407579571009\n",
            "35560 val_loss: 0.2745814323425293, train_loss: 0.009288602508604527\n",
            "35570 val_loss: 0.30864575505256653, train_loss: 0.00472120800986886\n",
            "35580 val_loss: 0.32332149147987366, train_loss: 0.004933831747621298\n",
            "35590 val_loss: 0.2913174331188202, train_loss: 0.008547569625079632\n",
            "35600 val_loss: 0.30176979303359985, train_loss: 0.013199929147958755\n",
            "35610 val_loss: 0.3092883229255676, train_loss: 0.0052859047427773476\n",
            "35620 val_loss: 0.26447832584381104, train_loss: 0.007054105866700411\n",
            "35630 val_loss: 0.288043737411499, train_loss: 0.005375401116907597\n",
            "35640 val_loss: 0.2876283824443817, train_loss: 0.005315737333148718\n",
            "35650 val_loss: 0.30940794944763184, train_loss: 0.0051426030695438385\n",
            "35660 val_loss: 0.29592692852020264, train_loss: 0.005102374590933323\n",
            "35670 val_loss: 0.2926426827907562, train_loss: 0.004930318798869848\n",
            "35680 val_loss: 0.29350775480270386, train_loss: 0.004800398368388414\n",
            "35690 val_loss: 0.2809922993183136, train_loss: 0.005525028333067894\n",
            "35700 val_loss: 0.29049232602119446, train_loss: 0.005075763911008835\n",
            "35710 val_loss: 0.2917778789997101, train_loss: 0.006890623364597559\n",
            "35720 val_loss: 0.30025514960289, train_loss: 0.005047603975981474\n",
            "35730 val_loss: 0.3197174668312073, train_loss: 0.005206950940191746\n",
            "35740 val_loss: 0.3045717775821686, train_loss: 0.004617930389940739\n",
            "35750 val_loss: 0.2937476933002472, train_loss: 0.005310131702572107\n",
            "35760 val_loss: 0.2561489939689636, train_loss: 0.015005813911557198\n",
            "35770 val_loss: 0.2634194791316986, train_loss: 0.005796176381409168\n",
            "35780 val_loss: 0.2718714475631714, train_loss: 0.00636314507573843\n",
            "35790 val_loss: 0.29065266251564026, train_loss: 0.004762752912938595\n",
            "35800 val_loss: 0.3532758951187134, train_loss: 0.008134501054883003\n",
            "35810 val_loss: 0.3019862771034241, train_loss: 0.004532483406364918\n",
            "35820 val_loss: 0.2891941964626312, train_loss: 0.005396209191530943\n",
            "35830 val_loss: 0.3240469992160797, train_loss: 0.005326787009835243\n",
            "35840 val_loss: 0.29342836141586304, train_loss: 0.004839075263589621\n",
            "35850 val_loss: 0.30305540561676025, train_loss: 0.004922498017549515\n",
            "35860 val_loss: 0.2818235158920288, train_loss: 0.00528234476223588\n",
            "35870 val_loss: 0.29658204317092896, train_loss: 0.0047578210942447186\n",
            "35880 val_loss: 0.28011366724967957, train_loss: 0.005664187017828226\n",
            "35890 val_loss: 0.25552067160606384, train_loss: 0.008293946273624897\n",
            "35900 val_loss: 0.30882611870765686, train_loss: 0.005147494841367006\n",
            "35910 val_loss: 0.3052908778190613, train_loss: 0.004861870780587196\n",
            "35920 val_loss: 0.3124532103538513, train_loss: 0.005221880041062832\n",
            "35930 val_loss: 0.2926590144634247, train_loss: 0.004722575657069683\n",
            "35940 val_loss: 0.27995121479034424, train_loss: 0.00743107357993722\n",
            "35950 val_loss: 0.30121973156929016, train_loss: 0.004753781016916037\n",
            "35960 val_loss: 0.28572311997413635, train_loss: 0.005120103247463703\n",
            "35970 val_loss: 0.3004719316959381, train_loss: 0.004767213948071003\n",
            "35980 val_loss: 0.38383179903030396, train_loss: 0.012638001702725887\n",
            "35990 val_loss: 0.32777106761932373, train_loss: 0.005152054131031036\n",
            "36000 val_loss: 0.2899406850337982, train_loss: 0.006848577409982681\n",
            "36010 val_loss: 0.3180636465549469, train_loss: 0.004787269048392773\n",
            "36020 val_loss: 0.3094128966331482, train_loss: 0.004905473440885544\n",
            "36030 val_loss: 0.26769018173217773, train_loss: 0.010535785928368568\n",
            "36040 val_loss: 0.32932186126708984, train_loss: 0.0059161074459552765\n",
            "36050 val_loss: 0.2861810028553009, train_loss: 0.005039682611823082\n",
            "36060 val_loss: 0.27165037393569946, train_loss: 0.010724086314439774\n",
            "36070 val_loss: 0.31572505831718445, train_loss: 0.004898445215076208\n",
            "36080 val_loss: 0.2668503522872925, train_loss: 0.00605627940967679\n",
            "36090 val_loss: 0.3162213861942291, train_loss: 0.004514879081398249\n",
            "36100 val_loss: 0.31682664155960083, train_loss: 0.004887871444225311\n",
            "36110 val_loss: 0.29921090602874756, train_loss: 0.004584229085594416\n",
            "36120 val_loss: 0.29379791021347046, train_loss: 0.004946419969201088\n",
            "36130 val_loss: 0.30009379982948303, train_loss: 0.004849072080105543\n",
            "36140 val_loss: 0.3870087265968323, train_loss: 0.01240517757833004\n",
            "36150 val_loss: 0.37092679738998413, train_loss: 0.009865081869065762\n",
            "36160 val_loss: 0.29898905754089355, train_loss: 0.0048637716099619865\n",
            "36170 val_loss: 0.3616544306278229, train_loss: 0.008259754627943039\n",
            "36180 val_loss: 0.33179545402526855, train_loss: 0.004851786885410547\n",
            "36190 val_loss: 0.314880907535553, train_loss: 0.004353316500782967\n",
            "36200 val_loss: 0.29103219509124756, train_loss: 0.0062203314155340195\n",
            "36210 val_loss: 0.3342374861240387, train_loss: 0.015545426867902279\n",
            "36220 val_loss: 0.3225094974040985, train_loss: 0.005028100684285164\n",
            "36230 val_loss: 0.4045484662055969, train_loss: 0.01593984290957451\n",
            "36240 val_loss: 0.3573450446128845, train_loss: 0.007648315280675888\n",
            "36250 val_loss: 0.35454240441322327, train_loss: 0.007607599254697561\n",
            "36260 val_loss: 0.36763519048690796, train_loss: 0.006390979513525963\n",
            "36270 val_loss: 0.2998320162296295, train_loss: 0.005059352144598961\n",
            "36280 val_loss: 0.34000372886657715, train_loss: 0.004538926295936108\n",
            "36290 val_loss: 0.32074782252311707, train_loss: 0.004611809737980366\n",
            "36300 val_loss: 0.3121742606163025, train_loss: 0.0047648195177316666\n",
            "36310 val_loss: 0.2945539951324463, train_loss: 0.005527570378035307\n",
            "36320 val_loss: 0.29283392429351807, train_loss: 0.005534009542316198\n",
            "36330 val_loss: 0.28073742985725403, train_loss: 0.008523302152752876\n",
            "36340 val_loss: 0.2979319095611572, train_loss: 0.005448221694678068\n",
            "36350 val_loss: 0.32778239250183105, train_loss: 0.0048975106328725815\n",
            "36360 val_loss: 0.327060341835022, train_loss: 0.004329025279730558\n",
            "36370 val_loss: 0.29574066400527954, train_loss: 0.007140239235013723\n",
            "36380 val_loss: 0.3270941376686096, train_loss: 0.004719910211861134\n",
            "36390 val_loss: 0.3243428170681, train_loss: 0.004969518631696701\n",
            "36400 val_loss: 0.3247818350791931, train_loss: 0.005309660919010639\n",
            "36410 val_loss: 0.2994527220726013, train_loss: 0.010263076052069664\n",
            "36420 val_loss: 0.2893049716949463, train_loss: 0.005237846169620752\n",
            "36430 val_loss: 0.30774202942848206, train_loss: 0.004682609811425209\n",
            "36440 val_loss: 0.3030780255794525, train_loss: 0.004913794808089733\n",
            "36450 val_loss: 0.2970298230648041, train_loss: 0.00485796295106411\n",
            "36460 val_loss: 0.4078879952430725, train_loss: 0.015483795665204525\n",
            "36470 val_loss: 0.3277503550052643, train_loss: 0.0053780353628098965\n",
            "36480 val_loss: 0.2845187485218048, train_loss: 0.006136312615126371\n",
            "36490 val_loss: 0.31774184107780457, train_loss: 0.004513456020504236\n",
            "36500 val_loss: 0.28739532828330994, train_loss: 0.0056232851929962635\n",
            "36510 val_loss: 0.3397621512413025, train_loss: 0.004663918167352676\n",
            "36520 val_loss: 0.3416631817817688, train_loss: 0.0060804164968431\n",
            "36530 val_loss: 0.3134053647518158, train_loss: 0.005017536226660013\n",
            "36540 val_loss: 0.2892870306968689, train_loss: 0.0059317792765796185\n",
            "36550 val_loss: 0.28061583638191223, train_loss: 0.0058198231272399426\n",
            "36560 val_loss: 0.305020272731781, train_loss: 0.007568437606096268\n",
            "36570 val_loss: 0.3376368284225464, train_loss: 0.006051909178495407\n",
            "36580 val_loss: 0.30050212144851685, train_loss: 0.004642479587346315\n",
            "36590 val_loss: 0.3379857838153839, train_loss: 0.006182277575135231\n",
            "36600 val_loss: 0.2687698006629944, train_loss: 0.007253732997924089\n",
            "36610 val_loss: 0.27809324860572815, train_loss: 0.0054843067191541195\n",
            "36620 val_loss: 0.29222798347473145, train_loss: 0.004569419659674168\n",
            "36630 val_loss: 0.29188838601112366, train_loss: 0.004809162113815546\n",
            "36640 val_loss: 0.3199768662452698, train_loss: 0.005079096648842096\n",
            "36650 val_loss: 0.26963475346565247, train_loss: 0.007255694828927517\n",
            "36660 val_loss: 0.31708505749702454, train_loss: 0.004692739341408014\n",
            "36670 val_loss: 0.4117841124534607, train_loss: 0.018491141498088837\n",
            "36680 val_loss: 0.2822023928165436, train_loss: 0.005143493879586458\n",
            "36690 val_loss: 0.2874545753002167, train_loss: 0.005857156123965979\n",
            "36700 val_loss: 0.3331247866153717, train_loss: 0.005422331392765045\n",
            "36710 val_loss: 0.30984336137771606, train_loss: 0.01029326394200325\n",
            "36720 val_loss: 0.3000175654888153, train_loss: 0.00505400262773037\n",
            "36730 val_loss: 0.31049033999443054, train_loss: 0.004461604170501232\n",
            "36740 val_loss: 0.29654884338378906, train_loss: 0.005935597233474255\n",
            "36750 val_loss: 0.3095424175262451, train_loss: 0.004384350031614304\n",
            "36760 val_loss: 0.3048650920391083, train_loss: 0.004488516133278608\n",
            "36770 val_loss: 0.301501601934433, train_loss: 0.004465400706976652\n",
            "36780 val_loss: 0.28995516896247864, train_loss: 0.005088771693408489\n",
            "36790 val_loss: 0.28527483344078064, train_loss: 0.004662165883928537\n",
            "36800 val_loss: 0.2860470414161682, train_loss: 0.004519617184996605\n",
            "36810 val_loss: 2.124781370162964, train_loss: 1.2768466472625732\n",
            "36820 val_loss: 0.22845983505249023, train_loss: 0.016120828688144684\n",
            "36830 val_loss: 0.23270173370838165, train_loss: 0.014494066126644611\n",
            "36840 val_loss: 0.22854487597942352, train_loss: 0.012183615006506443\n",
            "36850 val_loss: 0.26455461978912354, train_loss: 0.010587476193904877\n",
            "36860 val_loss: 0.2779161334037781, train_loss: 0.00831624586135149\n",
            "36870 val_loss: 0.29515501856803894, train_loss: 0.007195508573204279\n",
            "36880 val_loss: 0.27686065435409546, train_loss: 0.006791072431951761\n",
            "36890 val_loss: 0.29029762744903564, train_loss: 0.005723257549107075\n",
            "36900 val_loss: 0.32034599781036377, train_loss: 0.006654259283095598\n",
            "36910 val_loss: 0.2590463161468506, train_loss: 0.007439671084284782\n",
            "36920 val_loss: 0.28978484869003296, train_loss: 0.0049907611683011055\n",
            "36930 val_loss: 0.38708195090293884, train_loss: 0.01521171722561121\n",
            "36940 val_loss: 0.2836499810218811, train_loss: 0.006540944334119558\n",
            "36950 val_loss: 0.2806938886642456, train_loss: 0.005044838879257441\n",
            "36960 val_loss: 0.2970731556415558, train_loss: 0.004594709724187851\n",
            "36970 val_loss: 0.2834952771663666, train_loss: 0.0049302647821605206\n",
            "36980 val_loss: 0.31278443336486816, train_loss: 0.004741279873996973\n",
            "36990 val_loss: 0.3070862293243408, train_loss: 0.004655224271118641\n",
            "37000 val_loss: 0.3127168118953705, train_loss: 0.004684892948716879\n",
            "37010 val_loss: 0.30914053320884705, train_loss: 0.004473026841878891\n",
            "37020 val_loss: 0.3165470361709595, train_loss: 0.004666376393288374\n",
            "37030 val_loss: 0.2926265001296997, train_loss: 0.004921519663184881\n",
            "37040 val_loss: 0.27493900060653687, train_loss: 0.005513318348675966\n",
            "37050 val_loss: 0.2988668978214264, train_loss: 0.004552080761641264\n",
            "37060 val_loss: 0.34573861956596375, train_loss: 0.006869588978588581\n",
            "37070 val_loss: 0.29150232672691345, train_loss: 0.00528288446366787\n",
            "37080 val_loss: 0.30310186743736267, train_loss: 0.004410136956721544\n",
            "37090 val_loss: 0.288668692111969, train_loss: 0.004762732889503241\n",
            "37100 val_loss: 0.2892794907093048, train_loss: 0.004341550637036562\n",
            "37110 val_loss: 0.308355450630188, train_loss: 0.004482664167881012\n",
            "37120 val_loss: 0.2739469110965729, train_loss: 0.006945361848920584\n",
            "37130 val_loss: 0.2823641300201416, train_loss: 0.006715940777212381\n",
            "37140 val_loss: 0.3022485375404358, train_loss: 0.004155602306127548\n",
            "37150 val_loss: 0.29894548654556274, train_loss: 0.007496221456676722\n",
            "37160 val_loss: 0.35197654366493225, train_loss: 0.00832502730190754\n",
            "37170 val_loss: 0.30731523036956787, train_loss: 0.004241278860718012\n",
            "37180 val_loss: 0.31503573060035706, train_loss: 0.00437155133113265\n",
            "37190 val_loss: 0.2830224633216858, train_loss: 0.01005757600069046\n",
            "37200 val_loss: 0.30063825845718384, train_loss: 0.004147895611822605\n",
            "37210 val_loss: 0.2748737633228302, train_loss: 0.005529313813894987\n",
            "37220 val_loss: 0.2980344593524933, train_loss: 0.00406972412019968\n",
            "37230 val_loss: 0.29829859733581543, train_loss: 0.004625946749001741\n",
            "37240 val_loss: 0.29990631341934204, train_loss: 0.004829062148928642\n",
            "37250 val_loss: 0.295692503452301, train_loss: 0.008889511227607727\n",
            "37260 val_loss: 0.3407912254333496, train_loss: 0.005138708744198084\n",
            "37270 val_loss: 0.29299718141555786, train_loss: 0.006989230401813984\n",
            "37280 val_loss: 0.31385552883148193, train_loss: 0.004550482612103224\n",
            "37290 val_loss: 0.3785334825515747, train_loss: 0.010374294593930244\n",
            "37300 val_loss: 0.27173399925231934, train_loss: 0.006643780041486025\n",
            "37310 val_loss: 0.29098981618881226, train_loss: 0.006276685278862715\n",
            "37320 val_loss: 0.3559073805809021, train_loss: 0.008907345123589039\n",
            "37330 val_loss: 0.2842171788215637, train_loss: 0.012908441945910454\n",
            "37340 val_loss: 0.27565139532089233, train_loss: 0.00604291120544076\n",
            "37350 val_loss: 0.2754717767238617, train_loss: 0.0058880336582660675\n",
            "37360 val_loss: 0.30001547932624817, train_loss: 0.005021862685680389\n",
            "37370 val_loss: 0.2852746546268463, train_loss: 0.005570976063609123\n",
            "37380 val_loss: 0.30195510387420654, train_loss: 0.004754631780087948\n",
            "37390 val_loss: 0.28578710556030273, train_loss: 0.005054141860455275\n",
            "37400 val_loss: 0.3315604031085968, train_loss: 0.004375917371362448\n",
            "37410 val_loss: 0.30031320452690125, train_loss: 0.0048444499261677265\n",
            "37420 val_loss: 0.30633533000946045, train_loss: 0.00449034571647644\n",
            "37430 val_loss: 0.28026533126831055, train_loss: 0.00560529250651598\n",
            "37440 val_loss: 0.2991478145122528, train_loss: 0.004515450913459063\n",
            "37450 val_loss: 0.2983557879924774, train_loss: 0.004418947733938694\n",
            "37460 val_loss: 0.30853182077407837, train_loss: 0.004388102795928717\n",
            "37470 val_loss: 0.27420830726623535, train_loss: 0.01206190139055252\n",
            "37480 val_loss: 0.2890993654727936, train_loss: 0.005731133744120598\n",
            "37490 val_loss: 0.31630024313926697, train_loss: 0.004868365824222565\n",
            "37500 val_loss: 0.2904960811138153, train_loss: 0.004691812675446272\n",
            "37510 val_loss: 0.2957628071308136, train_loss: 0.004526391159743071\n",
            "37520 val_loss: 0.3016057014465332, train_loss: 0.006235918030142784\n",
            "37530 val_loss: 0.3054579794406891, train_loss: 0.006865459028631449\n",
            "37540 val_loss: 0.3194954991340637, train_loss: 0.004967282060533762\n",
            "37550 val_loss: 0.2951149642467499, train_loss: 0.004534900654107332\n",
            "37560 val_loss: 0.2845355272293091, train_loss: 0.005046295467764139\n",
            "37570 val_loss: 0.2932795584201813, train_loss: 0.004771508276462555\n",
            "37580 val_loss: 0.3237564265727997, train_loss: 0.004462802782654762\n",
            "37590 val_loss: 0.3233279585838318, train_loss: 0.004879866726696491\n",
            "37600 val_loss: 0.3530503213405609, train_loss: 0.005302419885993004\n",
            "37610 val_loss: 0.32836276292800903, train_loss: 0.007745945360511541\n",
            "37620 val_loss: 0.31062403321266174, train_loss: 0.004411777481436729\n",
            "37630 val_loss: 0.33975157141685486, train_loss: 0.005962947849184275\n",
            "37640 val_loss: 0.2839890122413635, train_loss: 0.009792967699468136\n",
            "37650 val_loss: 0.31189024448394775, train_loss: 0.004220726899802685\n",
            "37660 val_loss: 0.34614238142967224, train_loss: 0.00480116531252861\n",
            "37670 val_loss: 0.32110753655433655, train_loss: 0.004840674810111523\n",
            "37680 val_loss: 0.3057497441768646, train_loss: 0.005939454305917025\n",
            "37690 val_loss: 0.28921496868133545, train_loss: 0.008511585183441639\n",
            "37700 val_loss: 0.2976161539554596, train_loss: 0.004235568456351757\n",
            "37710 val_loss: 0.3717987835407257, train_loss: 0.010439673438668251\n",
            "37720 val_loss: 0.3092237114906311, train_loss: 0.004032418597489595\n",
            "37730 val_loss: 0.29374203085899353, train_loss: 0.004531071987003088\n",
            "37740 val_loss: 0.3102125823497772, train_loss: 0.003940128721296787\n",
            "37750 val_loss: 0.36783650517463684, train_loss: 0.008338309824466705\n",
            "37760 val_loss: 0.30371013283729553, train_loss: 0.004560628905892372\n",
            "37770 val_loss: 0.3015228807926178, train_loss: 0.004136682953685522\n",
            "37780 val_loss: 0.3874622583389282, train_loss: 0.01224034558981657\n",
            "37790 val_loss: 0.28721117973327637, train_loss: 0.0060615139082074165\n",
            "37800 val_loss: 0.3231316804885864, train_loss: 0.004044991452246904\n",
            "37810 val_loss: 0.33553987741470337, train_loss: 0.004835744854062796\n",
            "37820 val_loss: 0.2836533486843109, train_loss: 0.006846916396170855\n",
            "37830 val_loss: 0.30947721004486084, train_loss: 0.004317911341786385\n",
            "37840 val_loss: 0.297206312417984, train_loss: 0.004938832949846983\n",
            "37850 val_loss: 0.3901921212673187, train_loss: 0.012390457093715668\n",
            "37860 val_loss: 0.2870088219642639, train_loss: 0.005020991899073124\n",
            "37870 val_loss: 0.3209474980831146, train_loss: 0.004445038735866547\n",
            "37880 val_loss: 0.30101943016052246, train_loss: 0.004735234659165144\n",
            "37890 val_loss: 0.31605425477027893, train_loss: 0.004057887941598892\n",
            "37900 val_loss: 0.29063040018081665, train_loss: 0.005195134319365025\n",
            "37910 val_loss: 0.31892117857933044, train_loss: 0.004801374394446611\n",
            "37920 val_loss: 0.3106192350387573, train_loss: 0.004189652390778065\n",
            "37930 val_loss: 0.30076760053634644, train_loss: 0.0046022445894777775\n",
            "37940 val_loss: 0.3326852023601532, train_loss: 0.004454788751900196\n",
            "37950 val_loss: 0.32455670833587646, train_loss: 0.008167506195604801\n",
            "37960 val_loss: 0.348964661359787, train_loss: 0.01683308370411396\n",
            "37970 val_loss: 0.2758741080760956, train_loss: 0.008641013875603676\n",
            "37980 val_loss: 0.3086022436618805, train_loss: 0.004294205456972122\n",
            "37990 val_loss: 0.3150818943977356, train_loss: 0.004229889251291752\n",
            "38000 val_loss: 0.3118837773799896, train_loss: 0.004295430611819029\n",
            "38010 val_loss: 0.3052094876766205, train_loss: 0.004922167863696814\n",
            "38020 val_loss: 0.3036693036556244, train_loss: 0.008481441996991634\n",
            "38030 val_loss: 0.35618555545806885, train_loss: 0.003985327202826738\n",
            "38040 val_loss: 0.3097969591617584, train_loss: 0.004565270617604256\n",
            "38050 val_loss: 0.3109249472618103, train_loss: 0.004080889280885458\n",
            "38060 val_loss: 0.3057814836502075, train_loss: 0.003975328058004379\n",
            "38070 val_loss: 0.30804410576820374, train_loss: 0.004106692969799042\n",
            "38080 val_loss: 0.3164393901824951, train_loss: 0.004008435644209385\n",
            "38090 val_loss: 0.32154154777526855, train_loss: 0.0038115212228149176\n",
            "38100 val_loss: 0.3231741487979889, train_loss: 0.0038524013943970203\n",
            "38110 val_loss: 0.30375033617019653, train_loss: 0.004578151740133762\n",
            "38120 val_loss: 0.3037882447242737, train_loss: 0.0042512016370892525\n",
            "38130 val_loss: 0.3637147545814514, train_loss: 0.007539460435509682\n",
            "38140 val_loss: 0.3313038945198059, train_loss: 0.004147437866777182\n",
            "38150 val_loss: 0.3097171187400818, train_loss: 0.004233407322317362\n",
            "38160 val_loss: 0.34039443731307983, train_loss: 0.0038433608133345842\n",
            "38170 val_loss: 0.3436713218688965, train_loss: 0.005080155096948147\n",
            "38180 val_loss: 0.3057899475097656, train_loss: 0.0037564574740827084\n",
            "38190 val_loss: 0.3085835874080658, train_loss: 0.0036776603665202856\n",
            "38200 val_loss: 0.31280091404914856, train_loss: 0.004434346221387386\n",
            "38210 val_loss: 0.31227824091911316, train_loss: 0.006099128630012274\n",
            "38220 val_loss: 0.3114898204803467, train_loss: 0.005242703482508659\n",
            "38230 val_loss: 0.2965219020843506, train_loss: 0.004399051424115896\n",
            "38240 val_loss: 0.30109548568725586, train_loss: 0.004023701883852482\n",
            "38250 val_loss: 0.29510995745658875, train_loss: 0.004134107381105423\n",
            "38260 val_loss: 0.30415645241737366, train_loss: 0.005968404468148947\n",
            "38270 val_loss: 0.3152100145816803, train_loss: 0.004080144222825766\n",
            "38280 val_loss: 0.3112594485282898, train_loss: 0.00476484140381217\n",
            "38290 val_loss: 0.29925087094306946, train_loss: 0.004158702678978443\n",
            "38300 val_loss: 0.3041222095489502, train_loss: 0.003976750653237104\n",
            "38310 val_loss: 0.2921149432659149, train_loss: 0.004696570802479982\n",
            "38320 val_loss: 0.34094417095184326, train_loss: 0.00464053126052022\n",
            "38330 val_loss: 0.3207608759403229, train_loss: 0.003909798339009285\n",
            "38340 val_loss: 0.3124992847442627, train_loss: 0.004313525278121233\n",
            "38350 val_loss: 0.30605581402778625, train_loss: 0.004584536422044039\n",
            "38360 val_loss: 0.31536680459976196, train_loss: 0.0040105972439050674\n",
            "38370 val_loss: 0.3209017217159271, train_loss: 0.009530432522296906\n",
            "38380 val_loss: 0.3159458637237549, train_loss: 0.005520266015082598\n",
            "38390 val_loss: 0.301505982875824, train_loss: 0.00451961625367403\n",
            "38400 val_loss: 0.3602210581302643, train_loss: 0.010370051488280296\n",
            "38410 val_loss: 0.317313551902771, train_loss: 0.003911002539098263\n",
            "38420 val_loss: 0.3756604492664337, train_loss: 0.01072843186557293\n",
            "38430 val_loss: 0.3054177761077881, train_loss: 0.004124803934246302\n",
            "38440 val_loss: 0.28890037536621094, train_loss: 0.005648205988109112\n",
            "38450 val_loss: 0.3295159637928009, train_loss: 0.004696902818977833\n",
            "38460 val_loss: 0.3347451686859131, train_loss: 0.004455979913473129\n",
            "38470 val_loss: 0.30786487460136414, train_loss: 0.004191541112959385\n",
            "38480 val_loss: 0.3181421756744385, train_loss: 0.003931079059839249\n",
            "38490 val_loss: 0.3018108010292053, train_loss: 0.004185993690043688\n",
            "38500 val_loss: 0.32869410514831543, train_loss: 0.004489680752158165\n",
            "38510 val_loss: 0.30911028385162354, train_loss: 0.003946400247514248\n",
            "38520 val_loss: 0.3037409484386444, train_loss: 0.005717732012271881\n",
            "38530 val_loss: 0.3579936921596527, train_loss: 0.01493697427213192\n",
            "38540 val_loss: 0.3331534266471863, train_loss: 0.004995424300432205\n",
            "38550 val_loss: 0.32387804985046387, train_loss: 0.004287725314497948\n",
            "38560 val_loss: 0.2772776186466217, train_loss: 0.0062269228510558605\n",
            "38570 val_loss: 0.31277891993522644, train_loss: 0.004242707043886185\n",
            "38580 val_loss: 0.32501062750816345, train_loss: 0.003819826291874051\n",
            "38590 val_loss: 0.31374242901802063, train_loss: 0.004177888855338097\n",
            "38600 val_loss: 0.30785155296325684, train_loss: 0.003994460217654705\n",
            "38610 val_loss: 0.32492122054100037, train_loss: 0.004068736918270588\n",
            "38620 val_loss: 0.3050624430179596, train_loss: 0.00546696363016963\n",
            "38630 val_loss: 0.32344332337379456, train_loss: 0.004155254922807217\n",
            "38640 val_loss: 0.33931198716163635, train_loss: 0.005087301135063171\n",
            "38650 val_loss: 0.30589622259140015, train_loss: 0.003805507207289338\n",
            "38660 val_loss: 0.3139454126358032, train_loss: 0.004255272913724184\n",
            "38670 val_loss: 0.27357232570648193, train_loss: 0.009522671811282635\n",
            "38680 val_loss: 0.3145573139190674, train_loss: 0.003914136439561844\n",
            "38690 val_loss: 0.2594895362854004, train_loss: 0.013686471618711948\n",
            "38700 val_loss: 0.3140793740749359, train_loss: 0.004191865213215351\n",
            "38710 val_loss: 0.3068680167198181, train_loss: 0.0040069930255413055\n",
            "38720 val_loss: 0.320260226726532, train_loss: 0.00413886085152626\n",
            "38730 val_loss: 0.33439669013023376, train_loss: 0.005100682377815247\n",
            "38740 val_loss: 0.3111709654331207, train_loss: 0.004642600193619728\n",
            "38750 val_loss: 0.3034936487674713, train_loss: 0.005258485209196806\n",
            "38760 val_loss: 0.30438241362571716, train_loss: 0.0046589793637394905\n",
            "38770 val_loss: 0.3866346478462219, train_loss: 0.012653302401304245\n",
            "38780 val_loss: 0.33203068375587463, train_loss: 0.004733951296657324\n",
            "38790 val_loss: 0.3067534863948822, train_loss: 0.007837412878870964\n",
            "38800 val_loss: 0.31636086106300354, train_loss: 0.0041526490822434425\n",
            "38810 val_loss: 0.34714165329933167, train_loss: 0.003888587234541774\n",
            "38820 val_loss: 0.3347260057926178, train_loss: 0.004385659471154213\n",
            "38830 val_loss: 0.33172520995140076, train_loss: 0.0039432235062122345\n",
            "38840 val_loss: 0.3944931924343109, train_loss: 0.013080613687634468\n",
            "38850 val_loss: 0.3977774679660797, train_loss: 0.011409291997551918\n",
            "38860 val_loss: 0.28994977474212646, train_loss: 0.005643706768751144\n",
            "38870 val_loss: 0.3223070502281189, train_loss: 0.0035749278031289577\n",
            "38880 val_loss: 0.28902721405029297, train_loss: 0.010953572578728199\n",
            "38890 val_loss: 0.3042794466018677, train_loss: 0.004642680753022432\n",
            "38900 val_loss: 0.3262273371219635, train_loss: 0.00353278242982924\n",
            "38910 val_loss: 0.31261685490608215, train_loss: 0.005417009815573692\n",
            "38920 val_loss: 0.3168874680995941, train_loss: 0.003490699687972665\n",
            "38930 val_loss: 0.29919296503067017, train_loss: 0.006349883507937193\n",
            "38940 val_loss: 0.3557467460632324, train_loss: 0.0034890163224190474\n",
            "38950 val_loss: 0.3162742257118225, train_loss: 0.004109396133571863\n",
            "38960 val_loss: 0.3199610114097595, train_loss: 0.003591403365135193\n",
            "38970 val_loss: 0.3308165669441223, train_loss: 0.010852397419512272\n",
            "38980 val_loss: 0.47578272223472595, train_loss: 0.05170071870088577\n",
            "38990 val_loss: 0.3328227400779724, train_loss: 0.004100721795111895\n",
            "39000 val_loss: 0.3006661832332611, train_loss: 0.00430385023355484\n",
            "39010 val_loss: 0.3327604830265045, train_loss: 0.003612388391047716\n",
            "39020 val_loss: 0.32974761724472046, train_loss: 0.00338457222096622\n",
            "39030 val_loss: 0.3222595751285553, train_loss: 0.0039908853359520435\n",
            "39040 val_loss: 0.3191092908382416, train_loss: 0.00351841957308352\n",
            "39050 val_loss: 0.3338576853275299, train_loss: 0.004091887269169092\n",
            "39060 val_loss: 0.36933261156082153, train_loss: 0.007415245287120342\n",
            "39070 val_loss: 0.31999462842941284, train_loss: 0.0037688573356717825\n",
            "39080 val_loss: 0.2901482582092285, train_loss: 0.012514214962720871\n",
            "39090 val_loss: 0.3130153715610504, train_loss: 0.0036081464495509863\n",
            "39100 val_loss: 0.3090283274650574, train_loss: 0.005441772751510143\n",
            "39110 val_loss: 0.35525956749916077, train_loss: 0.006197423208504915\n",
            "39120 val_loss: 0.3512592911720276, train_loss: 0.005936159752309322\n",
            "39130 val_loss: 0.3106459975242615, train_loss: 0.004301802255213261\n",
            "39140 val_loss: 0.3093907833099365, train_loss: 0.00559452548623085\n",
            "39150 val_loss: 0.325031042098999, train_loss: 0.003751072334125638\n",
            "39160 val_loss: 0.32399532198905945, train_loss: 0.004443148151040077\n",
            "39170 val_loss: 0.3129594326019287, train_loss: 0.005494522396475077\n",
            "39180 val_loss: 0.3406757116317749, train_loss: 0.004127110820263624\n",
            "39190 val_loss: 0.3494455814361572, train_loss: 0.013118798844516277\n",
            "39200 val_loss: 0.3467138111591339, train_loss: 0.004502031486481428\n",
            "39210 val_loss: 0.33435964584350586, train_loss: 0.003974619321525097\n",
            "39220 val_loss: 0.3498064875602722, train_loss: 0.005161648616194725\n",
            "39230 val_loss: 0.35319504141807556, train_loss: 0.005270396359264851\n",
            "39240 val_loss: 0.30510494112968445, train_loss: 0.00485760485753417\n",
            "39250 val_loss: 0.3271564841270447, train_loss: 0.0036640027537941933\n",
            "39260 val_loss: 0.34272223711013794, train_loss: 0.00391017273068428\n",
            "39270 val_loss: 0.32156699895858765, train_loss: 0.003373027080669999\n",
            "39280 val_loss: 0.3407364785671234, train_loss: 0.004155726637691259\n",
            "39290 val_loss: 0.3265897333621979, train_loss: 0.003396893385797739\n",
            "39300 val_loss: 0.346621572971344, train_loss: 0.0033280763309448957\n",
            "39310 val_loss: 0.3893238306045532, train_loss: 0.010096561163663864\n",
            "39320 val_loss: 0.3195326328277588, train_loss: 0.0036188208032399416\n",
            "39330 val_loss: 0.30975693464279175, train_loss: 0.006006866227835417\n",
            "39340 val_loss: 0.332563191652298, train_loss: 0.0035154023207724094\n",
            "39350 val_loss: 0.33744144439697266, train_loss: 0.004518664442002773\n",
            "39360 val_loss: 0.3276588022708893, train_loss: 0.004203216638416052\n",
            "39370 val_loss: 0.28196120262145996, train_loss: 0.006886010989546776\n",
            "39380 val_loss: 0.3367033302783966, train_loss: 0.005724028218537569\n",
            "39390 val_loss: 0.3104361593723297, train_loss: 0.004620861262083054\n",
            "39400 val_loss: 0.30404236912727356, train_loss: 0.007899578660726547\n",
            "39410 val_loss: 0.3277365267276764, train_loss: 0.003570997854694724\n",
            "39420 val_loss: 0.31890371441841125, train_loss: 0.004111523739993572\n",
            "39430 val_loss: 0.3427959382534027, train_loss: 0.0038054019678384066\n",
            "39440 val_loss: 0.34181028604507446, train_loss: 0.00369257596321404\n",
            "39450 val_loss: 0.31276562809944153, train_loss: 0.0036205248907208443\n",
            "39460 val_loss: 0.34688571095466614, train_loss: 0.0038022983353585005\n",
            "39470 val_loss: 0.34217920899391174, train_loss: 0.003398302011191845\n",
            "39480 val_loss: 0.35061517357826233, train_loss: 0.003950911108404398\n",
            "39490 val_loss: 0.44817760586738586, train_loss: 0.019685575738549232\n",
            "39500 val_loss: 0.32663941383361816, train_loss: 0.0038088816218078136\n",
            "39510 val_loss: 0.3121475577354431, train_loss: 0.00422301422804594\n",
            "39520 val_loss: 0.31784671545028687, train_loss: 0.003908923827111721\n",
            "39530 val_loss: 0.32820868492126465, train_loss: 0.0074434238485991955\n",
            "39540 val_loss: 0.32758650183677673, train_loss: 0.003429215867072344\n",
            "39550 val_loss: 0.42387259006500244, train_loss: 0.017017045989632607\n",
            "39560 val_loss: 0.31712231040000916, train_loss: 0.003561371471732855\n",
            "39570 val_loss: 0.3153025209903717, train_loss: 0.004312347155064344\n",
            "39580 val_loss: 0.32693812251091003, train_loss: 0.0033741784282028675\n",
            "39590 val_loss: 0.3178529441356659, train_loss: 0.003769166534766555\n",
            "39600 val_loss: 0.3200168013572693, train_loss: 0.003956496249884367\n",
            "39610 val_loss: 0.3343733549118042, train_loss: 0.003734096186235547\n",
            "39620 val_loss: 0.328639954328537, train_loss: 0.0036696596071124077\n",
            "39630 val_loss: 0.3688914477825165, train_loss: 0.0068622189573943615\n",
            "39640 val_loss: 0.35249951481819153, train_loss: 0.004843828268349171\n",
            "39650 val_loss: 0.3318309783935547, train_loss: 0.003517947858199477\n",
            "39660 val_loss: 0.3178338408470154, train_loss: 0.004926455207169056\n",
            "39670 val_loss: 0.3363640308380127, train_loss: 0.003334440989419818\n",
            "39680 val_loss: 0.32330042123794556, train_loss: 0.003405315801501274\n",
            "39690 val_loss: 0.3676244020462036, train_loss: 0.006701964419335127\n",
            "39700 val_loss: 0.3241117298603058, train_loss: 0.004798752721399069\n",
            "39710 val_loss: 0.3380542993545532, train_loss: 0.0036923526786267757\n",
            "39720 val_loss: 0.37155434489250183, train_loss: 0.006112599279731512\n",
            "39730 val_loss: 0.3595169186592102, train_loss: 0.004774316214025021\n",
            "39740 val_loss: 0.356818288564682, train_loss: 0.004473912063986063\n",
            "39750 val_loss: 0.3260345458984375, train_loss: 0.0036856888327747583\n",
            "39760 val_loss: 0.32597219944000244, train_loss: 0.0038266004994511604\n",
            "39770 val_loss: 0.32808440923690796, train_loss: 0.0031902906484901905\n",
            "39780 val_loss: 0.3576301038265228, train_loss: 0.005063343793153763\n",
            "39790 val_loss: 1.0876909494400024, train_loss: 0.5068598985671997\n",
            "39800 val_loss: 0.2734732925891876, train_loss: 0.054219767451286316\n",
            "39810 val_loss: 0.2525223195552826, train_loss: 0.02632531151175499\n",
            "39820 val_loss: 0.25196972489356995, train_loss: 0.017041819170117378\n",
            "39830 val_loss: 0.2471204549074173, train_loss: 0.01329644862562418\n",
            "39840 val_loss: 0.27017390727996826, train_loss: 0.011300873011350632\n",
            "39850 val_loss: 0.29135724902153015, train_loss: 0.009889049455523491\n",
            "39860 val_loss: 0.29240044951438904, train_loss: 0.008435471914708614\n",
            "39870 val_loss: 0.2869814336299896, train_loss: 0.007269513327628374\n",
            "39880 val_loss: 0.34539276361465454, train_loss: 0.010511954315006733\n",
            "39890 val_loss: 0.29167047142982483, train_loss: 0.006766307167708874\n",
            "39900 val_loss: 0.3013136684894562, train_loss: 0.006109639070928097\n",
            "39910 val_loss: 0.3040657043457031, train_loss: 0.006099518854171038\n",
            "39920 val_loss: 0.3036033511161804, train_loss: 0.0048824273981153965\n",
            "39930 val_loss: 0.2993987500667572, train_loss: 0.005128216929733753\n",
            "39940 val_loss: 0.3153303265571594, train_loss: 0.004491826519370079\n",
            "39950 val_loss: 0.30775341391563416, train_loss: 0.004435534588992596\n",
            "39960 val_loss: 0.3799135386943817, train_loss: 0.013362513855099678\n",
            "39970 val_loss: 0.30909305810928345, train_loss: 0.00427696667611599\n",
            "39980 val_loss: 0.33771517872810364, train_loss: 0.005294295493513346\n",
            "39990 val_loss: 0.308345228433609, train_loss: 0.005393370520323515\n",
            "40000 val_loss: 0.3211064040660858, train_loss: 0.004172631539404392\n",
            "40010 val_loss: 0.3333137035369873, train_loss: 0.003940880764275789\n",
            "40020 val_loss: 0.2982192635536194, train_loss: 0.00560097536072135\n",
            "40030 val_loss: 0.30614688992500305, train_loss: 0.005333077162504196\n",
            "40040 val_loss: 0.32524165511131287, train_loss: 0.003585848491638899\n",
            "40050 val_loss: 0.3241404891014099, train_loss: 0.003572604851797223\n",
            "40060 val_loss: 0.3040447533130646, train_loss: 0.005021293181926012\n",
            "40070 val_loss: 0.33528050780296326, train_loss: 0.003805706975981593\n",
            "40080 val_loss: 0.34765496850013733, train_loss: 0.005266098305583\n",
            "40090 val_loss: 0.3195180594921112, train_loss: 0.004215847700834274\n",
            "40100 val_loss: 0.3383513391017914, train_loss: 0.0040623764507472515\n",
            "40110 val_loss: 0.30084842443466187, train_loss: 0.005365095566958189\n",
            "40120 val_loss: 0.3169027864933014, train_loss: 0.004366440232843161\n",
            "40130 val_loss: 0.31231874227523804, train_loss: 0.0039552198722958565\n",
            "40140 val_loss: 0.33281153440475464, train_loss: 0.003586877603083849\n",
            "40150 val_loss: 0.32271096110343933, train_loss: 0.0032420563511550426\n",
            "40160 val_loss: 0.3367466628551483, train_loss: 0.003747830167412758\n",
            "40170 val_loss: 0.3176797330379486, train_loss: 0.00363474921323359\n",
            "40180 val_loss: 0.3337087035179138, train_loss: 0.0038316191639751196\n",
            "40190 val_loss: 0.3607633709907532, train_loss: 0.006447338964790106\n",
            "40200 val_loss: 0.33924564719200134, train_loss: 0.0037216562777757645\n",
            "40210 val_loss: 0.28468501567840576, train_loss: 0.009391450323164463\n",
            "40220 val_loss: 0.34173640608787537, train_loss: 0.004237847868353128\n",
            "40230 val_loss: 0.2993462085723877, train_loss: 0.005398941691964865\n",
            "40240 val_loss: 0.305647611618042, train_loss: 0.004758873488754034\n",
            "40250 val_loss: 0.39478129148483276, train_loss: 0.012679134495556355\n",
            "40260 val_loss: 0.3154284954071045, train_loss: 0.004375453107059002\n",
            "40270 val_loss: 0.3135814070701599, train_loss: 0.0041451845318078995\n",
            "40280 val_loss: 0.3672786355018616, train_loss: 0.026056572794914246\n",
            "40290 val_loss: 0.3138923645019531, train_loss: 0.005107731092721224\n",
            "40300 val_loss: 0.3392437696456909, train_loss: 0.0040326411835849285\n",
            "40310 val_loss: 0.3134113550186157, train_loss: 0.0044630467891693115\n",
            "40320 val_loss: 0.2935892939567566, train_loss: 0.011252392083406448\n",
            "40330 val_loss: 0.31552860140800476, train_loss: 0.004243836272507906\n",
            "40340 val_loss: 0.34185945987701416, train_loss: 0.003974098712205887\n",
            "40350 val_loss: 0.3017157316207886, train_loss: 0.005895149894058704\n",
            "40360 val_loss: 0.3353550434112549, train_loss: 0.004249128513038158\n",
            "40370 val_loss: 0.33533287048339844, train_loss: 0.004093576688319445\n",
            "40380 val_loss: 0.3181942105293274, train_loss: 0.010623912326991558\n",
            "40390 val_loss: 0.3185369074344635, train_loss: 0.00400233780965209\n",
            "40400 val_loss: 0.3236435651779175, train_loss: 0.0036820145323872566\n",
            "40410 val_loss: 0.32280394434928894, train_loss: 0.003246295265853405\n",
            "40420 val_loss: 0.3804343342781067, train_loss: 0.005893191322684288\n",
            "40430 val_loss: 0.3557794988155365, train_loss: 0.0066066007129848\n",
            "40440 val_loss: 0.3193613290786743, train_loss: 0.003977708984166384\n",
            "40450 val_loss: 0.3707412779331207, train_loss: 0.006857727654278278\n",
            "40460 val_loss: 0.32341256737709045, train_loss: 0.004382149316370487\n",
            "40470 val_loss: 0.3272741734981537, train_loss: 0.003663272364065051\n",
            "40480 val_loss: 0.31620511412620544, train_loss: 0.005167076829820871\n",
            "40490 val_loss: 0.31357085704803467, train_loss: 0.006715353112667799\n",
            "40500 val_loss: 0.3349594473838806, train_loss: 0.0033637857995927334\n",
            "40510 val_loss: 0.3767131268978119, train_loss: 0.0037272393237799406\n",
            "40520 val_loss: 0.330434113740921, train_loss: 0.003483155742287636\n",
            "40530 val_loss: 0.32278746366500854, train_loss: 0.00745558412745595\n",
            "40540 val_loss: 0.33349815011024475, train_loss: 0.0037126538809388876\n",
            "40550 val_loss: 0.33771392703056335, train_loss: 0.0035817953757941723\n",
            "40560 val_loss: 0.3182734251022339, train_loss: 0.0042988513596355915\n",
            "40570 val_loss: 0.33597221970558167, train_loss: 0.003399395616725087\n",
            "40580 val_loss: 0.327906996011734, train_loss: 0.0034926889929920435\n",
            "40590 val_loss: 0.34243103861808777, train_loss: 0.004263383336365223\n",
            "40600 val_loss: 0.3434492349624634, train_loss: 0.003548524808138609\n",
            "40610 val_loss: 0.3308863937854767, train_loss: 0.0034457542933523655\n",
            "40620 val_loss: 0.3241402804851532, train_loss: 0.0035788787063211203\n",
            "40630 val_loss: 0.330294668674469, train_loss: 0.0032584010623395443\n",
            "40640 val_loss: 0.319077730178833, train_loss: 0.003628177335485816\n",
            "40650 val_loss: 0.3891705572605133, train_loss: 0.00573793426156044\n",
            "40660 val_loss: 0.32740098237991333, train_loss: 0.0040330905467271805\n",
            "40670 val_loss: 0.33443066477775574, train_loss: 0.0034459521993994713\n",
            "40680 val_loss: 0.33776387572288513, train_loss: 0.0032162927091121674\n",
            "40690 val_loss: 0.4027935266494751, train_loss: 0.011110986582934856\n",
            "40700 val_loss: 0.31977909803390503, train_loss: 0.003953240811824799\n",
            "40710 val_loss: 0.33962807059288025, train_loss: 0.003315503243356943\n",
            "40720 val_loss: 0.3448545038700104, train_loss: 0.0035380057524889708\n",
            "40730 val_loss: 0.3240654468536377, train_loss: 0.0035903416574001312\n",
            "40740 val_loss: 0.32173341512680054, train_loss: 0.0035403750371187925\n",
            "40750 val_loss: 0.31783321499824524, train_loss: 0.0053361766040325165\n",
            "40760 val_loss: 0.3491298258304596, train_loss: 0.00424351217225194\n",
            "40770 val_loss: 0.32494840025901794, train_loss: 0.003528983099386096\n",
            "40780 val_loss: 0.3420931398868561, train_loss: 0.0034681193064898252\n",
            "40790 val_loss: 0.33047041296958923, train_loss: 0.0033609450329095125\n",
            "40800 val_loss: 0.3400840163230896, train_loss: 0.003352500731125474\n",
            "40810 val_loss: 0.35211172699928284, train_loss: 0.003962001763284206\n",
            "40820 val_loss: 0.32319456338882446, train_loss: 0.0036724177189171314\n",
            "40830 val_loss: 0.34109050035476685, train_loss: 0.0032003559172153473\n",
            "40840 val_loss: 0.3324694037437439, train_loss: 0.0068107363767921925\n",
            "40850 val_loss: 0.35892805457115173, train_loss: 0.003886205144226551\n",
            "40860 val_loss: 0.41362640261650085, train_loss: 0.009710640646517277\n",
            "40870 val_loss: 0.32729068398475647, train_loss: 0.0034323623403906822\n",
            "40880 val_loss: 0.38874515891075134, train_loss: 0.00950198620557785\n",
            "40890 val_loss: 0.3272252678871155, train_loss: 0.003688907716423273\n",
            "40900 val_loss: 0.48590323328971863, train_loss: 0.02517256885766983\n",
            "40910 val_loss: 0.33392399549484253, train_loss: 0.002974756294861436\n",
            "40920 val_loss: 0.3333360552787781, train_loss: 0.0030315157491713762\n",
            "40930 val_loss: 0.33354878425598145, train_loss: 0.005332907661795616\n",
            "40940 val_loss: 0.32610023021698, train_loss: 0.0032975913491100073\n",
            "40950 val_loss: 0.3344976305961609, train_loss: 0.0032284243497997522\n",
            "40960 val_loss: 0.3349224030971527, train_loss: 0.003536870935931802\n",
            "40970 val_loss: 0.332710325717926, train_loss: 0.0031826922204345465\n",
            "40980 val_loss: 0.6088186502456665, train_loss: 0.14725486934185028\n",
            "40990 val_loss: 0.3793891370296478, train_loss: 0.013197199441492558\n",
            "41000 val_loss: 0.34567713737487793, train_loss: 0.006052209995687008\n",
            "41010 val_loss: 0.33831408619880676, train_loss: 0.004226920194923878\n",
            "41020 val_loss: 0.35131409764289856, train_loss: 0.004141821060329676\n",
            "41030 val_loss: 0.3402411639690399, train_loss: 0.004957444034516811\n",
            "41040 val_loss: 0.3434239625930786, train_loss: 0.004552643746137619\n",
            "41050 val_loss: 0.32377949357032776, train_loss: 0.004513985477387905\n",
            "41060 val_loss: 0.3359068036079407, train_loss: 0.0032033980824053288\n",
            "41070 val_loss: 0.3324846625328064, train_loss: 0.004701974336057901\n",
            "41080 val_loss: 0.3176161050796509, train_loss: 0.009411677718162537\n",
            "41090 val_loss: 0.31508868932724, train_loss: 0.005861719138920307\n",
            "41100 val_loss: 0.3281104564666748, train_loss: 0.003546796040609479\n",
            "41110 val_loss: 0.3465592861175537, train_loss: 0.0032020641956478357\n",
            "41120 val_loss: 0.3259912431240082, train_loss: 0.004295849706977606\n",
            "41130 val_loss: 0.3608168363571167, train_loss: 0.004110353067517281\n",
            "41140 val_loss: 0.3627420961856842, train_loss: 0.0040236664935946465\n",
            "41150 val_loss: 0.4103551506996155, train_loss: 0.009167907759547234\n",
            "41160 val_loss: 0.3664167821407318, train_loss: 0.0036196736618876457\n",
            "41170 val_loss: 0.3526048958301544, train_loss: 0.0030449372716248035\n",
            "41180 val_loss: 0.32858121395111084, train_loss: 0.0037647171411663294\n",
            "41190 val_loss: 0.3676988184452057, train_loss: 0.003590579144656658\n",
            "41200 val_loss: 0.3620188236236572, train_loss: 0.0034001993481069803\n",
            "41210 val_loss: 0.33584320545196533, train_loss: 0.0045507620088756084\n",
            "41220 val_loss: 0.36614444851875305, train_loss: 0.004115401301532984\n",
            "41230 val_loss: 0.36684679985046387, train_loss: 0.005812952760607004\n",
            "41240 val_loss: 0.35999801754951477, train_loss: 0.0030822071712464094\n",
            "41250 val_loss: 0.3451123833656311, train_loss: 0.0030003127176314592\n",
            "41260 val_loss: 0.3259415626525879, train_loss: 0.0031956385355442762\n",
            "41270 val_loss: 0.3572113513946533, train_loss: 0.0030766178388148546\n",
            "41280 val_loss: 0.33579057455062866, train_loss: 0.004154825583100319\n",
            "41290 val_loss: 0.33103370666503906, train_loss: 0.0035400432534515858\n",
            "41300 val_loss: 0.4121958017349243, train_loss: 0.003800352104008198\n",
            "41310 val_loss: 0.35516393184661865, train_loss: 0.0028952895663678646\n",
            "41320 val_loss: 0.3507225811481476, train_loss: 0.0031382523011416197\n",
            "41330 val_loss: 0.36260226368904114, train_loss: 0.003257153555750847\n",
            "41340 val_loss: 0.32013437151908875, train_loss: 0.004505039192736149\n",
            "41350 val_loss: 0.33627912402153015, train_loss: 0.0033052980434149504\n",
            "41360 val_loss: 0.4236621856689453, train_loss: 0.012062283232808113\n",
            "41370 val_loss: 0.3259056508541107, train_loss: 0.004215299617499113\n",
            "41380 val_loss: 0.3607485890388489, train_loss: 0.003772756550461054\n",
            "41390 val_loss: 0.3272308111190796, train_loss: 0.004013950936496258\n",
            "41400 val_loss: 0.33261504769325256, train_loss: 0.003868556348606944\n",
            "41410 val_loss: 0.34267133474349976, train_loss: 0.0031234975904226303\n",
            "41420 val_loss: 0.3626185953617096, train_loss: 0.003877451177686453\n",
            "41430 val_loss: 0.342769593000412, train_loss: 0.0032183099538087845\n",
            "41440 val_loss: 0.3403661847114563, train_loss: 0.0033291790168732405\n",
            "41450 val_loss: 0.33747273683547974, train_loss: 0.003370292019098997\n",
            "41460 val_loss: 0.4417286515235901, train_loss: 0.014417323283851147\n",
            "41470 val_loss: 0.34708794951438904, train_loss: 0.0034672666806727648\n",
            "41480 val_loss: 0.3520427644252777, train_loss: 0.003702946472913027\n",
            "41490 val_loss: 0.3787008225917816, train_loss: 0.004164291545748711\n",
            "41500 val_loss: 0.3596321642398834, train_loss: 0.003547951579093933\n",
            "41510 val_loss: 0.34704849123954773, train_loss: 0.004012541379779577\n",
            "41520 val_loss: 0.36009928584098816, train_loss: 0.004444901365786791\n",
            "41530 val_loss: 0.35982710123062134, train_loss: 0.003850727342069149\n",
            "41540 val_loss: 0.3421367108821869, train_loss: 0.004393925424665213\n",
            "41550 val_loss: 0.3398917615413666, train_loss: 0.0036375306081026793\n",
            "41560 val_loss: 0.36923784017562866, train_loss: 0.005037900060415268\n",
            "41570 val_loss: 0.41725626587867737, train_loss: 0.01111912727355957\n",
            "41580 val_loss: 0.3828123211860657, train_loss: 0.005595842842012644\n",
            "41590 val_loss: 0.36738476157188416, train_loss: 0.0034550440032035112\n",
            "41600 val_loss: 0.3625447452068329, train_loss: 0.003114628605544567\n",
            "41610 val_loss: 0.37131741642951965, train_loss: 0.005046321544796228\n",
            "41620 val_loss: 0.36441570520401, train_loss: 0.003138686530292034\n",
            "41630 val_loss: 0.3386869728565216, train_loss: 0.0033007182646542788\n",
            "41640 val_loss: 0.3494063913822174, train_loss: 0.0030533778481185436\n",
            "41650 val_loss: 0.3399285674095154, train_loss: 0.0036129376385360956\n",
            "41660 val_loss: 0.3580920100212097, train_loss: 0.009491474367678165\n",
            "41670 val_loss: 0.3495585024356842, train_loss: 0.0033956337720155716\n",
            "41680 val_loss: 0.3635489046573639, train_loss: 0.003006775164976716\n",
            "41690 val_loss: 0.33405500650405884, train_loss: 0.00322464806959033\n",
            "41700 val_loss: 0.4430124759674072, train_loss: 0.015005817636847496\n",
            "41710 val_loss: 0.35056304931640625, train_loss: 0.006033867597579956\n",
            "41720 val_loss: 0.3379177749156952, train_loss: 0.0028767536859959364\n",
            "41730 val_loss: 0.3524647653102875, train_loss: 0.003040919778868556\n",
            "41740 val_loss: 0.49271678924560547, train_loss: 0.024048009887337685\n",
            "41750 val_loss: 0.41279956698417664, train_loss: 0.009318072348833084\n",
            "41760 val_loss: 0.34749072790145874, train_loss: 0.00447498494759202\n",
            "41770 val_loss: 0.38422122597694397, train_loss: 0.005148273427039385\n",
            "41780 val_loss: 0.35613760352134705, train_loss: 0.00301554286852479\n",
            "41790 val_loss: 0.34239959716796875, train_loss: 0.0032369159162044525\n",
            "41800 val_loss: 0.35192492604255676, train_loss: 0.002867303090170026\n",
            "41810 val_loss: 0.37254032492637634, train_loss: 0.0036600299645215273\n",
            "41820 val_loss: 0.37778064608573914, train_loss: 0.0026948503218591213\n",
            "41830 val_loss: 0.32807907462120056, train_loss: 0.00364514603279531\n",
            "41840 val_loss: 0.41894766688346863, train_loss: 0.013099892064929008\n",
            "41850 val_loss: 0.37076207995414734, train_loss: 0.003527588676661253\n",
            "41860 val_loss: 0.3504706919193268, train_loss: 0.00307533354498446\n",
            "41870 val_loss: 0.32972416281700134, train_loss: 0.004456684924662113\n",
            "41880 val_loss: 0.33906617760658264, train_loss: 0.003103747731074691\n",
            "41890 val_loss: 0.34888097643852234, train_loss: 0.014854137785732746\n",
            "41900 val_loss: 0.3360685706138611, train_loss: 0.0036143125034868717\n",
            "41910 val_loss: 0.3381190299987793, train_loss: 0.0032717047724872828\n",
            "41920 val_loss: 0.33292922377586365, train_loss: 0.006347490940243006\n",
            "41930 val_loss: 0.35383349657058716, train_loss: 0.0027851429767906666\n",
            "41940 val_loss: 0.41805997490882874, train_loss: 0.0028751185163855553\n",
            "41950 val_loss: 0.36607393622398376, train_loss: 0.0029781979974359274\n",
            "41960 val_loss: 0.3442399501800537, train_loss: 0.002959667472168803\n",
            "41970 val_loss: 0.6253567934036255, train_loss: 0.08242415636777878\n",
            "41980 val_loss: 0.3208511769771576, train_loss: 0.00377992307767272\n",
            "41990 val_loss: 0.3481738865375519, train_loss: 0.0037916789297014475\n",
            "42000 val_loss: 0.3503701984882355, train_loss: 0.0033351012971252203\n",
            "42010 val_loss: 0.3478972017765045, train_loss: 0.003028168575838208\n",
            "42020 val_loss: 0.33580246567726135, train_loss: 0.00395806971937418\n",
            "42030 val_loss: 0.34496399760246277, train_loss: 0.005390985868871212\n",
            "42040 val_loss: 0.361250102519989, train_loss: 0.002792173298075795\n",
            "42050 val_loss: 0.35180380940437317, train_loss: 0.0030037022661417723\n",
            "42060 val_loss: 0.34938377141952515, train_loss: 0.00294028059579432\n",
            "42070 val_loss: 0.35053953528404236, train_loss: 0.0027036722749471664\n",
            "42080 val_loss: 0.35347744822502136, train_loss: 0.0027282426599413157\n",
            "42090 val_loss: 0.35969558358192444, train_loss: 0.0032689766958355904\n",
            "42100 val_loss: 0.33220982551574707, train_loss: 0.006699701771140099\n",
            "42110 val_loss: 0.3534221053123474, train_loss: 0.002823395188897848\n",
            "42120 val_loss: 0.3301277160644531, train_loss: 0.004423138219863176\n",
            "42130 val_loss: 0.3561793863773346, train_loss: 0.0031471820548176765\n",
            "42140 val_loss: 0.38914018869400024, train_loss: 0.006020359229296446\n",
            "42150 val_loss: 0.3263903260231018, train_loss: 0.008022375404834747\n",
            "42160 val_loss: 0.37469473481178284, train_loss: 0.005060768686234951\n",
            "42170 val_loss: 0.35176903009414673, train_loss: 0.0033254483714699745\n",
            "42180 val_loss: 0.3298514187335968, train_loss: 0.003749351017177105\n",
            "42190 val_loss: 0.34204015135765076, train_loss: 0.003150542499497533\n",
            "42200 val_loss: 0.3568028509616852, train_loss: 0.002910719020292163\n",
            "42210 val_loss: 0.36267009377479553, train_loss: 0.0035357025917619467\n",
            "42220 val_loss: 0.3441707193851471, train_loss: 0.00276788673363626\n",
            "42230 val_loss: 0.33233171701431274, train_loss: 0.004312010016292334\n",
            "42240 val_loss: 0.33578333258628845, train_loss: 0.0034732255153357983\n",
            "42250 val_loss: 0.3585994243621826, train_loss: 0.002694524358958006\n",
            "42260 val_loss: 0.3345622420310974, train_loss: 0.003282081102952361\n",
            "42270 val_loss: 0.4179891347885132, train_loss: 0.009579825215041637\n",
            "42280 val_loss: 0.34278160333633423, train_loss: 0.0077974204905331135\n",
            "42290 val_loss: 0.3397444784641266, train_loss: 0.0036219435278326273\n",
            "42300 val_loss: 0.3632604777812958, train_loss: 0.0029703497420996428\n",
            "42310 val_loss: 0.33935022354125977, train_loss: 0.003356469329446554\n",
            "42320 val_loss: 0.3425499498844147, train_loss: 0.0034933758433908224\n",
            "42330 val_loss: 0.3596906065940857, train_loss: 0.0033157847356051207\n",
            "42340 val_loss: 0.3602663278579712, train_loss: 0.0027278983034193516\n",
            "42350 val_loss: 0.351155549287796, train_loss: 0.0026999209076166153\n",
            "42360 val_loss: 0.37796440720558167, train_loss: 0.016871562227606773\n",
            "42370 val_loss: 0.3249082565307617, train_loss: 0.004739401862025261\n",
            "42380 val_loss: 0.3777748644351959, train_loss: 0.0033017487730830908\n",
            "42390 val_loss: 0.36645516753196716, train_loss: 0.0028757553081959486\n",
            "42400 val_loss: 0.370462566614151, train_loss: 0.0029377909377217293\n",
            "42410 val_loss: 0.3570527732372284, train_loss: 0.002856485778465867\n",
            "42420 val_loss: 0.37664908170700073, train_loss: 0.003660398069769144\n",
            "42430 val_loss: 0.37520113587379456, train_loss: 0.01563064381480217\n",
            "42440 val_loss: 0.34860652685165405, train_loss: 0.003249343018978834\n",
            "42450 val_loss: 0.35018330812454224, train_loss: 0.0030226989183574915\n",
            "42460 val_loss: 0.3369493782520294, train_loss: 0.00406505586579442\n",
            "42470 val_loss: 0.3583543300628662, train_loss: 0.002624468645080924\n",
            "42480 val_loss: 0.37144771218299866, train_loss: 0.002527270931750536\n",
            "42490 val_loss: 0.39274510741233826, train_loss: 0.0055551715195178986\n",
            "42500 val_loss: 0.3384076654911041, train_loss: 0.0029615124221891165\n",
            "42510 val_loss: 0.3574345111846924, train_loss: 0.0028778829146176577\n",
            "42520 val_loss: 0.3569301962852478, train_loss: 0.0025886076036840677\n",
            "42530 val_loss: 0.36849385499954224, train_loss: 0.002601967891678214\n",
            "42540 val_loss: 0.43833619356155396, train_loss: 0.012125924229621887\n",
            "42550 val_loss: 0.39436087012290955, train_loss: 0.005021232180297375\n",
            "42560 val_loss: 0.339934766292572, train_loss: 0.0047414833679795265\n",
            "42570 val_loss: 0.3311404287815094, train_loss: 0.0064890338107943535\n",
            "42580 val_loss: 0.35514307022094727, train_loss: 0.0025277368258684874\n",
            "42590 val_loss: 0.33684611320495605, train_loss: 0.004413964692503214\n",
            "42600 val_loss: 0.339310884475708, train_loss: 0.011465218849480152\n",
            "42610 val_loss: 0.34773313999176025, train_loss: 0.003410104662179947\n",
            "42620 val_loss: 0.3631708025932312, train_loss: 0.002834522631019354\n",
            "42630 val_loss: 0.3620431423187256, train_loss: 0.0025903135538101196\n",
            "42640 val_loss: 0.33605143427848816, train_loss: 0.004794925916939974\n",
            "42650 val_loss: 0.3632591664791107, train_loss: 0.0025767404586076736\n",
            "42660 val_loss: 0.3924558162689209, train_loss: 0.004683800507336855\n",
            "42670 val_loss: 0.3299841284751892, train_loss: 0.008981109596788883\n",
            "42680 val_loss: 0.35449928045272827, train_loss: 0.002878140192478895\n",
            "42690 val_loss: 0.350792795419693, train_loss: 0.003239496611058712\n",
            "42700 val_loss: 0.32909631729125977, train_loss: 0.00484337517991662\n",
            "42710 val_loss: 0.34390386939048767, train_loss: 0.00283226789906621\n",
            "42720 val_loss: 0.35506686568260193, train_loss: 0.008372279815375805\n",
            "42730 val_loss: 0.35360589623451233, train_loss: 0.0027745445258915424\n",
            "42740 val_loss: 0.3381595313549042, train_loss: 0.00325766927562654\n",
            "42750 val_loss: 0.33810877799987793, train_loss: 0.012489569373428822\n",
            "42760 val_loss: 0.3456086218357086, train_loss: 0.0027052322402596474\n",
            "42770 val_loss: 0.3460897207260132, train_loss: 0.002637069206684828\n",
            "42780 val_loss: 0.34890034794807434, train_loss: 0.0027250992134213448\n",
            "42790 val_loss: 0.41300255060195923, train_loss: 0.006774391978979111\n",
            "42800 val_loss: 0.34941402077674866, train_loss: 0.002691368106752634\n",
            "42810 val_loss: 0.3813575208187103, train_loss: 0.003100836416706443\n",
            "42820 val_loss: 0.3583449721336365, train_loss: 0.016386592760682106\n",
            "42830 val_loss: 0.3485502302646637, train_loss: 0.0025750468485057354\n",
            "42840 val_loss: 0.42158013582229614, train_loss: 0.0026473093312233686\n",
            "42850 val_loss: 0.4098683297634125, train_loss: 0.0024411980994045734\n",
            "42860 val_loss: 0.3547547459602356, train_loss: 0.002607540227472782\n",
            "42870 val_loss: 0.3799344599246979, train_loss: 0.003454386256635189\n",
            "42880 val_loss: 0.36295807361602783, train_loss: 0.002599694998934865\n",
            "42890 val_loss: 0.3486230671405792, train_loss: 0.0035754952114075422\n",
            "42900 val_loss: 0.44192495942115784, train_loss: 0.014830856584012508\n",
            "42910 val_loss: 0.34584176540374756, train_loss: 0.0028736479580402374\n",
            "42920 val_loss: 0.3602311313152313, train_loss: 0.003247053362429142\n",
            "42930 val_loss: 0.35576707124710083, train_loss: 0.002644280670210719\n",
            "42940 val_loss: 0.3462062478065491, train_loss: 0.0028332225047051907\n",
            "42950 val_loss: 0.34980064630508423, train_loss: 0.002622791100293398\n",
            "42960 val_loss: 0.3445008099079132, train_loss: 0.00276555516757071\n",
            "42970 val_loss: 0.32808607816696167, train_loss: 0.010802341625094414\n",
            "42980 val_loss: 0.3548862040042877, train_loss: 0.0027247988618910313\n",
            "42990 val_loss: 0.3874676525592804, train_loss: 0.004205247387290001\n",
            "43000 val_loss: 0.38008907437324524, train_loss: 0.002786685014143586\n",
            "43010 val_loss: 0.39355120062828064, train_loss: 0.0052517130970954895\n",
            "43020 val_loss: 0.36831262707710266, train_loss: 0.0030956645496189594\n",
            "43030 val_loss: 0.3595767617225647, train_loss: 0.002659850986674428\n",
            "43040 val_loss: 0.34479090571403503, train_loss: 0.003220444777980447\n",
            "43050 val_loss: 0.3680329918861389, train_loss: 0.0027100713923573494\n",
            "43060 val_loss: 0.3681379556655884, train_loss: 0.0025129744317382574\n",
            "43070 val_loss: 0.3610319495201111, train_loss: 0.003278323682025075\n",
            "43080 val_loss: 0.3585226535797119, train_loss: 0.0026173945516347885\n",
            "43090 val_loss: 0.36259210109710693, train_loss: 0.002566490788012743\n",
            "43100 val_loss: 0.3692646324634552, train_loss: 0.002632938092574477\n",
            "43110 val_loss: 0.3688216209411621, train_loss: 0.0030215352308005095\n",
            "43120 val_loss: 0.37720176577568054, train_loss: 0.003409586613997817\n",
            "43130 val_loss: 0.3776583969593048, train_loss: 0.0034165114630013704\n",
            "43140 val_loss: 0.36490121483802795, train_loss: 0.0025244595017284155\n",
            "43150 val_loss: 0.37321972846984863, train_loss: 0.0028341002762317657\n",
            "43160 val_loss: 0.3576284945011139, train_loss: 0.0037453612312674522\n",
            "43170 val_loss: 0.3785761594772339, train_loss: 0.003181609557941556\n",
            "43180 val_loss: 0.36226001381874084, train_loss: 0.00239847251214087\n",
            "43190 val_loss: 0.37446078658103943, train_loss: 0.004566249903291464\n",
            "43200 val_loss: 0.3616105616092682, train_loss: 0.0036653296556323767\n",
            "43210 val_loss: 0.36912456154823303, train_loss: 0.002993788104504347\n",
            "43220 val_loss: 0.3769019544124603, train_loss: 0.002508236328139901\n",
            "43230 val_loss: 0.3618793189525604, train_loss: 0.0026411262806504965\n",
            "43240 val_loss: 0.34455767273902893, train_loss: 0.005020898301154375\n",
            "43250 val_loss: 0.34666621685028076, train_loss: 0.0038424627855420113\n",
            "43260 val_loss: 0.3719765543937683, train_loss: 0.0026770986150950193\n",
            "43270 val_loss: 0.3459765911102295, train_loss: 0.0035316357389092445\n",
            "43280 val_loss: 0.34381377696990967, train_loss: 0.006118037272244692\n",
            "43290 val_loss: 0.41079050302505493, train_loss: 0.005836671683937311\n",
            "43300 val_loss: 0.344082772731781, train_loss: 0.004365194123238325\n",
            "43310 val_loss: 0.38003700971603394, train_loss: 0.0030735055916011333\n",
            "43320 val_loss: 0.396341472864151, train_loss: 0.004771192092448473\n",
            "43330 val_loss: 0.3556663393974304, train_loss: 0.003257902106270194\n",
            "43340 val_loss: 0.36047056317329407, train_loss: 0.00293857348151505\n",
            "43350 val_loss: 0.36600539088249207, train_loss: 0.0026732205878943205\n",
            "43360 val_loss: 0.3704638183116913, train_loss: 0.0025244709104299545\n",
            "43370 val_loss: 0.36577391624450684, train_loss: 0.0026197589468210936\n",
            "43380 val_loss: 0.35096803307533264, train_loss: 0.003145982977002859\n",
            "43390 val_loss: 0.3869941234588623, train_loss: 0.003664458869025111\n",
            "43400 val_loss: 0.3442906439304352, train_loss: 0.008785143494606018\n",
            "43410 val_loss: 0.4083142876625061, train_loss: 0.01360451802611351\n",
            "43420 val_loss: 0.3851913809776306, train_loss: 0.009048862382769585\n",
            "43430 val_loss: 0.3632300794124603, train_loss: 0.002912013093009591\n",
            "43440 val_loss: 0.3651528060436249, train_loss: 0.0025492345448583364\n",
            "43450 val_loss: 0.3642786741256714, train_loss: 0.002559536835178733\n",
            "43460 val_loss: 0.3731570541858673, train_loss: 0.002553492086008191\n",
            "43470 val_loss: 0.48645296692848206, train_loss: 0.01727910153567791\n",
            "43480 val_loss: 0.3621562421321869, train_loss: 0.0024102632887661457\n",
            "43490 val_loss: 0.3519376516342163, train_loss: 0.0028713613282889128\n",
            "43500 val_loss: 0.3943975567817688, train_loss: 0.0042387316934764385\n",
            "43510 val_loss: 0.4081823229789734, train_loss: 0.00594825716689229\n",
            "43520 val_loss: 0.40321069955825806, train_loss: 0.005462100729346275\n",
            "43530 val_loss: 0.38337692618370056, train_loss: 0.012629314325749874\n",
            "43540 val_loss: 0.36954817175865173, train_loss: 0.002692120149731636\n",
            "43550 val_loss: 0.35334330797195435, train_loss: 0.0039932564832270145\n",
            "43560 val_loss: 0.3700075149536133, train_loss: 0.00254011619836092\n",
            "43570 val_loss: 0.3551032543182373, train_loss: 0.002804398536682129\n",
            "43580 val_loss: 0.33534762263298035, train_loss: 0.005402920302003622\n",
            "43590 val_loss: 0.6059508323669434, train_loss: 0.08665304630994797\n",
            "43600 val_loss: 0.368756502866745, train_loss: 0.003685077652335167\n",
            "43610 val_loss: 0.3465353548526764, train_loss: 0.003421412082388997\n",
            "43620 val_loss: 0.3410698175430298, train_loss: 0.0034636349882930517\n",
            "43630 val_loss: 0.3570886552333832, train_loss: 0.002714126603677869\n",
            "43640 val_loss: 0.34417158365249634, train_loss: 0.004088199697434902\n",
            "43650 val_loss: 0.3976282477378845, train_loss: 0.0025651303585618734\n",
            "43660 val_loss: 0.38028550148010254, train_loss: 0.002469103317707777\n",
            "43670 val_loss: 0.5515131950378418, train_loss: 0.031127559021115303\n",
            "43680 val_loss: 0.3808611333370209, train_loss: 0.003148952964693308\n",
            "43690 val_loss: 0.3776033818721771, train_loss: 0.015410641208291054\n",
            "43700 val_loss: 0.4121007025241852, train_loss: 0.004673770163208246\n",
            "43710 val_loss: 0.38790658116340637, train_loss: 0.003126122523099184\n",
            "43720 val_loss: 0.6435578465461731, train_loss: 0.07451862096786499\n",
            "43730 val_loss: 0.3673718273639679, train_loss: 0.003273341106250882\n",
            "43740 val_loss: 0.356579065322876, train_loss: 0.002541926223784685\n",
            "43750 val_loss: 0.3642609119415283, train_loss: 0.0024404542054980993\n",
            "43760 val_loss: 0.34631943702697754, train_loss: 0.003685951931402087\n",
            "43770 val_loss: 0.3531028926372528, train_loss: 0.00904238410294056\n",
            "43780 val_loss: 0.40777337551116943, train_loss: 0.005968722980469465\n",
            "43790 val_loss: 0.372517853975296, train_loss: 0.0027137575671076775\n",
            "43800 val_loss: 0.3694344758987427, train_loss: 0.0028606108389794827\n",
            "43810 val_loss: 0.3554684519767761, train_loss: 0.0031633717007935047\n",
            "43820 val_loss: 0.36064085364341736, train_loss: 0.0027526277117431164\n",
            "43830 val_loss: 0.36564531922340393, train_loss: 0.002687296597287059\n",
            "43840 val_loss: 0.375565767288208, train_loss: 0.002959589473903179\n",
            "43850 val_loss: 0.4115811288356781, train_loss: 0.005716037005186081\n",
            "43860 val_loss: 0.3573059141635895, train_loss: 0.0026217878330498934\n",
            "43870 val_loss: 0.3393348455429077, train_loss: 0.004060477018356323\n",
            "43880 val_loss: 0.3756992220878601, train_loss: 0.0025822659954428673\n",
            "43890 val_loss: 0.3663952648639679, train_loss: 0.0024994276463985443\n",
            "43900 val_loss: 0.3654337525367737, train_loss: 0.0025601827073842287\n",
            "43910 val_loss: 0.36166977882385254, train_loss: 0.00334412744268775\n",
            "43920 val_loss: 0.38401249051094055, train_loss: 0.002750406041741371\n",
            "43930 val_loss: 0.34813442826271057, train_loss: 0.003846837906166911\n",
            "43940 val_loss: 0.3790968358516693, train_loss: 0.002858412452042103\n",
            "43950 val_loss: 0.35001274943351746, train_loss: 0.0035229476634413004\n",
            "43960 val_loss: 0.37277790904045105, train_loss: 0.00329802930355072\n",
            "43970 val_loss: 0.3619367182254791, train_loss: 0.0029252993408590555\n",
            "43980 val_loss: 0.3863110840320587, train_loss: 0.014011201448738575\n",
            "43990 val_loss: 0.40660545229911804, train_loss: 0.00576120475307107\n",
            "44000 val_loss: 0.37943926453590393, train_loss: 0.0025318849366158247\n",
            "44010 val_loss: 0.36165323853492737, train_loss: 0.0027142127510160208\n",
            "44020 val_loss: 0.3693261742591858, train_loss: 0.0024752537719905376\n",
            "44030 val_loss: 0.37370386719703674, train_loss: 0.0022540721110999584\n",
            "44040 val_loss: 0.36478397250175476, train_loss: 0.008930439129471779\n",
            "44050 val_loss: 0.393027126789093, train_loss: 0.003051597625017166\n",
            "44060 val_loss: 0.41651424765586853, train_loss: 0.003827356966212392\n",
            "44070 val_loss: 0.3700709939002991, train_loss: 0.003093135077506304\n",
            "44080 val_loss: 0.3734320104122162, train_loss: 0.0023495075292885303\n",
            "44090 val_loss: 0.42013612389564514, train_loss: 0.006027547176927328\n",
            "44100 val_loss: 0.3711106777191162, train_loss: 0.0025117509067058563\n",
            "44110 val_loss: 0.34925568103790283, train_loss: 0.003052390879020095\n",
            "44120 val_loss: 0.39068371057510376, train_loss: 0.01592004857957363\n",
            "44130 val_loss: 0.36263948678970337, train_loss: 0.002581296255812049\n",
            "44140 val_loss: 0.36651700735092163, train_loss: 0.0025676731020212173\n",
            "44150 val_loss: 0.36472970247268677, train_loss: 0.002535725012421608\n",
            "44160 val_loss: 0.41121944785118103, train_loss: 0.00437566265463829\n",
            "44170 val_loss: 0.3722843527793884, train_loss: 0.002749467734247446\n",
            "44180 val_loss: 0.3784426152706146, train_loss: 0.002554002683609724\n",
            "44190 val_loss: 0.35006842017173767, train_loss: 0.004838571418076754\n",
            "44200 val_loss: 0.41143155097961426, train_loss: 0.010549627244472504\n",
            "44210 val_loss: 0.376899391412735, train_loss: 0.0021916143596172333\n",
            "44220 val_loss: 0.37063002586364746, train_loss: 0.013982612639665604\n",
            "44230 val_loss: 0.3791724741458893, train_loss: 0.015080256387591362\n",
            "44240 val_loss: 0.3742789626121521, train_loss: 0.0023702136240899563\n",
            "44250 val_loss: 0.3803985118865967, train_loss: 0.0025359175633639097\n",
            "44260 val_loss: 0.36725252866744995, train_loss: 0.0023425815161317587\n",
            "44270 val_loss: 0.35760870575904846, train_loss: 0.005687637720257044\n",
            "44280 val_loss: 0.3562961518764496, train_loss: 0.011300944723188877\n",
            "44290 val_loss: 0.35476526618003845, train_loss: 0.003273568581789732\n",
            "44300 val_loss: 0.40395626425743103, train_loss: 0.003625141689553857\n",
            "44310 val_loss: 0.36430925130844116, train_loss: 0.006125542800873518\n",
            "44320 val_loss: 0.3785357177257538, train_loss: 0.0021561074536293745\n",
            "44330 val_loss: 0.383756548166275, train_loss: 0.003037954680621624\n",
            "44340 val_loss: 0.37854743003845215, train_loss: 0.002517695538699627\n",
            "44350 val_loss: 0.3879638910293579, train_loss: 0.003237650729715824\n",
            "44360 val_loss: 0.3356530964374542, train_loss: 0.01330053061246872\n",
            "44370 val_loss: 0.3584742546081543, train_loss: 0.0037497144658118486\n",
            "44380 val_loss: 0.36143526434898376, train_loss: 0.00272930390201509\n",
            "44390 val_loss: 0.3655560612678528, train_loss: 0.002678120508790016\n",
            "44400 val_loss: 0.3682164251804352, train_loss: 0.008196203969419003\n",
            "44410 val_loss: 0.3757505416870117, train_loss: 0.0023453275207430124\n",
            "44420 val_loss: 0.4372269809246063, train_loss: 0.00926794670522213\n",
            "44430 val_loss: 0.37352901697158813, train_loss: 0.0026065907441079617\n",
            "44440 val_loss: 0.37627148628234863, train_loss: 0.008692982606589794\n",
            "44450 val_loss: 0.37605565786361694, train_loss: 0.0044924421235919\n",
            "44460 val_loss: 0.4133777618408203, train_loss: 0.017614878714084625\n",
            "44470 val_loss: 0.39506688714027405, train_loss: 0.002539865206927061\n",
            "44480 val_loss: 0.3782256245613098, train_loss: 0.0027416287921369076\n",
            "44490 val_loss: 0.3559059798717499, train_loss: 0.00957889761775732\n",
            "44500 val_loss: 0.3739378750324249, train_loss: 0.0023441084194928408\n",
            "44510 val_loss: 0.3505629599094391, train_loss: 0.009763788431882858\n",
            "44520 val_loss: 0.36759886145591736, train_loss: 0.002727577229961753\n",
            "44530 val_loss: 0.3596596419811249, train_loss: 0.0030475028324872255\n",
            "44540 val_loss: 0.372628390789032, train_loss: 0.0025632791221141815\n",
            "44550 val_loss: 0.373188853263855, train_loss: 0.0024346751160919666\n",
            "44560 val_loss: 0.43453043699264526, train_loss: 0.008799847215414047\n",
            "44570 val_loss: 0.3662682771682739, train_loss: 0.0032063694670796394\n",
            "44580 val_loss: 0.3628845512866974, train_loss: 0.004219977650791407\n",
            "44590 val_loss: 0.3695961534976959, train_loss: 0.0026353849098086357\n",
            "44600 val_loss: 0.3887898921966553, train_loss: 0.014742235653102398\n",
            "44610 val_loss: 0.36830586194992065, train_loss: 0.002681594341993332\n",
            "44620 val_loss: 0.4631044864654541, train_loss: 0.012496314942836761\n",
            "44630 val_loss: 0.38539624214172363, train_loss: 0.0024279551580548286\n",
            "44640 val_loss: 0.3859301209449768, train_loss: 0.003048595506697893\n",
            "44650 val_loss: 0.38619205355644226, train_loss: 0.002189372666180134\n",
            "44660 val_loss: 0.39330628514289856, train_loss: 0.0024645740631967783\n",
            "44670 val_loss: 0.4028417468070984, train_loss: 0.0021551104728132486\n",
            "44680 val_loss: 0.3901190459728241, train_loss: 0.004075304139405489\n",
            "44690 val_loss: 0.3910812735557556, train_loss: 0.0027287446428090334\n",
            "44700 val_loss: 0.3749445080757141, train_loss: 0.002038234146311879\n",
            "44710 val_loss: 0.36815860867500305, train_loss: 0.0024378502275794744\n",
            "44720 val_loss: 0.36542001366615295, train_loss: 0.002614753320813179\n",
            "44730 val_loss: 0.4854901134967804, train_loss: 0.01869424618780613\n",
            "44740 val_loss: 0.37739211320877075, train_loss: 0.006307221949100494\n",
            "44750 val_loss: 0.37991464138031006, train_loss: 0.0022733586374670267\n",
            "44760 val_loss: 0.3917589783668518, train_loss: 0.00282286386936903\n",
            "44770 val_loss: 0.39123767614364624, train_loss: 0.002556876977905631\n",
            "44780 val_loss: 0.37264928221702576, train_loss: 0.002747230464592576\n",
            "44790 val_loss: 0.38055071234703064, train_loss: 0.0024156479630619287\n",
            "44800 val_loss: 0.392193466424942, train_loss: 0.01048377063125372\n",
            "44810 val_loss: 0.382375031709671, train_loss: 0.0026719907764345407\n",
            "44820 val_loss: 0.3732226490974426, train_loss: 0.003463899018242955\n",
            "44830 val_loss: 0.3652596175670624, train_loss: 0.003051965730264783\n",
            "44840 val_loss: 0.3169424831867218, train_loss: 0.01439756527543068\n",
            "44850 val_loss: 0.366222620010376, train_loss: 0.002304359572008252\n",
            "44860 val_loss: 0.35464563965797424, train_loss: 0.0038380336482077837\n",
            "44870 val_loss: 0.39433637261390686, train_loss: 0.0029244478791952133\n",
            "44880 val_loss: 0.37012553215026855, train_loss: 0.0025568008422851562\n",
            "44890 val_loss: 0.3667667806148529, train_loss: 0.002498090732842684\n",
            "44900 val_loss: 0.369609534740448, train_loss: 0.0023877706844359636\n",
            "44910 val_loss: 0.38359180092811584, train_loss: 0.0023948857560753822\n",
            "44920 val_loss: 0.40395283699035645, train_loss: 0.0152744734659791\n",
            "44930 val_loss: 0.37395599484443665, train_loss: 0.0029633441008627415\n",
            "44940 val_loss: 0.3777438700199127, train_loss: 0.002786193508654833\n",
            "44950 val_loss: 0.36621418595314026, train_loss: 0.0036048567853868008\n",
            "44960 val_loss: 0.38338702917099, train_loss: 0.0022607934661209583\n",
            "44970 val_loss: 0.36944955587387085, train_loss: 0.0033762494567781687\n",
            "44980 val_loss: 0.4128778874874115, train_loss: 0.009388452395796776\n",
            "44990 val_loss: 0.40225958824157715, train_loss: 0.0026900041848421097\n",
            "45000 val_loss: 0.4003070592880249, train_loss: 0.0025529114063829184\n",
            "45010 val_loss: 0.38139548897743225, train_loss: 0.002286385279148817\n",
            "45020 val_loss: 0.3863501250743866, train_loss: 0.002146305050700903\n",
            "45030 val_loss: 0.3852529525756836, train_loss: 0.0020775434095412493\n",
            "45040 val_loss: 0.4102802872657776, train_loss: 0.0032029387075453997\n",
            "45050 val_loss: 0.37925246357917786, train_loss: 0.002142779529094696\n",
            "45060 val_loss: 0.38984471559524536, train_loss: 0.002409533830359578\n",
            "45070 val_loss: 0.42823195457458496, train_loss: 0.018696341663599014\n",
            "45080 val_loss: 0.3777879774570465, train_loss: 0.00300384359434247\n",
            "45090 val_loss: 0.3847637176513672, train_loss: 0.0021715927869081497\n",
            "45100 val_loss: 0.37129512429237366, train_loss: 0.0026103185955435038\n",
            "45110 val_loss: 0.386120080947876, train_loss: 0.0021136871073395014\n",
            "45120 val_loss: 0.3560211658477783, train_loss: 0.006680772639811039\n",
            "45130 val_loss: 0.3850513696670532, train_loss: 0.002589089795947075\n",
            "45140 val_loss: 0.40109363198280334, train_loss: 0.002282213419675827\n",
            "45150 val_loss: 0.37215936183929443, train_loss: 0.0041608805768191814\n",
            "45160 val_loss: 0.3998337686061859, train_loss: 0.001979141030460596\n",
            "45170 val_loss: 0.39580655097961426, train_loss: 0.01264354307204485\n",
            "45180 val_loss: 0.4162827134132385, train_loss: 0.014417249709367752\n",
            "45190 val_loss: 0.4985518157482147, train_loss: 0.015307213179767132\n",
            "45200 val_loss: 0.468695729970932, train_loss: 0.01043794211000204\n",
            "45210 val_loss: 0.38157689571380615, train_loss: 0.0022168413270264864\n",
            "45220 val_loss: 0.40537548065185547, train_loss: 0.0021479371935129166\n",
            "45230 val_loss: 0.4006742835044861, train_loss: 0.0022098191548138857\n",
            "45240 val_loss: 0.42500704526901245, train_loss: 0.00446918373927474\n",
            "45250 val_loss: 0.4049760699272156, train_loss: 0.002437133342027664\n",
            "45260 val_loss: 0.36815497279167175, train_loss: 0.0031554820016026497\n",
            "45270 val_loss: 0.3724960684776306, train_loss: 0.002668194007128477\n",
            "45280 val_loss: 0.40146568417549133, train_loss: 0.0021095566917210817\n",
            "45290 val_loss: 0.3895750045776367, train_loss: 0.0025599447544664145\n",
            "45300 val_loss: 0.39385300874710083, train_loss: 0.0023608077317476273\n",
            "45310 val_loss: 0.391387403011322, train_loss: 0.002866640454158187\n",
            "45320 val_loss: 0.4583807587623596, train_loss: 0.008174777962267399\n",
            "45330 val_loss: 0.3759252429008484, train_loss: 0.0028282622806727886\n",
            "45340 val_loss: 0.4380274713039398, train_loss: 0.00581037811934948\n",
            "45350 val_loss: 0.4114270806312561, train_loss: 0.00381718878634274\n",
            "45360 val_loss: 0.4101911783218384, train_loss: 0.01444532722234726\n",
            "45370 val_loss: 0.37784162163734436, train_loss: 0.00250901747494936\n",
            "45380 val_loss: 0.41683250665664673, train_loss: 0.00419546477496624\n",
            "45390 val_loss: 0.379783570766449, train_loss: 0.002501944312825799\n",
            "45400 val_loss: 0.3969184458255768, train_loss: 0.0023315739817917347\n",
            "45410 val_loss: 0.37936729192733765, train_loss: 0.002589283511042595\n",
            "45420 val_loss: 0.45571377873420715, train_loss: 0.0039513385854661465\n",
            "45430 val_loss: 0.43399539589881897, train_loss: 0.002283221110701561\n",
            "45440 val_loss: 0.4021969735622406, train_loss: 0.004422126337885857\n",
            "45450 val_loss: 0.4082513451576233, train_loss: 0.0021489164792001247\n",
            "45460 val_loss: 0.38673722743988037, train_loss: 0.004402183927595615\n",
            "45470 val_loss: 0.4017847180366516, train_loss: 0.005081718787550926\n",
            "45480 val_loss: 0.4073113799095154, train_loss: 0.0022144021932035685\n",
            "45490 val_loss: 0.39118361473083496, train_loss: 0.0021090914960950613\n",
            "45500 val_loss: 0.3960238993167877, train_loss: 0.0021646565292030573\n",
            "45510 val_loss: 0.4240511357784271, train_loss: 0.006154579576104879\n",
            "45520 val_loss: 0.36612287163734436, train_loss: 0.0027662457432597876\n",
            "45530 val_loss: 0.36660799384117126, train_loss: 0.003441406646743417\n",
            "45540 val_loss: 0.38031601905822754, train_loss: 0.0021381990518420935\n",
            "45550 val_loss: 0.37142542004585266, train_loss: 0.004123644437640905\n",
            "45560 val_loss: 0.3812236785888672, train_loss: 0.0026189435739070177\n",
            "45570 val_loss: 0.4065617024898529, train_loss: 0.0025752948131412268\n",
            "45580 val_loss: 0.3611365258693695, train_loss: 0.0027102238964289427\n",
            "45590 val_loss: 0.3736073076725006, train_loss: 0.0028844031039625406\n",
            "45600 val_loss: 0.39449572563171387, train_loss: 0.002423484344035387\n",
            "45610 val_loss: 0.3940879702568054, train_loss: 0.0023041239473968744\n",
            "45620 val_loss: 0.4024220407009125, train_loss: 0.017003867775201797\n",
            "45630 val_loss: 0.3729022443294525, train_loss: 0.003200822276994586\n",
            "45640 val_loss: 0.40377479791641235, train_loss: 0.002310144482180476\n",
            "45650 val_loss: 0.37797027826309204, train_loss: 0.0027212966233491898\n",
            "45660 val_loss: 0.38159051537513733, train_loss: 0.0025637061335146427\n",
            "45670 val_loss: 0.40702107548713684, train_loss: 0.0023988487664610147\n",
            "45680 val_loss: 0.3814658522605896, train_loss: 0.002955123782157898\n",
            "45690 val_loss: 0.40163013339042664, train_loss: 0.0024085300974547863\n",
            "45700 val_loss: 0.4834616482257843, train_loss: 0.013640583492815495\n",
            "45710 val_loss: 0.39016231894493103, train_loss: 0.002599575789645314\n",
            "45720 val_loss: 0.3888973891735077, train_loss: 0.0026265813503414392\n",
            "45730 val_loss: 0.3975975811481476, train_loss: 0.0020496079232543707\n",
            "45740 val_loss: 0.39992815256118774, train_loss: 0.002324165077880025\n",
            "45750 val_loss: 0.39984217286109924, train_loss: 0.002853517420589924\n",
            "45760 val_loss: 0.3528597354888916, train_loss: 0.006549435667693615\n",
            "45770 val_loss: 0.36613526940345764, train_loss: 0.0057789417915046215\n",
            "45780 val_loss: 0.3827636241912842, train_loss: 0.002310479525476694\n",
            "45790 val_loss: 0.3955976366996765, train_loss: 0.0021946507040411234\n",
            "45800 val_loss: 0.3827381134033203, train_loss: 0.0025394526310265064\n",
            "45810 val_loss: 0.3985479772090912, train_loss: 0.0021259444765746593\n",
            "45820 val_loss: 0.3817320466041565, train_loss: 0.002070685848593712\n",
            "45830 val_loss: 0.38108354806900024, train_loss: 0.002181215211749077\n",
            "45840 val_loss: 0.38648420572280884, train_loss: 0.002080014906823635\n",
            "45850 val_loss: 0.37268415093421936, train_loss: 0.0036876641679555178\n",
            "45860 val_loss: 0.3951232433319092, train_loss: 0.0020517068915069103\n",
            "45870 val_loss: 0.3669397830963135, train_loss: 0.004107166547328234\n",
            "45880 val_loss: 0.45780685544013977, train_loss: 0.00662674056366086\n",
            "45890 val_loss: 0.4025081396102905, train_loss: 0.016312867403030396\n",
            "45900 val_loss: 0.396564245223999, train_loss: 0.0024813388008624315\n",
            "45910 val_loss: 0.3974248766899109, train_loss: 0.0029568318277597427\n",
            "45920 val_loss: 0.4279486835002899, train_loss: 0.006531190127134323\n",
            "45930 val_loss: 0.3842936158180237, train_loss: 0.0023630803916603327\n",
            "45940 val_loss: 0.3889085650444031, train_loss: 0.002080750185996294\n",
            "45950 val_loss: 0.39977067708969116, train_loss: 0.0022256679367274046\n",
            "45960 val_loss: 0.3957080841064453, train_loss: 0.002110007219016552\n",
            "45970 val_loss: 0.3889947235584259, train_loss: 0.002351073082536459\n",
            "45980 val_loss: 0.40470173954963684, train_loss: 0.0026191622018814087\n",
            "45990 val_loss: 0.3740908205509186, train_loss: 0.0026560116093605757\n",
            "46000 val_loss: 0.3849372863769531, train_loss: 0.00198421161621809\n",
            "46010 val_loss: 0.414339154958725, train_loss: 0.00303093483671546\n",
            "46020 val_loss: 0.37357231974601746, train_loss: 0.004741591401398182\n",
            "46030 val_loss: 0.4004485607147217, train_loss: 0.0019144172547385097\n",
            "46040 val_loss: 0.40114083886146545, train_loss: 0.002010389929637313\n",
            "46050 val_loss: 0.4068876802921295, train_loss: 0.0023161619901657104\n",
            "46060 val_loss: 0.3882588744163513, train_loss: 0.004656474571675062\n",
            "46070 val_loss: 0.4038096070289612, train_loss: 0.002086568856611848\n",
            "46080 val_loss: 0.39325642585754395, train_loss: 0.002945819403976202\n",
            "46090 val_loss: 0.3680790960788727, train_loss: 0.017210137099027634\n",
            "46100 val_loss: 0.36682283878326416, train_loss: 0.002648747293278575\n",
            "46110 val_loss: 0.3604445457458496, train_loss: 0.0038222279399633408\n",
            "46120 val_loss: 0.4525090157985687, train_loss: 0.0073062037117779255\n",
            "46130 val_loss: 0.4210178256034851, train_loss: 0.002225195989012718\n",
            "46140 val_loss: 0.42295515537261963, train_loss: 0.0022020952310413122\n",
            "46150 val_loss: 0.41788727045059204, train_loss: 0.004359584301710129\n",
            "46160 val_loss: 0.40567144751548767, train_loss: 0.002291083103045821\n",
            "46170 val_loss: 0.40385422110557556, train_loss: 0.0020304271019995213\n",
            "46180 val_loss: 0.40047264099121094, train_loss: 0.013338844291865826\n",
            "46190 val_loss: 0.3523050844669342, train_loss: 0.006423878949135542\n",
            "46200 val_loss: 0.36484748125076294, train_loss: 0.0032843041699379683\n",
            "46210 val_loss: 0.4003518521785736, train_loss: 0.0022239969111979008\n",
            "46220 val_loss: 0.3915000557899475, train_loss: 0.0019828802905976772\n",
            "46230 val_loss: 0.3983789086341858, train_loss: 0.01157358568161726\n",
            "46240 val_loss: 0.41682660579681396, train_loss: 0.0028239479288458824\n",
            "46250 val_loss: 0.41569218039512634, train_loss: 0.0028418959118425846\n",
            "46260 val_loss: 0.40160471200942993, train_loss: 0.0021312914323061705\n",
            "46270 val_loss: 0.3943723142147064, train_loss: 0.0033846565056592226\n",
            "46280 val_loss: 0.3998139798641205, train_loss: 0.0021566685754805803\n",
            "46290 val_loss: 0.4188612401485443, train_loss: 0.015389001928269863\n",
            "46300 val_loss: 0.3903875946998596, train_loss: 0.0023149133194237947\n",
            "46310 val_loss: 0.44128671288490295, train_loss: 0.004358064848929644\n",
            "46320 val_loss: 0.3682471811771393, train_loss: 0.004953018389642239\n",
            "46330 val_loss: 0.4013577401638031, train_loss: 0.0019182441756129265\n",
            "46340 val_loss: 0.3876577615737915, train_loss: 0.010790545493364334\n",
            "46350 val_loss: 0.3724483847618103, train_loss: 0.012831258587539196\n",
            "46360 val_loss: 0.3826778829097748, train_loss: 0.002441419055685401\n",
            "46370 val_loss: 0.4229017496109009, train_loss: 0.0025569326244294643\n",
            "46380 val_loss: 0.3983524739742279, train_loss: 0.002342777093872428\n",
            "46390 val_loss: 0.4006504416465759, train_loss: 0.003645933698862791\n",
            "46400 val_loss: 0.4053317606449127, train_loss: 0.00792478397488594\n",
            "46410 val_loss: 0.3970717489719391, train_loss: 0.002452267799526453\n",
            "46420 val_loss: 0.42454633116722107, train_loss: 0.003840208984911442\n",
            "46430 val_loss: 0.3983173370361328, train_loss: 0.0021090577356517315\n",
            "46440 val_loss: 0.3940798044204712, train_loss: 0.006949138827621937\n",
            "46450 val_loss: 0.35069096088409424, train_loss: 0.01378028653562069\n",
            "46460 val_loss: 0.3618289530277252, train_loss: 0.005758895538747311\n",
            "46470 val_loss: 0.38741573691368103, train_loss: 0.002743285847827792\n",
            "46480 val_loss: 0.38829925656318665, train_loss: 0.0024708323180675507\n",
            "46490 val_loss: 0.40855270624160767, train_loss: 0.002483772113919258\n",
            "46500 val_loss: 0.3936910033226013, train_loss: 0.010407108813524246\n",
            "46510 val_loss: 0.39464640617370605, train_loss: 0.0019260013941675425\n",
            "46520 val_loss: 0.4087464511394501, train_loss: 0.0023020487278699875\n",
            "46530 val_loss: 0.40728622674942017, train_loss: 0.0021003757137805223\n",
            "46540 val_loss: 0.4488646686077118, train_loss: 0.006163091864436865\n",
            "46550 val_loss: 0.40728119015693665, train_loss: 0.002130259294062853\n",
            "46560 val_loss: 0.40241286158561707, train_loss: 0.00190631952136755\n",
            "46570 val_loss: 0.38997548818588257, train_loss: 0.0025192666798830032\n",
            "46580 val_loss: 0.38606372475624084, train_loss: 0.0021702612284570932\n",
            "46590 val_loss: 0.3789951801300049, train_loss: 0.004151553846895695\n",
            "46600 val_loss: 0.508651852607727, train_loss: 0.003593930508941412\n",
            "46610 val_loss: 0.4486631155014038, train_loss: 0.002580935601145029\n",
            "46620 val_loss: 0.42793551087379456, train_loss: 0.0022057704627513885\n",
            "46630 val_loss: 0.4203137457370758, train_loss: 0.0027301625814288855\n",
            "46640 val_loss: 0.4148440957069397, train_loss: 0.002735108369961381\n",
            "46650 val_loss: 0.46198469400405884, train_loss: 0.009545599110424519\n",
            "46660 val_loss: 0.3797414004802704, train_loss: 0.0026805587112903595\n",
            "46670 val_loss: 0.3657418489456177, train_loss: 0.0036194634158164263\n",
            "46680 val_loss: 0.4538111984729767, train_loss: 0.007551949936896563\n",
            "46690 val_loss: 0.3862974941730499, train_loss: 0.00237025273963809\n",
            "46700 val_loss: 0.41133666038513184, train_loss: 0.002562000183388591\n",
            "46710 val_loss: 0.41059356927871704, train_loss: 0.002588686067610979\n",
            "46720 val_loss: 0.41847530007362366, train_loss: 0.0027004771400243044\n",
            "46730 val_loss: 0.417392373085022, train_loss: 0.001978469081223011\n",
            "46740 val_loss: 0.43276527523994446, train_loss: 0.00471263425424695\n",
            "46750 val_loss: 0.4019376337528229, train_loss: 0.0020854559261351824\n",
            "46760 val_loss: 0.38287901878356934, train_loss: 0.0039853318594396114\n",
            "46770 val_loss: 0.392516553401947, train_loss: 0.002426467603072524\n",
            "46780 val_loss: 0.398438960313797, train_loss: 0.0044831507839262486\n",
            "46790 val_loss: 0.4077078104019165, train_loss: 0.002114677568897605\n",
            "46800 val_loss: 0.4125499725341797, train_loss: 0.0022004302591085434\n",
            "46810 val_loss: 0.41768524050712585, train_loss: 0.002447646576911211\n",
            "46820 val_loss: 0.3994479477405548, train_loss: 0.0020903050899505615\n",
            "46830 val_loss: 0.43834471702575684, train_loss: 0.0055276211351156235\n",
            "46840 val_loss: 0.4926699697971344, train_loss: 0.013907892629504204\n",
            "46850 val_loss: 0.386473149061203, train_loss: 0.0027241490315645933\n",
            "46860 val_loss: 0.3989790380001068, train_loss: 0.002057043369859457\n",
            "46870 val_loss: 0.4036542475223541, train_loss: 0.002018141560256481\n",
            "46880 val_loss: 0.42188066244125366, train_loss: 0.0030537089332938194\n",
            "46890 val_loss: 0.39950525760650635, train_loss: 0.0019502138020470738\n",
            "46900 val_loss: 0.46245092153549194, train_loss: 0.008224718272686005\n",
            "46910 val_loss: 0.38970425724983215, train_loss: 0.002727544168010354\n",
            "46920 val_loss: 0.4053615927696228, train_loss: 0.0021367238368839025\n",
            "46930 val_loss: 0.3828657269477844, train_loss: 0.0026121637783944607\n",
            "46940 val_loss: 0.39682888984680176, train_loss: 0.002169286599382758\n",
            "46950 val_loss: 0.402413547039032, train_loss: 0.0021326360292732716\n",
            "46960 val_loss: 0.409483402967453, train_loss: 0.0022043436765670776\n",
            "46970 val_loss: 0.3989697992801666, train_loss: 0.002704681595787406\n",
            "46980 val_loss: 0.39842674136161804, train_loss: 0.002338448539376259\n",
            "46990 val_loss: 0.40956035256385803, train_loss: 0.0022270262707024813\n",
            "47000 val_loss: 0.4293113946914673, train_loss: 0.0033612828701734543\n",
            "47010 val_loss: 0.4008411169052124, train_loss: 0.001957937143743038\n",
            "47020 val_loss: 0.4091305136680603, train_loss: 0.001990951132029295\n",
            "47030 val_loss: 0.41458067297935486, train_loss: 0.002097749849781394\n",
            "47040 val_loss: 0.40403103828430176, train_loss: 0.0020065444987267256\n",
            "47050 val_loss: 0.41127628087997437, train_loss: 0.001815302763134241\n",
            "47060 val_loss: 0.3621998131275177, train_loss: 0.012445379048585892\n",
            "47070 val_loss: 0.3811265528202057, train_loss: 0.0023105626460164785\n",
            "47080 val_loss: 0.4047602713108063, train_loss: 0.0019959756173193455\n",
            "47090 val_loss: 0.39954930543899536, train_loss: 0.002019258216023445\n",
            "47100 val_loss: 0.40201741456985474, train_loss: 0.012129842303693295\n",
            "47110 val_loss: 3.281303882598877, train_loss: 2.799039840698242\n",
            "47120 val_loss: 0.29128581285476685, train_loss: 0.06439317762851715\n",
            "47130 val_loss: 0.28248944878578186, train_loss: 0.040981896221637726\n",
            "47140 val_loss: 0.26313579082489014, train_loss: 0.017465339973568916\n",
            "47150 val_loss: 0.27147457003593445, train_loss: 0.012631024233996868\n",
            "47160 val_loss: 0.27875417470932007, train_loss: 0.010962940752506256\n",
            "47170 val_loss: 0.28071627020835876, train_loss: 0.009937132708728313\n",
            "47180 val_loss: 0.28060129284858704, train_loss: 0.00957247894257307\n",
            "47190 val_loss: 0.29680293798446655, train_loss: 0.00939954537898302\n",
            "47200 val_loss: 0.2924230992794037, train_loss: 0.009413250721991062\n",
            "47210 val_loss: 0.30539923906326294, train_loss: 0.008445142768323421\n",
            "47220 val_loss: 0.30321019887924194, train_loss: 0.007967469282448292\n",
            "47230 val_loss: 0.3164088726043701, train_loss: 0.007374537643045187\n",
            "47240 val_loss: 0.3282187581062317, train_loss: 0.006391610950231552\n",
            "47250 val_loss: 0.37154388427734375, train_loss: 0.005182047374546528\n",
            "47260 val_loss: 0.36978039145469666, train_loss: 0.004242552910000086\n",
            "47270 val_loss: 0.36324191093444824, train_loss: 0.0033923943992704153\n",
            "47280 val_loss: 0.3666183054447174, train_loss: 0.003600063733756542\n",
            "47290 val_loss: 0.39709627628326416, train_loss: 0.002900357125326991\n",
            "47300 val_loss: 0.3800319731235504, train_loss: 0.002622310072183609\n",
            "47310 val_loss: 0.3790800869464874, train_loss: 0.002263885922729969\n",
            "47320 val_loss: 0.34895139932632446, train_loss: 0.004850430879741907\n",
            "47330 val_loss: 0.36845946311950684, train_loss: 0.0029698649886995554\n",
            "47340 val_loss: 0.37444135546684265, train_loss: 0.0027234700974076986\n",
            "47350 val_loss: 0.3752001225948334, train_loss: 0.002615322358906269\n",
            "47360 val_loss: 0.4720439016819, train_loss: 0.013527369126677513\n",
            "47370 val_loss: 0.42603614926338196, train_loss: 0.0064361924305558205\n",
            "47380 val_loss: 0.3668668270111084, train_loss: 0.002684664446860552\n",
            "47390 val_loss: 0.3554316461086273, train_loss: 0.003079304937273264\n",
            "47400 val_loss: 0.4014945328235626, train_loss: 0.0033044905867427588\n",
            "47410 val_loss: 0.34180769324302673, train_loss: 0.006448571570217609\n",
            "47420 val_loss: 0.3875831961631775, train_loss: 0.0023571972269564867\n",
            "47430 val_loss: 0.373288094997406, train_loss: 0.0025917014572769403\n",
            "47440 val_loss: 0.36333203315734863, train_loss: 0.003971091005951166\n",
            "47450 val_loss: 0.40736711025238037, train_loss: 0.003274837974458933\n",
            "47460 val_loss: 0.3735882341861725, train_loss: 0.002751233521848917\n",
            "47470 val_loss: 0.45712122321128845, train_loss: 0.009821886196732521\n",
            "47480 val_loss: 0.3840135335922241, train_loss: 0.0022871193941682577\n",
            "47490 val_loss: 0.37834882736206055, train_loss: 0.0024756439961493015\n",
            "47500 val_loss: 0.39189642667770386, train_loss: 0.014799483120441437\n",
            "47510 val_loss: 0.37148720026016235, train_loss: 0.0028197893407195807\n",
            "47520 val_loss: 0.45238521695137024, train_loss: 0.009290028363466263\n",
            "47530 val_loss: 0.35982319712638855, train_loss: 0.0037261806428432465\n",
            "47540 val_loss: 0.39101386070251465, train_loss: 0.0021811635233461857\n",
            "47550 val_loss: 0.4295805096626282, train_loss: 0.005830148234963417\n",
            "47560 val_loss: 0.39538806676864624, train_loss: 0.002494516083970666\n",
            "47570 val_loss: 0.3930211663246155, train_loss: 0.0022524434607475996\n",
            "47580 val_loss: 0.3927413821220398, train_loss: 0.0022099411580711603\n",
            "47590 val_loss: 0.3732419013977051, train_loss: 0.014118950814008713\n",
            "47600 val_loss: 0.37908443808555603, train_loss: 0.002105981344357133\n",
            "47610 val_loss: 0.39923596382141113, train_loss: 0.002339499769732356\n",
            "47620 val_loss: 0.4051049053668976, train_loss: 0.0025367753114551306\n",
            "47630 val_loss: 0.36002567410469055, train_loss: 0.006314018741250038\n",
            "47640 val_loss: 0.5076438784599304, train_loss: 0.018482420593500137\n",
            "47650 val_loss: 0.3654780983924866, train_loss: 0.0028771511279046535\n",
            "47660 val_loss: 0.36671504378318787, train_loss: 0.002816468710079789\n",
            "47670 val_loss: 0.3423675298690796, train_loss: 0.006381397135555744\n",
            "47680 val_loss: 0.36688172817230225, train_loss: 0.0026428394485265017\n",
            "47690 val_loss: 0.3986392617225647, train_loss: 0.002581115812063217\n",
            "47700 val_loss: 0.38333114981651306, train_loss: 0.002069109119474888\n",
            "47710 val_loss: 0.392157644033432, train_loss: 0.0022054666187614202\n",
            "47720 val_loss: 0.38601526618003845, train_loss: 0.0019972138106822968\n",
            "47730 val_loss: 0.3792400360107422, train_loss: 0.013202671892940998\n",
            "47740 val_loss: 0.3904849588871002, train_loss: 0.0020913216285407543\n",
            "47750 val_loss: 0.3922591507434845, train_loss: 0.002144778147339821\n",
            "47760 val_loss: 0.394927978515625, train_loss: 0.002044766442850232\n",
            "47770 val_loss: 0.38191837072372437, train_loss: 0.0029924153350293636\n",
            "47780 val_loss: 0.44084858894348145, train_loss: 0.0019566668197512627\n",
            "47790 val_loss: 0.4074050486087799, train_loss: 0.002454152563586831\n",
            "47800 val_loss: 0.3947084844112396, train_loss: 0.0023167242761701345\n",
            "47810 val_loss: 0.37569913268089294, train_loss: 0.0027545220218598843\n",
            "47820 val_loss: 0.3900526463985443, train_loss: 0.0018250998109579086\n",
            "47830 val_loss: 0.4155442416667938, train_loss: 0.0025847814977169037\n",
            "47840 val_loss: 0.4016472101211548, train_loss: 0.0022980747744441032\n",
            "47850 val_loss: 0.4135005474090576, train_loss: 0.0030562144238501787\n",
            "47860 val_loss: 0.3729732632637024, train_loss: 0.0032352537382394075\n",
            "47870 val_loss: 0.38447585701942444, train_loss: 0.002605054061859846\n",
            "47880 val_loss: 0.38886547088623047, train_loss: 0.0019490945851430297\n",
            "47890 val_loss: 0.4285154938697815, train_loss: 0.005371248349547386\n",
            "47900 val_loss: 0.39745888113975525, train_loss: 0.0018277328927069902\n",
            "47910 val_loss: 0.38193389773368835, train_loss: 0.0025777388364076614\n",
            "47920 val_loss: 0.3615663945674896, train_loss: 0.009058821946382523\n",
            "47930 val_loss: 0.4009437561035156, train_loss: 0.0018821883713826537\n",
            "47940 val_loss: 0.38220536708831787, train_loss: 0.0025527076795697212\n",
            "47950 val_loss: 0.42819464206695557, train_loss: 0.0048720394261181355\n",
            "47960 val_loss: 0.42766639590263367, train_loss: 0.001764821819961071\n",
            "47970 val_loss: 0.4089847207069397, train_loss: 0.0021734945476055145\n",
            "47980 val_loss: 0.3877505362033844, train_loss: 0.003008269239217043\n",
            "47990 val_loss: 0.40724408626556396, train_loss: 0.0022756573744118214\n",
            "48000 val_loss: 0.39605703949928284, train_loss: 0.0019286924507468939\n",
            "48010 val_loss: 0.39139771461486816, train_loss: 0.005128417629748583\n",
            "48020 val_loss: 0.4088708758354187, train_loss: 0.0021797555964440107\n",
            "48030 val_loss: 0.3989488482475281, train_loss: 0.01352261658757925\n",
            "48040 val_loss: 0.3961094915866852, train_loss: 0.0019026387017220259\n",
            "48050 val_loss: 0.41868236660957336, train_loss: 0.002029484137892723\n",
            "48060 val_loss: 0.4198695719242096, train_loss: 0.00681968592107296\n",
            "48070 val_loss: 0.40716353058815, train_loss: 0.0020443855319172144\n",
            "48080 val_loss: 0.4081285893917084, train_loss: 0.0032799779437482357\n",
            "48090 val_loss: 0.39090991020202637, train_loss: 0.002815444488078356\n",
            "48100 val_loss: 0.3712650537490845, train_loss: 0.0029460617806762457\n",
            "48110 val_loss: 0.6073740124702454, train_loss: 0.03499846160411835\n",
            "48120 val_loss: 0.39139801263809204, train_loss: 0.0022085991222411394\n",
            "48130 val_loss: 0.39210018515586853, train_loss: 0.0026227571070194244\n",
            "48140 val_loss: 0.39506304264068604, train_loss: 0.002035018987953663\n",
            "48150 val_loss: 0.3778059482574463, train_loss: 0.010028134100139141\n",
            "48160 val_loss: 0.40429478883743286, train_loss: 0.001900626695714891\n",
            "48170 val_loss: 0.39607003331184387, train_loss: 0.0018663363298401237\n",
            "48180 val_loss: 0.4013392925262451, train_loss: 0.0019385309424251318\n",
            "48190 val_loss: 0.3822275698184967, train_loss: 0.002552388235926628\n",
            "48200 val_loss: 0.3876360356807709, train_loss: 0.002185695106163621\n",
            "48210 val_loss: 0.4129357933998108, train_loss: 0.0024755075573921204\n",
            "48220 val_loss: 0.3864099383354187, train_loss: 0.0023311395198106766\n",
            "48230 val_loss: 0.39357495307922363, train_loss: 0.0018990273820236325\n",
            "48240 val_loss: 0.3950235843658447, train_loss: 0.003384144976735115\n",
            "48250 val_loss: 0.3883582651615143, train_loss: 0.0021282231900840998\n",
            "48260 val_loss: 0.39890486001968384, train_loss: 0.0019891755655407906\n",
            "48270 val_loss: 0.38333678245544434, train_loss: 0.002679188270121813\n",
            "48280 val_loss: 0.38701385259628296, train_loss: 0.0021714114118367434\n",
            "48290 val_loss: 0.39427486062049866, train_loss: 0.0018442607251927257\n",
            "48300 val_loss: 0.40828168392181396, train_loss: 0.001778486999683082\n",
            "48310 val_loss: 0.38598042726516724, train_loss: 0.0028399385046213865\n",
            "48320 val_loss: 0.3966427445411682, train_loss: 0.003180385334417224\n",
            "48330 val_loss: 0.4457227289676666, train_loss: 0.0022417535074055195\n",
            "48340 val_loss: 0.47193536162376404, train_loss: 0.009619193151593208\n",
            "48350 val_loss: 0.40144628286361694, train_loss: 0.0036847181618213654\n",
            "48360 val_loss: 0.4042844772338867, train_loss: 0.002663364866748452\n",
            "48370 val_loss: 0.40544945001602173, train_loss: 0.0017676419811323285\n",
            "48380 val_loss: 0.45546773076057434, train_loss: 0.005006682593375444\n",
            "48390 val_loss: 0.4440450072288513, train_loss: 0.003510504961013794\n",
            "48400 val_loss: 0.44278255105018616, train_loss: 0.005002330988645554\n",
            "48410 val_loss: 0.403624951839447, train_loss: 0.0018668374978005886\n",
            "48420 val_loss: 0.3852827847003937, train_loss: 0.0020773482974618673\n",
            "48430 val_loss: 0.43139371275901794, train_loss: 0.005175914615392685\n",
            "48440 val_loss: 0.3831435739994049, train_loss: 0.0023476628120988607\n",
            "48450 val_loss: 0.38699227571487427, train_loss: 0.0021492070518434048\n",
            "48460 val_loss: 0.38508114218711853, train_loss: 0.0037667714059352875\n",
            "48470 val_loss: 0.39547228813171387, train_loss: 0.002083738334476948\n",
            "48480 val_loss: 0.4194324016571045, train_loss: 0.0025754221715033054\n",
            "48490 val_loss: 0.4067477583885193, train_loss: 0.002145837526768446\n",
            "48500 val_loss: 0.41123756766319275, train_loss: 0.0021439979318529367\n",
            "48510 val_loss: 0.39154571294784546, train_loss: 0.0020881635136902332\n",
            "48520 val_loss: 0.4068535268306732, train_loss: 0.0020832684822380543\n",
            "48530 val_loss: 0.5184890031814575, train_loss: 0.017298623919487\n",
            "48540 val_loss: 0.38795703649520874, train_loss: 0.002270575612783432\n",
            "48550 val_loss: 0.4183494448661804, train_loss: 0.0025159737560898066\n",
            "48560 val_loss: 0.3956545293331146, train_loss: 0.0018944189650937915\n",
            "48570 val_loss: 0.5746116638183594, train_loss: 0.02642793022096157\n",
            "48580 val_loss: 0.3870135247707367, train_loss: 0.0063385129906237125\n",
            "48590 val_loss: 0.3941165506839752, train_loss: 0.0030257138423621655\n",
            "48600 val_loss: 0.368573397397995, train_loss: 0.010602121241390705\n",
            "48610 val_loss: 0.40413689613342285, train_loss: 0.001955663086846471\n",
            "48620 val_loss: 0.437875896692276, train_loss: 0.0021302420645952225\n",
            "48630 val_loss: 0.43482470512390137, train_loss: 0.003052561543881893\n",
            "48640 val_loss: 0.4059644937515259, train_loss: 0.00806380808353424\n",
            "48650 val_loss: 0.3918183147907257, train_loss: 0.0018910531653091311\n",
            "48660 val_loss: 0.3961469233036041, train_loss: 0.0017503483686596155\n",
            "48670 val_loss: 0.3890555799007416, train_loss: 0.0018911154475063086\n",
            "48680 val_loss: 0.4734993577003479, train_loss: 0.008516809903085232\n",
            "48690 val_loss: 0.3914959728717804, train_loss: 0.0018246844410896301\n",
            "48700 val_loss: 0.3869706988334656, train_loss: 0.002745480975136161\n",
            "48710 val_loss: 0.5392651557922363, train_loss: 0.021252233535051346\n",
            "48720 val_loss: 0.369584858417511, train_loss: 0.007219701539725065\n",
            "48730 val_loss: 0.4159623086452484, train_loss: 0.0025807598140090704\n",
            "48740 val_loss: 0.4248104989528656, train_loss: 0.0029062507674098015\n",
            "48750 val_loss: 0.40222352743148804, train_loss: 0.002293631434440613\n",
            "48760 val_loss: 0.4132983386516571, train_loss: 0.0017694799462333322\n",
            "48770 val_loss: 0.42562049627304077, train_loss: 0.00201446283608675\n",
            "48780 val_loss: 0.42906317114830017, train_loss: 0.002778204157948494\n",
            "48790 val_loss: 0.4220813512802124, train_loss: 0.002109482418745756\n",
            "48800 val_loss: 0.41844281554222107, train_loss: 0.0020579795818775892\n",
            "48810 val_loss: 0.41218090057373047, train_loss: 0.0034732879139482975\n",
            "48820 val_loss: 0.40376776456832886, train_loss: 0.002286809729412198\n",
            "48830 val_loss: 0.3959933817386627, train_loss: 0.002372609218582511\n",
            "48840 val_loss: 0.40930086374282837, train_loss: 0.0018259749049320817\n",
            "48850 val_loss: 0.42297035455703735, train_loss: 0.002335134893655777\n",
            "48860 val_loss: 0.42461782693862915, train_loss: 0.0029211232904344797\n",
            "48870 val_loss: 0.4400692880153656, train_loss: 0.004731850232928991\n",
            "48880 val_loss: 0.4550919234752655, train_loss: 0.006114929914474487\n",
            "48890 val_loss: 0.4019041955471039, train_loss: 0.0016508925473317504\n",
            "48900 val_loss: 0.37934762239456177, train_loss: 0.013380439020693302\n",
            "48910 val_loss: 0.38902968168258667, train_loss: 0.00216385698877275\n",
            "48920 val_loss: 0.40167754888534546, train_loss: 0.0017178012058138847\n",
            "48930 val_loss: 0.39084392786026, train_loss: 0.002700730226933956\n",
            "48940 val_loss: 0.4192969501018524, train_loss: 0.0020418327767401934\n",
            "48950 val_loss: 0.40147024393081665, train_loss: 0.0017388156848028302\n",
            "48960 val_loss: 0.41728347539901733, train_loss: 0.0018189549446105957\n",
            "48970 val_loss: 0.40940195322036743, train_loss: 0.0020061235409229994\n",
            "48980 val_loss: 0.41568243503570557, train_loss: 0.0020801511127501726\n",
            "48990 val_loss: 0.4158661365509033, train_loss: 0.0016368007054552436\n",
            "49000 val_loss: 0.4754185974597931, train_loss: 0.001910694409161806\n",
            "49010 val_loss: 0.4236277639865875, train_loss: 0.0020538989920169115\n",
            "49020 val_loss: 0.4215896725654602, train_loss: 0.0016379571752622724\n",
            "49030 val_loss: 0.41360118985176086, train_loss: 0.006977397948503494\n",
            "49040 val_loss: 0.396013081073761, train_loss: 0.0021119448356330395\n",
            "49050 val_loss: 0.39601489901542664, train_loss: 0.003603264456614852\n",
            "49060 val_loss: 0.4172547161579132, train_loss: 0.0018719608196988702\n",
            "49070 val_loss: 0.4007970690727234, train_loss: 0.0021228077821433544\n",
            "49080 val_loss: 0.40690457820892334, train_loss: 0.0018635347951203585\n",
            "49090 val_loss: 0.3985847234725952, train_loss: 0.002124159364029765\n",
            "49100 val_loss: 0.42070770263671875, train_loss: 0.0021533502731472254\n",
            "49110 val_loss: 0.4002585709095001, train_loss: 0.001898486283607781\n",
            "49120 val_loss: 0.4108280837535858, train_loss: 0.0016322594601660967\n",
            "49130 val_loss: 0.3982468545436859, train_loss: 0.002089689252898097\n",
            "49140 val_loss: 0.390370637178421, train_loss: 0.003744579153135419\n",
            "49150 val_loss: 0.39522796869277954, train_loss: 0.002291891723871231\n",
            "49160 val_loss: 0.40459683537483215, train_loss: 0.0018715873593464494\n",
            "49170 val_loss: 0.48408108949661255, train_loss: 0.007507616654038429\n",
            "49180 val_loss: 0.4128267765045166, train_loss: 0.002240899484604597\n",
            "49190 val_loss: 0.4071830213069916, train_loss: 0.01078089140355587\n",
            "49200 val_loss: 0.4368959069252014, train_loss: 0.0017706949729472399\n",
            "49210 val_loss: 0.4395226836204529, train_loss: 0.0023426024708896875\n",
            "49220 val_loss: 0.49569275975227356, train_loss: 0.011365342885255814\n",
            "49230 val_loss: 0.41343873739242554, train_loss: 0.0019783892203122377\n",
            "49240 val_loss: 0.4281138479709625, train_loss: 0.002647446235641837\n",
            "49250 val_loss: 0.4117584824562073, train_loss: 0.0017286937218159437\n",
            "49260 val_loss: 0.4126518666744232, train_loss: 0.0017177632544189692\n",
            "49270 val_loss: 0.41729500889778137, train_loss: 0.0016690969932824373\n",
            "49280 val_loss: 0.4134748876094818, train_loss: 0.0021397643722593784\n",
            "49290 val_loss: 0.42414620518684387, train_loss: 0.00170437793713063\n",
            "49300 val_loss: 0.40950992703437805, train_loss: 0.0019963013473898172\n",
            "49310 val_loss: 0.43785232305526733, train_loss: 0.0032105871941894293\n",
            "49320 val_loss: 0.4096194803714752, train_loss: 0.0017623420571908355\n",
            "49330 val_loss: 0.4403262734413147, train_loss: 0.003716744715347886\n",
            "49340 val_loss: 0.40666261315345764, train_loss: 0.0017172154039144516\n",
            "49350 val_loss: 0.409017413854599, train_loss: 0.0017071743495762348\n",
            "49360 val_loss: 0.3946731686592102, train_loss: 0.004019181709736586\n",
            "49370 val_loss: 0.3988930284976959, train_loss: 0.0032392716966569424\n",
            "49380 val_loss: 0.4033679962158203, train_loss: 0.0028558780904859304\n",
            "49390 val_loss: 0.4000523090362549, train_loss: 0.0021906194742769003\n",
            "49400 val_loss: 0.4339649975299835, train_loss: 0.0022048873361200094\n",
            "49410 val_loss: 0.3954097330570221, train_loss: 0.0026170529890805483\n",
            "49420 val_loss: 0.3978050649166107, train_loss: 0.0025681215338408947\n",
            "49430 val_loss: 0.4948572516441345, train_loss: 0.011721083894371986\n",
            "49440 val_loss: 0.45250335335731506, train_loss: 0.005133864004164934\n",
            "49450 val_loss: 0.4078142046928406, train_loss: 0.0017611212097108364\n",
            "49460 val_loss: 0.4235069751739502, train_loss: 0.001999594271183014\n",
            "49470 val_loss: 0.4172261655330658, train_loss: 0.0032361198682338\n",
            "49480 val_loss: 0.412946879863739, train_loss: 0.0017415463225916028\n",
            "49490 val_loss: 0.4106425344944, train_loss: 0.001633804407902062\n",
            "49500 val_loss: 0.39355218410491943, train_loss: 0.004013479221612215\n",
            "49510 val_loss: 0.4512287378311157, train_loss: 0.004861530382186174\n",
            "49520 val_loss: 0.3943628966808319, train_loss: 0.001999479718506336\n",
            "49530 val_loss: 0.3991450369358063, train_loss: 0.0019628601148724556\n",
            "49540 val_loss: 0.43336358666419983, train_loss: 0.0027298361528664827\n",
            "49550 val_loss: 0.4239546060562134, train_loss: 0.0020206153858453035\n",
            "49560 val_loss: 0.40524840354919434, train_loss: 0.001951754093170166\n",
            "49570 val_loss: 0.39931052923202515, train_loss: 0.002225131494924426\n",
            "49580 val_loss: 0.39607661962509155, train_loss: 0.002675892086699605\n",
            "49590 val_loss: 0.39499205350875854, train_loss: 0.0018986643990501761\n",
            "49600 val_loss: 0.39384832978248596, train_loss: 0.0021039333660155535\n",
            "49610 val_loss: 0.40426695346832275, train_loss: 0.002359080361202359\n",
            "49620 val_loss: 0.3973619341850281, train_loss: 0.0019229829777032137\n",
            "49630 val_loss: 0.3914196491241455, train_loss: 0.002409860957413912\n",
            "49640 val_loss: 0.4135092794895172, train_loss: 0.0020387242548167706\n",
            "49650 val_loss: 0.4014948010444641, train_loss: 0.0019004952628165483\n",
            "49660 val_loss: 0.4152364730834961, train_loss: 0.0018650965066626668\n",
            "49670 val_loss: 0.4780030846595764, train_loss: 0.010357992723584175\n",
            "49680 val_loss: 0.42494988441467285, train_loss: 0.0024975049309432507\n",
            "49690 val_loss: 0.4087717533111572, train_loss: 0.002001675311475992\n",
            "49700 val_loss: 0.41108736395835876, train_loss: 0.001849719905294478\n",
            "49710 val_loss: 0.41332322359085083, train_loss: 0.0020237104035913944\n",
            "49720 val_loss: 0.41864094138145447, train_loss: 0.0016462312778458\n",
            "49730 val_loss: 0.42816996574401855, train_loss: 0.0020912059117108583\n",
            "49740 val_loss: 0.42989927530288696, train_loss: 0.0017352132126688957\n",
            "49750 val_loss: 0.48250433802604675, train_loss: 0.009209801442921162\n",
            "49760 val_loss: 0.4193370044231415, train_loss: 0.0018215692834928632\n",
            "49770 val_loss: 0.4265851080417633, train_loss: 0.0016524032689630985\n",
            "49780 val_loss: 0.4163588583469391, train_loss: 0.0018391498597338796\n",
            "49790 val_loss: 0.40809255838394165, train_loss: 0.006715554278343916\n",
            "49800 val_loss: 0.4195574223995209, train_loss: 0.003531990572810173\n",
            "49810 val_loss: 0.41639527678489685, train_loss: 0.0016372207319363952\n",
            "49820 val_loss: 0.4218311309814453, train_loss: 0.0018294909968972206\n",
            "49830 val_loss: 0.4086836278438568, train_loss: 0.001961057074368\n",
            "49840 val_loss: 0.42369264364242554, train_loss: 0.001803171238861978\n",
            "49850 val_loss: 0.4047592580318451, train_loss: 0.00970478542149067\n",
            "49860 val_loss: 0.4685385227203369, train_loss: 0.007203972432762384\n",
            "49870 val_loss: 0.4077330529689789, train_loss: 0.001720433123409748\n",
            "49880 val_loss: 0.40344804525375366, train_loss: 0.0017387861153110862\n",
            "49890 val_loss: 0.43709659576416016, train_loss: 0.0025813004467636347\n",
            "49900 val_loss: 0.43345245718955994, train_loss: 0.0020762451458722353\n",
            "49910 val_loss: 0.40615421533584595, train_loss: 0.0019758855924010277\n",
            "49920 val_loss: 0.4200911819934845, train_loss: 0.0035298301372677088\n",
            "49930 val_loss: 0.4997669756412506, train_loss: 0.0025051566772162914\n",
            "49940 val_loss: 0.495027631521225, train_loss: 0.005873856600373983\n",
            "49950 val_loss: 0.4744022786617279, train_loss: 0.0022172541357576847\n",
            "49960 val_loss: 0.3955630660057068, train_loss: 0.0036489018239080906\n",
            "49970 val_loss: 0.42491573095321655, train_loss: 0.0037319757975637913\n",
            "49980 val_loss: 0.4514474868774414, train_loss: 0.003223348641768098\n",
            "49990 val_loss: 0.3902108371257782, train_loss: 0.006456023547798395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes `t_losses` and `val_losses` are lists of loss values\n",
        "plt.plot(t_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.xlabel('Steps (x10)')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "DAujR3cKUR2D",
        "outputId": "ac53fd7b-1300-4cfb-9a52-0d1f569bd3ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABz2klEQVR4nO3dd1QUVxsG8GdpC0hTkKaAKIgdu2JPxGCNmsQYPxNL1BQ1aoyJmsSeBI0ae9REI2mW2DVWLFixi11sCBaKinSpe78/JqwsHVx2Yff5nbMH5s6dmTvD6r57q0wIIUBERESkIwy0XQAiIiIidWJwQ0RERDqFwQ0RERHpFAY3REREpFMY3BAREZFOYXBDREREOoXBDREREekUBjdERESkUxjcEBERkU5hcEOkBkOGDEGNGjVKdez06dMhk8nUW6By5v79+5DJZAgICND4tWUyGaZPn67cDggIgEwmw/3794s8tkaNGhgyZIhay/Mq7xUiKh4GN6TTZDJZsV5BQUHaLqreGzNmDGQyGe7cuVNgnm+++QYymQyXL1/WYMlK7vHjx5g+fTpCQkK0XRSl7ABz3rx52i4KUZkz0nYBiMrSn3/+qbL9xx9/IDAwME963bp1X+k6v/76KxQKRamO/fbbbzFp0qRXur4uGDhwIJYsWYK1a9di6tSp+eZZt24dGjZsiEaNGpX6Oh988AHee+89yOXyUp+jKI8fP8aMGTNQo0YNNG7cWGXfq7xXiKh4GNyQTnv//fdVtk+dOoXAwMA86bmlpKTA3Ny82NcxNjYuVfkAwMjICEZG/KfYqlUreHh4YN26dfkGN8HBwQgLC8Ps2bNf6TqGhoYwNDR8pXO8ild5rxBR8bBZivRep06d0KBBA5w/fx4dOnSAubk5vv76awDA9u3b0aNHDzg7O0Mul6NWrVqYNWsWsrKyVM6Rux9FziaAX375BbVq1YJcLkeLFi1w9uxZlWPz63Mjk8kwevRobNu2DQ0aNIBcLkf9+vWxd+/ePOUPCgpC8+bNYWpqilq1amHlypXF7sdz7Ngx9OvXD66urpDL5XBxccHnn3+OFy9e5Lk/CwsLPHr0CH369IGFhQWqVq2KCRMm5HkWcXFxGDJkCKytrWFjY4PBgwcjLi6uyLIAUu3NzZs3ceHChTz71q5dC5lMhgEDBiA9PR1Tp05Fs2bNYG1tjUqVKqF9+/Y4fPhwkdfIr8+NEALfffcdqlevDnNzc7z22mu4du1anmNjY2MxYcIENGzYEBYWFrCyskK3bt1w6dIlZZ6goCC0aNECADB06FBl02d2f6P8+twkJyfjiy++gIuLC+RyOby8vDBv3jwIIVTyleR9UVoxMTEYNmwYHBwcYGpqCm9vb/z+++958q1fvx7NmjWDpaUlrKys0LBhQyxatEi5PyMjAzNmzICnpydMTU1ha2uLdu3aITAwUOU8N2/exDvvvIMqVarA1NQUzZs3x44dO1TyFPdcRNn4dZEIwLNnz9CtWze89957eP/99+Hg4ABA+iC0sLDA+PHjYWFhgUOHDmHq1KlISEjA3Llzizzv2rVrkZiYiI8//hgymQw//vgj3nrrLdy7d6/Ib/DHjx/Hli1bMHLkSFhaWmLx4sV4++23ERERAVtbWwDAxYsX0bVrVzg5OWHGjBnIysrCzJkzUbVq1WLd98aNG5GSkoJPP/0Utra2OHPmDJYsWYKHDx9i48aNKnmzsrLg5+eHVq1aYd68eThw4ADmz5+PWrVq4dNPPwUgBQm9e/fG8ePH8cknn6Bu3brYunUrBg8eXKzyDBw4EDNmzMDatWvRtGlTlWv/888/aN++PVxdXfH06VOsWrUKAwYMwIgRI5CYmIjVq1fDz88PZ86cydMUVJSpU6fiu+++Q/fu3dG9e3dcuHABb7zxBtLT01Xy3bt3D9u2bUO/fv3g7u6O6OhorFy5Eh07dsT169fh7OyMunXrYubMmZg6dSo++ugjtG/fHgDQpk2bfK8thMCbb76Jw4cPY9iwYWjcuDH27duHL7/8Eo8ePcKCBQtU8hfnfVFaL168QKdOnXDnzh2MHj0a7u7u2LhxI4YMGYK4uDiMHTsWABAYGIgBAwagc+fOmDNnDgDgxo0bOHHihDLP9OnT4e/vj+HDh6Nly5ZISEjAuXPncOHCBXTp0gUAcO3aNbRt2xbVqlXDpEmTUKlSJfzzzz/o06cPNm/ejL59+xb7XEQqBJEeGTVqlMj9tu/YsaMAIFasWJEnf0pKSp60jz/+WJibm4vU1FRl2uDBg4Wbm5tyOywsTAAQtra2IjY2Vpm+fft2AUDs3LlTmTZt2rQ8ZQIgTExMxJ07d5Rply5dEgDEkiVLlGm9evUS5ubm4tGjR8q027dvCyMjozznzE9+9+fv7y9kMpkIDw9XuT8AYubMmSp5mzRpIpo1a6bc3rZtmwAgfvzxR2VaZmamaN++vQAg1qxZU2SZWrRoIapXry6ysrKUaXv37hUAxMqVK5XnTEtLUznu+fPnwsHBQXz44Ycq6QDEtGnTlNtr1qwRAERYWJgQQoiYmBhhYmIievToIRQKhTLf119/LQCIwYMHK9NSU1NVyiWE9LeWy+Uqz+bs2bMF3m/u90r2M/vuu+9U8r3zzjtCJpOpvAeK+77IT/Z7cu7cuQXmWbhwoQAg/vrrL2Vaenq68PHxERYWFiIhIUEIIcTYsWOFlZWVyMzMLPBc3t7eokePHoWWqXPnzqJhw4Yq/5YUCoVo06aN8PT0LNG5iHJisxQRALlcjqFDh+ZJNzMzU/6emJiIp0+fon379khJScHNmzeLPG///v1RuXJl5Xb2t/h79+4Veayvry9q1aql3G7UqBGsrKyUx2ZlZeHAgQPo06cPnJ2dlfk8PDzQrVu3Is8PqN5fcnIynj59ijZt2kAIgYsXL+bJ/8knn6hst2/fXuVedu/eDSMjI2VNDiD1cfnss8+KVR5A6if18OFDHD16VJm2du1amJiYoF+/fspzmpiYAAAUCgViY2ORmZmJ5s2b59ukVZgDBw4gPT0dn332mUpT3rhx4/LklcvlMDCQ/tvMysrCs2fPYGFhAS8vrxJfN9vu3bthaGiIMWPGqKR/8cUXEEJgz549KulFvS9exe7du+Ho6IgBAwYo04yNjTFmzBgkJSXhyJEjAAAbGxskJycX2ixkY2ODa9eu4fbt2/nuj42NxaFDh/Duu+8q/209ffoUz549g5+fH27fvo1Hjx4V61xEuTG4IQJQrVo15YdlTteuXUPfvn1hbW0NKysrVK1aVdkZOT4+vsjzurq6qmxnBzrPnz8v8bHZx2cfGxMTgxcvXsDDwyNPvvzS8hMREYEhQ4agSpUqyn40HTt2BJD3/kxNTfM0d+UsDwCEh4fDyckJFhYWKvm8vLyKVR4AeO+992BoaIi1a9cCAFJTU7F161Z069ZNJVD8/fff0ahRI2UfjKpVq2LXrl3F+rvkFB4eDgDw9PRUSa9atarK9QApkFqwYAE8PT0hl8thZ2eHqlWr4vLlyyW+bs7rOzs7w9LSUiU9ewRfdvmyFfW+eBXh4eHw9PRUBnAFlWXkyJGoXbs2unXrhurVq+PDDz/M0+9n5syZiIuLQ+3atdGwYUN8+eWXKkP479y5AyEEpkyZgqpVq6q8pk2bBkB6jxfnXES5MbghgmoNRra4uDh07NgRly5dwsyZM7Fz504EBgYq+xgUZzhvQaNyRK6Oouo+tjiysrLQpUsX7Nq1CxMnTsS2bdsQGBio7Pia+/40NcLI3t4eXbp0webNm5GRkYGdO3ciMTERAwcOVOb566+/MGTIENSqVQurV6/G3r17ERgYiNdff71Mh1n/8MMPGD9+PDp06IC//voL+/btQ2BgIOrXr6+x4d1l/b4oDnt7e4SEhGDHjh3K/kLdunVT6VvVoUMH3L17F7/99hsaNGiAVatWoWnTpli1ahWAl++vCRMmIDAwMN9XdpBe1LmIcmOHYqICBAUF4dmzZ9iyZQs6dOigTA8LC9NiqV6yt7eHqalpvpPeFTYRXrYrV67g1q1b+P333zFo0CBl+quMQHFzc8PBgweRlJSkUnsTGhpaovMMHDgQe/fuxZ49e7B27VpYWVmhV69eyv2bNm1CzZo1sWXLFpWmpOxv/CUtMwDcvn0bNWvWVKY/efIkT23Ipk2b8Nprr2H16tUq6XFxcbCzs1Nul2TGaTc3Nxw4cACJiYkqtTfZzZ7Z5dMENzc3XL58GQqFQqX2Jr+ymJiYoFevXujVqxcUCgVGjhyJlStXYsqUKcqgpEqVKhg6dCiGDh2KpKQkdOjQAdOnT8fw4cOVz9rY2Bi+vr5Flq2wcxHlxpobogJkf0PO+Y04PT0dP//8s7aKpMLQ0BC+vr7Ytm0bHj9+rEy/c+dOnn4aBR0PqN6fEEJlOG9Jde/eHZmZmVi+fLkyLSsrC0uWLCnRefr06QNzc3P8/PPP2LNnD9566y2YmpoWWvbTp08jODi4xGX29fWFsbExlixZonK+hQsX5slraGiYp4Zk48aNyr4h2SpVqgQAxRoC3717d2RlZWHp0qUq6QsWLIBMJit2/yl16N69O6KiorBhwwZlWmZmJpYsWQILCwtlk+WzZ89UjjMwMFBOrJiWlpZvHgsLC3h4eCj329vbo1OnTli5ciUiIyPzlOXJkyfK34s6F1FurLkhKkCbNm1QuXJlDB48WLk0wJ9//qnR6v+iTJ8+Hfv370fbtm3x6aefKj8kGzRoUOTU/3Xq1EGtWrUwYcIEPHr0CFZWVti8efMr9d3o1asX2rZti0mTJuH+/fuoV68etmzZUuL+KBYWFujTp4+y303OJikA6NmzJ7Zs2YK+ffuiR48eCAsLw4oVK1CvXj0kJSWV6FrZ8/X4+/ujZ8+e6N69Oy5evIg9e/ao1MZkX3fmzJkYOnQo2rRpgytXruDvv/9WqfEBgFq1asHGxgYrVqyApaUlKlWqhFatWsHd3T3P9Xv16oXXXnsN33zzDe7fvw9vb2/s378f27dvx7hx41Q6D6vDwYMHkZqamie9T58++Oijj7By5UoMGTIE58+fR40aNbBp0yacOHECCxcuVNYsDR8+HLGxsXj99ddRvXp1hIeHY8mSJWjcuLGyf069evXQqVMnNGvWDFWqVMG5c+ewadMmjB49WnnNZcuWoV27dmjYsCFGjBiBmjVrIjo6GsHBwXj48KFy/qDinItIhVbGaBFpSUFDwevXr59v/hMnTojWrVsLMzMz4ezsLL766iuxb98+AUAcPnxYma+goeD5DbtFrqHJBQ0FHzVqVJ5j3dzcVIYmCyHEwYMHRZMmTYSJiYmoVauWWLVqlfjiiy+EqalpAU/hpevXrwtfX19hYWEh7OzsxIgRI5RDi3MOYx48eLCoVKlSnuPzK/uzZ8/EBx98IKysrIS1tbX44IMPxMWLF4s9FDzbrl27BADh5OSUZ/i1QqEQP/zwg3BzcxNyuVw0adJE/Pvvv3n+DkIUPRRcCCGysrLEjBkzhJOTkzAzMxOdOnUSV69ezfO8U1NTxRdffKHM17ZtWxEcHCw6duwoOnbsqHLd7du3i3r16imH5Wffe35lTExMFJ9//rlwdnYWxsbGwtPTU8ydO1dlaHr2vRT3fZFb9nuyoNeff/4phBAiOjpaDB06VNjZ2QkTExPRsGHDPH+3TZs2iTfeeEPY29sLExMT4erqKj7++GMRGRmpzPPdd9+Jli1bChsbG2FmZibq1Kkjvv/+e5Genq5yrrt374pBgwYJR0dHYWxsLKpVqyZ69uwpNm3aVOJzEWWTCVGOvoYSkVr06dOHQ2eJSG+xzw1RBZd7qYTbt29j9+7d6NSpk3YKRESkZay5IargnJycMGTIENSsWRPh4eFYvnw50tLScPHixTxztxAR6QN2KCaq4Lp27Yp169YhKioKcrkcPj4++OGHHxjYEJHeYs0NERER6RT2uSEiIiKdwuCGiIiIdIre9blRKBR4/PgxLC0tSzRFOhEREWmPEAKJiYlwdnbOs7hrbnoX3Dx+/BguLi7aLgYRERGVwoMHD1C9evVC8+hdcJM9ffiDBw9gZWWl5dIQERFRcSQkJMDFxUVlgdmC6F1wk90UZWVlxeCGiIiogilOlxJ2KCYiIiKdwuCGiIiIdAqDGyIiItIpetfnpriysrKQkZGh7WJQBWdsbAxDQ0NtF4OISK8wuMlFCIGoqCjExcVpuyikI2xsbODo6Mh5lYiINITBTS7ZgY29vT3Mzc35gUSlJoRASkoKYmJiAEirdxMRUdljcJNDVlaWMrCxtbXVdnFIB5iZmQEAYmJiYG9vzyYqIiINYIfiHLL72Jibm2u5JKRLst9P7MNFRKQZDG7ywaYoUie+n4iINIvBDREREekUBjdUoBo1amDhwoXFzh8UFASZTFbmI80CAgJgY2NTptcgIqKKi8GNDpDJZIW+pk+fXqrznj17Fh999FGx87dp0waRkZGwtrYu1fWIiIjUgaOldEBkZKTy9w0bNmDq1KkIDQ1VpllYWCh/F0IgKysLRkZF/+mrVq1aonKYmJjA0dGxRMcQEZGGZLwAjEwBPegHyJobHeDo6Kh8WVtbQyaTKbdv3rwJS0tL7NmzB82aNYNcLsfx48dx9+5d9O7dGw4ODrCwsECLFi1w4MABlfPmbpaSyWRYtWoV+vbtC3Nzc3h6emLHjh3K/bmbpbKbj/bt24e6devCwsICXbt2VQnGMjMzMWbMGNjY2MDW1hYTJ07E4MGD0adPnxI9g+XLl6NWrVowMTGBl5cX/vzzT+U+IQSmT58OV1dXyOVyODs7Y8yYMcr9P//8Mzw9PWFqagoHBwe88847Jbo2EVG59+wu8L0jsHmYtkuiEQxuiiCEQEp6plZeQgi13cekSZMwe/Zs3LhxA40aNUJSUhK6d++OgwcP4uLFi+jatSt69eqFiIiIQs8zY8YMvPvuu7h8+TK6d++OgQMHIjY2tsD8KSkpmDdvHv78808cPXoUERERmDBhgnL/nDlz8Pfff2PNmjU4ceIEEhISsG3bthLd29atWzF27Fh88cUXuHr1Kj7++GMMHToUhw8fBgBs3rwZCxYswMqVK3H79m1s27YNDRs2BACcO3cOY8aMwcyZMxEaGoq9e/eiQ4cOJbo+EVG5d3qF9PPqZu2WQ0PYLFWEFxlZqDd1n1aufX2mH8xN1PMnmjlzJrp06aLcrlKlCry9vZXbs2bNwtatW7Fjxw6MHj26wPMMGTIEAwYMAAD88MMPWLx4Mc6cOYOuXbvmmz8jIwMrVqxArVq1AACjR4/GzJkzlfuXLFmCyZMno2/fvgCApUuXYvfu3SW6t3nz5mHIkCEYOXIkAGD8+PE4deoU5s2bh9deew0RERFwdHSEr68vjI2N4erqipYtWwIAIiIiUKlSJfTs2ROWlpZwc3NDkyZNSnR9IiIqX1hzoyeaN2+usp2UlIQJEyagbt26sLGxgYWFBW7cuFFkzU2jRo2Uv1eqVAlWVlbK5QXyY25urgxsAGkJguz88fHxiI6OVgYaAGBoaIhmzZqV6N5u3LiBtm3bqqS1bdsWN27cAAD069cPL168QM2aNTFixAhs3boVmZmZAIAuXbrAzc0NNWvWxAcffIC///4bKSkpJbo+ERGVL6y5KYKZsSGuz/TT2rXVpVKlSirbEyZMQGBgIObNmwcPDw+YmZnhnXfeQXp6eqHnMTY2VtmWyWRQKBQlyq/O5rbicHFxQWhoKA4cOIDAwECMHDkSc+fOxZEjR2BpaYkLFy4gKCgI+/fvx9SpUzF9+nScPXuWw82JiCoo1twUQSaTwdzESCuvspzZ9sSJExgyZAj69u2Lhg0bwtHREffv3y+z6+XH2toaDg4OOHv2rDItKysLFy5cKNF56tatixMnTqiknThxAvXq1VNum5mZoVevXli8eDGCgoIQHByMK1euAACMjIzg6+uLH3/8EZcvX8b9+/dx6NChV7gzIiLSJtbc6ClPT09s2bIFvXr1gkwmw5QpUwqtgSkrn332Gfz9/eHh4YE6depgyZIleP78eYkCuy+//BLvvvsumjRpAl9fX+zcuRNbtmxRjv4KCAhAVlYWWrVqBXNzc/z1118wMzODm5sb/v33X9y7dw8dOnRA5cqVsXv3bigUCnh5eZXVLRMRURljcKOnfvrpJ3z44Ydo06YN7OzsMHHiRCQkJGi8HBMnTkRUVBQGDRoEQ0NDfPTRR/Dz8yvR6tl9+vTBokWLMG/ePIwdOxbu7u5Ys2YNOnXqBACwsbHB7NmzMX78eGRlZaFhw4bYuXMnbG1tYWNjgy1btmD69OlITU2Fp6cn1q1bh/r165fRHRMRUVmTCU13gNCyhIQEWFtbIz4+HlZWVir7UlNTERYWBnd3d5iammqphPpNoVCgbt26ePfddzFr1ixtF0ct+L4iIq3b/RVwZqX0+/R47ZallAr7/M6NNTekVeHh4di/fz86duyItLQ0LF26FGFhYfjf//6n7aIREVEFxQ7FpFUGBgYICAhAixYt0LZtW1y5cgUHDhxA3bp1tV00IiKqoFhzQ1rl4uKSZ6QTERHRq2DNDREREekUBjdEREQ6T6/GDjG4ISIiIt3C4IaIiEjnld2M9+URgxsiIiLSKQxuiIiISKcwuCGlTp06Ydy4ccrtGjVqYOHChYUeI5PJsG3btle+trrOU5jp06ejcePGZXoNIiLSPgY3OqBXr17o2rVrvvuOHTsGmUyGy5cvl/i8Z8+exUcfffSqxVNRUIARGRmJbt26qfVaRESknxjc6IBhw4YhMDAQDx8+zLNvzZo1aN68ORo1alTi81atWhXm5ubqKGKRHB0dIZfLNXItIiLSbQxudEDPnj1RtWpVBAQEqKQnJSVh48aNGDZsGJ49e4YBAwagWrVqMDc3R8OGDbFu3bpCz5u7Wer27dvo0KEDTE1NUa9ePQQGBuY5ZuLEiahduzbMzc1Rs2ZNTJkyBRkZGQCAgIAAzJgxA5cuXYJMJoNMJlOWOXez1JUrV/D666/DzMwMtra2+Oijj5CUlKTcP2TIEPTp0wfz5s2Dk5MTbG1tMWrUKOW1ikOhUGDmzJmoXr065HI5GjdujL179yr3p6enY/To0XBycoKpqSnc3Nzg7+8PABBCYPr06XB1dYVcLoezszPGjBlT7GsTEWmUTL9GS3H5haIIAWSkaOfaxubFekMaGRlh0KBBCAgIwDfffAPZf8ds3LgRWVlZGDBgAJKSktCsWTNMnDgRVlZW2LVrFz744APUqlULLVu2LPIaCoUCb731FhwcHHD69GnEx8er9M/JZmlpiYCAADg7O+PKlSsYMWIELC0t8dVXX6F///64evUq9u7diwMHDgAArK2t85wjOTkZfn5+8PHxwdmzZxETE4Phw4dj9OjRKgHc4cOH4eTkhMOHD+POnTvo378/GjdujBEjRhR5PwCwaNEizJ8/HytXrkSTJk3w22+/4c0338S1a9fg6emJxYsXY8eOHfjnn3/g6uqKBw8e4MGDBwCAzZs3Y8GCBVi/fj3q16+PqKgoXLp0qVjXJSKissXgpigZKcAPztq59tePAZNKxcr64YcfYu7cuThy5Ag6deoEQGqSevvtt2FtbQ1ra2tMmDBBmf+zzz7Dvn378M8//xQruDlw4ABu3ryJffv2wdlZeh4//PBDnn4y3377rfL3GjVqYMKECVi/fj2++uormJmZwcLCAkZGRnB0dCzwWmvXrkVqair++OMPVKok3f/SpUvRq1cvzJkzBw4ODgCAypUrY+nSpTA0NESdOnXQo0cPHDx4sNjBzbx58zBx4kS89957AIA5c+bg8OHDWLhwIZYtW4aIiAh4enqiXbt2kMlkcHNzUx4bEREBR0dH+Pr6wtjYGK6ursV6jkREVPbYLKUj6tSpgzZt2uC3334DANy5cwfHjh3DsGHDAABZWVmYNWsWGjZsiCpVqsDCwgL79u1DREREsc5/48YNuLi4KAMbAPDx8cmTb8OGDWjbti0cHR1hYWGBb7/9ttjXyHktb29vZWADAG3btoVCoUBoaKgyrX79+jA0NFRuOzk5ISYmpljXSEhIwOPHj9G2bVuV9LZt2+LGjRsApKavkJAQeHl5YcyYMdi/f78yX79+/fDixQvUrFkTI0aMwNatW5GZmVmi+yQiorKh1Zqb5cuXY/ny5bh//z4A6cNq6tSphY6a2bhxI6ZMmYL79+/D09MTc+bMQffu3cuukMbmUg2KNhiXrDPvsGHD8Nlnn2HZsmVYs2YNatWqhY4dOwIA5s6di0WLFmHhwoVo2LAhKlWqhHHjxiE9PV1txQ0ODsbAgQMxY8YM+Pn5wdraGuvXr8f8+fPVdo2cjI2NVbZlMhkUCoXazt+0aVOEhYVhz549OHDgAN599134+vpi06ZNcHFxQWhoKA4cOIDAwECMHDlSWXOWu1xERFonuLaUxlSvXh2zZ8/G+fPnce7cObz++uvo3bs3rl27lm/+kydPYsCAARg2bBguXryIPn36oE+fPrh69WrZFVImk5qGtPEqYQewd999FwYGBli7di3++OMPfPjhh8r+NydOnEDv3r3x/vvvw9vbGzVr1sStW7eKfe66deviwYMHiIyMVKadOnVKJc/Jkyfh5uaGb775Bs2bN4enpyfCw8NV8piYmCArK6vIa126dAnJycnKtBMnTsDAwABeXl7FLnNhrKys4OzsjBMnTqiknzhxAvXq1VPJ179/f/z666/YsGEDNm/ejNjYWACAmZkZevXqhcWLFyMoKAjBwcG4cuWKWspHRESlp9XgplevXujevTs8PT1Ru3ZtfP/997CwsMjzoZlt0aJF6Nq1K7788kvUrVsXs2bNQtOmTbF06VINl7x8srCwQP/+/TF58mRERkZiyJAhyn2enp4IDAzEyZMncePGDXz88ceIjo4u9rl9fX1Ru3ZtDB48GJcuXcKxY8fwzTffqOTx9PREREQE1q9fj7t372Lx4sXYunWrSp4aNWogLCwMISEhePr0KdLS0vJca+DAgTA1NcXgwYNx9epVHD58GJ999hk++OADZX8bdfjyyy8xZ84cbNiwAaGhoZg0aRJCQkIwduxYAMBPP/2EdevW4ebNm7h16xY2btwIR0dH2NjYICAgAKtXr8bVq1dx7949/PXXXzAzM1Ppl0NERNpRbvrcZGVlYf369UhOTs63LwcgNXv4+vqqpPn5+SE4OFgTRawQhg0bhufPn8PPz0+lf8y3336Lpk2bws/PD506dYKjoyP69OlT7PMaGBhg69atePHiBVq2bInhw4fj+++/V8nz5ptv4vPPP8fo0aPRuHFjnDx5ElOmTFHJ8/bbb6Nr16547bXXULVq1XyHo5ubm2Pfvn2IjY1FixYt8M4776Bz585qD2LHjBmD8ePH44svvkDDhg2xd+9e7NixA56engCkkV8//vgjmjdvjhYtWuD+/fvYvXs3DAwMYGNjg19//RVt27ZFo0aNcODAAezcuRO2trZqLSMRkVro2VBwmRDabYi7cuUKfHx8kJqaCgsLC6xdu7bAPjQmJib4/fffMWDAAGXazz//jBkzZhRYC5GWlqZSO5CQkAAXFxfEx8fDyspKJW9qairCwsLg7u4OU1NTNdwdEd9XRFQO7JkInF4h/T49XrtlKaWEhARYW1vn+/mdm9Zrbry8vBASEoLTp0/j008/xeDBg3H9+nW1nd/f3185FNra2houLi5qOzcRERGVP1oPbkxMTODh4YFmzZrB398f3t7eWLRoUb55HR0d89TQREdHFzpnyuTJkxEfH698ZU/CRkRERLpJ68FNbgqFIt9OpoA0r8rBgwdV0gIDAwvsowMAcrkcVlZWKi8iIiLSXVqd52by5Mno1q0bXF1dkZiYiLVr1yIoKAj79u0DAAwaNAjVqlVTruczduxYdOzYEfPnz0ePHj2wfv16nDt3Dr/88os2b4OIiIjKEa0GNzExMRg0aBAiIyNhbW2NRo0aYd++fejSpQsAaYp7A4OXlUtt2rTB2rVr8e233+Lrr7+Gp6cntm3bhgYNGqi1XFruY006hu8nIiLN0mpws3r16kL3BwUF5Unr168f+vXrVyblyZ5ZNiUlBWZmZmVyDdI/KSnSwqucuZiItEe/hoJz4cwcDA0NYWNjo1yfyNzcXDnDL1FJCSGQkpKCmJgY2NjYqKyDRUREZYfBTS7ZI6+KuwAjUVFsbGwKHdFHRFT29Kt5nMFNLjKZDE5OTrC3t0dGRoa2i0MVnLGxMWtsiIg0jMFNAQwNDfmhREREVAGVu3luiIiIiF4FgxsiIiKdp1+DYxjcEBERkU5hcENEREQ6hcENERER6RQGN0RERKRTGNwQERGRTmFwQ0RERDqFwQ0REZGu07N1EhncEBER6bhMhULbRdAoBjdEREQ67sbjeG0XQaMY3BAREem4pLRMbRdBoxjcEBERkU5hcENEREQ6hcENERER6RQGN0RERDqPQ8GJiIiIKiwGN0RERLqOk/gRERERVVwMboiIiEinMLghIiIincLghoiIiHQKgxsiIiLSKQxuiIiISKcwuCEiIiKdwuCGiIiIdAqDGyIiItIpDG6IiIhIpzC4ISIiIp3C4IaIiIh0CoMbIiIi0ikMboiIiEinMLghIiIincLghoiIiHQKgxsiIiLSKQxuiIiISKcwuCEiIiKdotXgxt/fHy1atIClpSXs7e3Rp08fhIaGFnpMQEAAZDKZysvU1FRDJSYiIqLyTqvBzZEjRzBq1CicOnUKgYGByMjIwBtvvIHk5ORCj7OyskJkZKTyFR4erqESExERUXlnpM2L7927V2U7ICAA9vb2OH/+PDp06FDgcTKZDI6OjmVdPCIiIqqAylWfm/j4eABAlSpVCs2XlJQENzc3uLi4oHfv3rh27VqBedPS0pCQkKDyIiIiIt1VboIbhUKBcePGoW3btmjQoEGB+by8vPDbb79h+/bt+Ouvv6BQKNCmTRs8fPgw3/z+/v6wtrZWvlxcXMrqFoiIiKgckAkhhLYLAQCffvop9uzZg+PHj6N69erFPi4jIwN169bFgAEDMGvWrDz709LSkJaWptxOSEiAi4sL4uPjYWVlpZayExERlWfBP38Mn5j10sb0eO0WppQSEhJgbW1drM9vrfa5yTZ69Gj8+++/OHr0aIkCGwAwNjZGkyZNcOfOnXz3y+VyyOVydRSTiIiIKgCtNksJITB69Ghs3boVhw4dgru7e4nPkZWVhStXrsDJyakMSkhEREQVjVZrbkaNGoW1a9di+/btsLS0RFRUFADA2toaZmZmAIBBgwahWrVq8Pf3BwDMnDkTrVu3hoeHB+Li4jB37lyEh4dj+PDhWrsPIiIiKj+0GtwsX74cANCpUyeV9DVr1mDIkCEAgIiICBgYvKxgev78OUaMGIGoqChUrlwZzZo1w8mTJ1GvXj1NFZuIiKiCKRfdazVGq8FNcfoyBwUFqWwvWLAACxYsKKMSERERUUVXboaCExERUVmRabsAGsXghoiIiHQKgxsiIiLSKQxuiIiISKcwuCEiIiKdwuCGiIiIdAqDGyIiIp3H0VJERESkS/QrtmFwQ0RERLqFwQ0REZGO06/FFxjcEBERkY5hcENERKTjZMVYy1GXMLghIiLSefrVo5jBDREREekUBjdERES6Tr8qbhjcEBERkW5hcENEREQ6hcENERER6RQGN0RERKRTGNwQERGRTmFwQ0REpOOEng2XYnBDREREOoXBDREREekUBjdEREQ6TqZn64IzuCEiIiKdwuCGiIiIdAqDGyIiItIpDG6IiIh0HIeCExEREVVgDG6IiIhIpzC4ISIizRICOPYTcDtQ2yXRG/rVKAUYabsARESkZ+4eAg7OkH6fHq/dspBOYs0NERFpVsIjbZeAdByDGyIiIh2nX/MTM7ghIiLSA/rV64bBDRERkc7Tr7obBjdERESkUxjcEBER6Tj9apRicENEREQ6hsENERER6RStBjf+/v5o0aIFLC0tYW9vjz59+iA0NLTI4zZu3Ig6derA1NQUDRs2xO7duzVQWiIiooqJC2dq0JEjRzBq1CicOnUKgYGByMjIwBtvvIHk5OQCjzl58iQGDBiAYcOG4eLFi+jTpw/69OmDq1evarDkREREVF5pdfmFvXv3qmwHBATA3t4e58+fR4cOHfI9ZtGiRejatSu+/PJLAMCsWbMQGBiIpUuXYsWKFWVeZiIiIirfylWfm/h4aY2RKlWqFJgnODgYvr6+Kml+fn4IDg7ON39aWhoSEhJUXkRERPpEpl+tUuUnuFEoFBg3bhzatm2LBg0aFJgvKioKDg4OKmkODg6IiorKN7+/vz+sra2VLxcXF7WWm4iIiMqXchPcjBo1ClevXsX69evVet7JkycjPj5e+Xrw4IFaz09ERFTeCf2aoFi7fW6yjR49Gv/++y+OHj2K6tWrF5rX0dER0dHRKmnR0dFwdHTMN79cLodcLldbWYmIiKh802rNjRACo0ePxtatW3Ho0CG4u7sXeYyPjw8OHjyokhYYGAgfH5+yKiYREamTvlUjlAd61ulGqzU3o0aNwtq1a7F9+3ZYWloq+81YW1vDzMwMADBo0CBUq1YN/v7+AICxY8eiY8eOmD9/Pnr06IH169fj3Llz+OWXX7R2H0REROWangWUWq25Wb58OeLj49GpUyc4OTkpXxs2bFDmiYiIQGRkpHK7TZs2WLt2LX755Rd4e3tj06ZN2LZtW6GdkImIqBzRs1qE8kDfHrlWa25EMSLJoKCgPGn9+vVDv379yqBEREREVNGVm9FSREREROrA4IaIiIh0CoMbIiIi0ikMboiIiHQcVwUnIiIqS3o2LLk80LfRUgxuiIiISKcwuCEiIs3St2qEckDfKssY3BAREZFOYXBDREREOoXBDREREekUBjdEREQ6Tt+6OTG4ISIiIp3C4IaIiIh0CoMbIiLSLH0bl0wax+CGiIiIdAqDGyIi0ix9691KGsfghoiISOfpV0DJ4IaIiIh0SqmCmwcPHuDhw4fK7TNnzmDcuHH45Zdf1FYwIiIiUg9968JdquDmf//7Hw4fPgwAiIqKQpcuXXDmzBl88803mDlzploLSERERFQSpQpurl69ipYtWwIA/vnnHzRo0AAnT57E33//jYCAAHWWj4iIiKhEShXcZGRkQC6XAwAOHDiAN998EwBQp04dREZGqq90RESkezjPjcbJ9KxhqlTBTf369bFixQocO3YMgYGB6Nq1KwDg8ePHsLW1VWsBiYiIiEqiVMHNnDlzsHLlSnTq1AkDBgyAt7c3AGDHjh3K5ioiIqJ8cZ4bLdCvZ25UmoM6deqEp0+fIiEhAZUrV1amf/TRRzA3N1db4YiIiIhKqlQ1Ny9evEBaWpoysAkPD8fChQsRGhoKe3t7tRaQiIiIqCRKFdz07t0bf/zxBwAgLi4OrVq1wvz589GnTx8sX75crQUkIiIiKolSBTcXLlxA+/btAQCbNm2Cg4MDwsPD8ccff2Dx4sVqLSARERFRSZQquElJSYGlpSUAYP/+/XjrrbdgYGCA1q1bIzw8XK0FJCIiIiqJUgU3Hh4e2LZtGx48eIB9+/bhjTfeAADExMTAyspKrQUkIiIdw3luNE7o2WipUgU3U6dOxYQJE1CjRg20bNkSPj4+AKRanCZNmqi1gEREREQlUaqh4O+88w7atWuHyMhI5Rw3ANC5c2f07dtXbYUjIiIiKqlSBTcA4OjoCEdHR+Xq4NWrV+cEfkREVDRO4kdlrFTNUgqFAjNnzoS1tTXc3Nzg5uYGGxsbzJo1CwqFQt1lJCIiolegb2tLlarm5ptvvsHq1asxe/ZstG3bFgBw/PhxTJ8+Hampqfj+++/VWkgiIiKi4ipVcPP7779j1apVytXAAaBRo0aoVq0aRo4cyeCGiIiItKZUzVKxsbGoU6dOnvQ6deogNjb2lQtFRERE6sOh4MXg7e2NpUuX5klfunQpGjVq9MqFIiIiHcZ5bqiMlapZ6scff0SPHj1w4MAB5Rw3wcHBePDgAXbv3q3WAhIRERGVRKlqbjp27Ihbt26hb9++iIuLQ1xcHN566y1cu3YNf/75p7rLSERERFRspQpuAMDZ2Rnff/89Nm/ejM2bN+O7777D8+fPsXr16mKf4+jRo+jVqxecnZ0hk8mwbdu2QvMHBQVBJpPleUVFRZX2NoiISNM4zw2VsVIHN+qQnJwMb29vLFu2rETHhYaGIjIyUvmyt7cvoxISERFVfPoWTpZ6hmJ16NatG7p161bi4+zt7WFjY6P+AhEREekgfevCrdWam9Jq3LgxnJyc0KVLF5w4caLQvGlpaUhISFB5ERER6RU9awosUc3NW2+9Vej+uLi4VylLkZycnLBixQo0b94caWlpWLVqFTp16oTTp0+jadOm+R7j7++PGTNmlGm5iIiIqPwoUXBjbW1d5P5Bgwa9UoEK4+XlBS8vL+V2mzZtcPfuXSxYsKDAUVqTJ0/G+PHjldsJCQlwcXEpszISEVEROM8NlbESBTdr1qwpq3KUWsuWLXH8+PEC98vlcsjlcg2WiIiIqJzRs4CyQva5ySkkJAROTk7aLgYREVG5pV89brQ8WiopKQl37txRboeFhSEkJARVqlSBq6srJk+ejEePHuGPP/4AACxcuBDu7u6oX78+UlNTsWrVKhw6dAj79+/X1i0QEVFJ6VnnVtI8rQY3586dw2uvvabczu4bM3jwYAQEBCAyMhIRERHK/enp6fjiiy/w6NEjmJubo1GjRjhw4IDKOYiIiEiV0LOAUqvBTadOnSAKaQcMCAhQ2f7qq6/w1VdflXGpiIiIqCKr8H1uiIiIiHJicENEREQ6hcENERGRjtOvHjcMboiISNP0bM6V8kDfnjiDGyIiItIpDG6IiIh0nn41TDG4ISIizdKzOVdI8xjcEBER6Tz96nXD4IaIiEjH6VtdGYMbIiIi0ikMboiIiEinMLghIiLN4jw3VMYY3BAREek4oWe9bhjcEBERkU5hcENERJrFeW6ojDG4ISIijVKwzw2VMQY3RESkUdceJ2i7CKTjGNwQEZFGvUjP0nYRSMcxuCEiItJ1etbPicENERFplEzP1jkqF/SsnxODGyIiItIpDG6IiIh0nH41SjG4ISIiIh3D4IaIiDRM3+oRSNMY3BAREZFOYXBDRESaxYobjRMcCk5ERERUcTG4ISIiDdOvOVdI8xjcEBERkU5hcENEREQ6hcENERER6RQGN0REpGH6NXKHNI/BDREREekUBjdEREQ6Tt/qyhjcEBGR7hICuHsYSHqi7ZKQBjG4ISIijZJpcp6b69uAP/sAi5to7pqkdQxuiIhIwzTYSHJrn/QzPVFz1yStY3BDREREOoXBDREREekUBjdEREQ6Tt9W89JqcHP06FH06tULzs7OkMlk2LZtW5HHBAUFoWnTppDL5fDw8EBAQECZl5OIiNRIpsmByfo2CJoALQc3ycnJ8Pb2xrJly4qVPywsDD169MBrr72GkJAQjBs3DsOHD8e+ffvKuKRERERUURhp8+LdunVDt27dip1/xYoVcHd3x/z58wEAdevWxfHjx7FgwQL4+fmVVTGJiEiNWJdCZa1C9bkJDg6Gr6+vSpqfnx+Cg4O1VCIiIiIqb7Rac1NSUVFRcHBwUElzcHBAQkICXrx4ATMzszzHpKWlIS0tTbmdkJBQ5uUkIqJCCA12b9Vo/x4qLypUzU1p+Pv7w9raWvlycXHRdpGIiIg0SqZnjYEVKrhxdHREdHS0Slp0dDSsrKzyrbUBgMmTJyM+Pl75evDggSaKSkRERFpSoZqlfHx8sHv3bpW0wMBA+Pj4FHiMXC6HXC4v66IREVG5pF81FiTRas1NUlISQkJCEBISAkAa6h0SEoKIiAgAUq3LoEGDlPk/+eQT3Lt3D1999RVu3ryJn3/+Gf/88w8+//xzbRSfiIhKg/1gqIxpNbg5d+4cmjRpgiZNpNVax48fjyZNmmDq1KkAgMjISGWgAwDu7u7YtWsXAgMD4e3tjfnz52PVqlUcBk5ERERKWm2W6tSpE0Qhvebzm324U6dOuHjxYhmWioiIiCqyCtWhmIiIiKgoDG6IiEijZHq3jGN5oF/9nBjcEBGRZnHdTCpjDG6IiIhIpzC4ISIiIp3C4IaIiEjn6Vc/JwY3RESkYex0o3F69hgY3BAREZFOYXBDRKTP4h8Bi5sCwT9r7JL6tkJ1+aBfz5zBDRGRPjs4A4i9C+ybrMGLarD/B9ex0ksMboiI9FlWurZLQKR2DG6IiPRZIev7kQ7Rsz8zgxsiIiLSKQxuiIj0Gfuk6Ac9+zMzuCEiIg3Ts0/ackG/njmDGyIi0mH69aFOEgY3REREpFMY3BARkYbp2dAd0jgGN0RERDpPvwJKBjdERPpM1+e54WgwAPrX84jBDREREekUBjdEROVRxgvgzK/A8/tlex3WbOgFoWd1N0baLgAREeUjyB84sQgwMgW+jS676+h6s5SefaiThMGNmqSmJOH5P6Nh4t4G1jWbwsi6GmBmI/3HxG9GRFRSYUeln5mp2i1HmeD/iVS2GNyoSdT1E6hxfytwfytw+GW6AjKkQY50mQmyZEbIlBkhS2YMhcwYWQZGUMiMIQyMoTCQfgpDYygMTSGTW8DQzBrG5taQW1SGWWVnmNs6w8jaGbCwB+SW2rtZItId/PJFOojBjZokyu3xt7w/ar24AldZFBzwHIYyAQMImCEVZiJVrSPxUoxskGTjBUPHBrBybwpjj06AdXX1XYCI9IMWmqVkMl1vCiNtY3CjJg0bNkHDhr8gSyEQ/yIDj1+kITUlEakpichKS0ZGehqyMtKQmZ6OrMxUZGWkQ5GZ9t9P6SUy0yAy04HMFxCpiRBpSZClJ8I0Ix7WiueoijjYy+JgIUuFeWYczJ+eBp6eBq6uBgDEV6oBA8/OsGzxPuDchN/IiIhILzG4UTNDAxmqVDJBlUomANTXdJSZpUBsSjpuPEvBnYdReB5xDSLqGiwTbqGBIhTesruwTr4PhKwGQlYjwcoT5i0Hwajxe1IzFhERkZ5gcFNBGBkawN7SFPaWpmhRowqAegD6QQiBW9FJCLhyF7HXDsDr2UH4GZyFVcJt4MAUKA5MR6q7L8zbjwTcO7I2h6ii0PlRTBrC//P0EoObCk4mk8HL0RJejo2BLo3xKG4UVp28hoRz/6Br5kE0MbgD87B9QNg+JNjURaWOY2DY8B3AyETbRSci0j/HFwL3DgMDNgDGptoujc7iJH46ppqNGUZ1b44J38xG9Lu7MNFxFQIy30CKkMMq7gYMt3+KlDm1kbTjKyDmpraLS0QF0eEahwp/Z69Sq3ZgGnAvCLi0Tm3FobxYc6OjjA0N0LWBI7o26IfwZ93xy4mrMLq4Bv0Ue+CQ8Ry4sBK4sBJRVo0g6r4Jh6Y9YWBfR6f/QyWi8qFCz5Z78S8gcBowcCNQrWnpz5PxQn1lKo4K/MhLg8GNHnCzrYRxb7ZCevcW2H/lIa4f2wLvJzvR2eACHBMuA6cvA6e/Q6yxI55XbQm5Rwc41G0DY3svwJBvESKqyErwqZ6ZDkSGAM5NC/6/b/so6efmYcCYiyUrikqNTzntU5USC5haAwaG2i7JK+Enlx4xMTJAzyau6NlkHB7EfoRtl68h4/JWVH92HC1xHVUyolDl8Q7g8Q7gKJAOY8SY1URqlXqQu3jDwaMpTJwaAJVstX0rRETqt2M0cHkD0GYM8MaswvMKRcnOLQQQ0EN1u7x5Egosawm4tQWG7tZ2aV4Jgxs95VLFHC6dWgCdWiAtMwsX7z7G45ADMH4YjOqJIfAU4bCQpaL6i1DgUSjwaCtwSjo20dAGcTb1AZdWsPVoDnPXpoClI5u0iKhYZOW11uLyBunnycVFBzcllRILhJ9Q7zlLpBj/P4f8Lf3UajnVg8ENQW5kiNZeLoDXUABDoVAI3H+aiJO3riI5PAQGMVdhkxCKGlkRcDOIgWVWHCyfnQCenQBCpHMkGtogzqoO4NwEdnXbw8y9FVDJTpu3RURUjr90aTjAK481RWWIwQ3lYWAgQ017K9S0bwO0awMAEEIgJjENQfcfI/LuFcgenkLl51fhnnkXtWSPpYDn+Sng+Sng2nIAQKypK7Jqvg47766Q1WgPyC20eVtERNpTboOsQggB7PgMsHEFOn6l7dKUCIMbKhaZTAYHK1M4NKoJNKoJoDcA4FlSGoIjYhB15zwyHobA4tll1Mu4jloGkaiSGgFcDwCuByBTZoRkpzawav0BZHV6AibmWr0fIiKt0nRNSrGCq1x5Hl8ELv4p/c7ghvSJrYUc7eq5APVcAPQBADyKe4EdofcRGbIf1o+PoY0IgavBE1g/PgpsOYoMIwsYtBwOwzajAYuqWi0/EZFG5AkuKkAzUWaqtktQagxuSO2q2ZihWqu6QKu6SM0YjRO3n2DdhbOwuLUVb+IoXDKfACcXIvPUCiiaDoZJ+7GAdTVtF5uofNHlPhIVsYnmleW654r2901+VqFGynKGYipTpsaG6FzPERPf74UBE1dga4ddGG8wESGKmjBSpMLk3EpkLWwExY6xQGyYtotLRFRMehagza0JxN7TdimKrVwEN8uWLUONGjVgamqKVq1a4cyZMwXmDQgIgEwmU3mZmnJ9joqgSiUTjPH1wg+TJ+Jmj2340mwGTivqwFBkwuBCAMSSZsCWj4Ent7RdVCLSGWUVhJS05iV3fs3W3JRqVujctUs3d6mnMBqg9eBmw4YNGD9+PKZNm4YLFy7A29sbfn5+iImJKfAYKysrREZGKl/h4eEaLDG9KlNjQ7zXyg0/TBiD637rMQgzEZTlDZnIAi6vh/i5FbBtFBD3QNtFJaIyIKtgLTJqkTtQKOtmKSEARZZys1RzC909pMYCaZbWg5uffvoJI0aMwNChQ1GvXj2sWLEC5ubm+O233wo8RiaTwdHRUflycHDQYIlJXYwNDTC0rTsWTPgEh5v/jD4Z32F/VjPIhAII+QtiSVNg91fAcwavRGVHtyON1MysojNVBCUNhrZ+DPxUF0iNLzhPxClgUWPgdmD++4/NK9k1ASmgSkss+XFqptXgJj09HefPn4evr68yzcDAAL6+vggODi7wuKSkJLi5ucHFxQW9e/fGtWvXCsyblpaGhIQElReVL7YWcszo3QALP/8Q2+vMQ9+0GTiZVQ+yrHTgzEqIRd7An28BoXuArAxtF5eIKpDLDwv5cC+JxGjgxs4cCSVs5skTnJQgWLmyCfjRHbh/vPjHXN4AJEUDp1cCN/6VasZz+70X8DwM+Pud4p8XkNbg2jkWCFkLBE4FHp1/uW/jYMC/utb7UGo1uHn69CmysrLy1Lw4ODggKioq32O8vLzw22+/Yfv27fjrr7+gUCjQpk0bPHz4MN/8/v7+sLa2Vr5cXFzUfh+kHjXsKmHZwKaYNOIDfGf3I/6X/jWOZjWUqlPvHgTWvQf8VA/Y/y375RCpjW53jE3LLOYaUOkphe//uTWw4f3SFUIIYPcXedMKcv+4VGudXabNw4AXz4G1/V/mCT9ZvGajw98DGwaiUfTWvPuy0os+Pj+BU4HzAcC2T4ETi4BfX5cCntsHXgaAZ1eV7txqUuGGgvv4+MDHx0e53aZNG9StWxcrV67ErFl51wKZPHkyxo8fr9xOSEhggFPOtappi52ftcOGs24Yt78pLFIe4APDQPQ3OQmr5Bjg5BLpVaM90GI4UKcnVy8nKjXtNksJISB71aHh0deAM78CHScCVk4qu2TFDd6Clxa+/0VsroQSPLfIEOBa7uCikOOzF9g0tQJe//Zleva8MwoFsKab9PuX94o1RNs84/nLjbgHRS/8+fR23jShAA7OBE4vz7vvu1xzlml5jhytfiLY2dnB0NAQ0dHRKunR0dFwdHQs1jmMjY3RpEkT3LlzJ9/9crkccrn8lctKmmVoIMP/WrmiRyMnLDpwG3OCHTEn5T28YXwZk+xOwPV5MHD/mPSyqg60HA54D5AW8CTSBbo8F4y6b225tEwMnt0BhvxbunMkPFJfeXIrqlYop6QnL3/PPfRakSn9zBmYpDwt+fwzCxsUnWdp87xpV7dIgVpxaDm40WqzlImJCZo1a4aDBw8q0xQKBQ4ePKhSO1OYrKwsXLlyBU5OTkVnpgrH2swYU3vVw95x7dHKwwG7M5qiQ+RnGFn1dyS2+hwwtwMSHgIHpktNVttHAVFXtF1solensUnetBFEldE18/m3L4odJJa0TCXIL8vno7agP++yljny5JNpcRMgLscgizXdpaagmBvSyuNlqbiBDaDtCkHtj5YaP348fv31V/z++++4ceMGPv30UyQnJ2Po0KEAgEGDBmHy5MnK/DNnzsT+/ftx7949XLhwAe+//z7Cw8MxfPhwbd0CaYCHvSX+GtYK8/p5w0JuhN0PjNH+bBsc7HYYeHMpUL0lILKAi38BK9oBq/2ASxsKHylARND2p5B6Y7gcJ9s1QfqyU1wFBUFJMSUfyJDwWOqDUui5C7jxPM1fucTeAwJ6vtxOeSr1Bfq5NTDXQ+qbE3OjZOUF1B9Mh/yl3vOVkNY7KvTv3x9PnjzB1KlTERUVhcaNG2Pv3r3KTsYREREwMHgZgz1//hwjRoxAVFQUKleujGbNmuHkyZOoV6+etm6BNEQmk+GdZtXRokZlfLbuIi4/jMewv69gRPtmmDh0IIwengaO/wTc3g88OCW9DOVAne5A08FAzU66XdVPVGGUUUCVfdqMF8DZXwEANpbti3dsfrUrT0KlmhQb18KPjbwM7PkK8J0OmFgAK9oC9vWAkcEFnzu3mJvA0bnFK2vi4/zTRRYwp0bxzpHbhvcBW4/SHVsOaT24AYDRo0dj9OjR+e4LCgpS2V6wYAEWLFiggVJReeVmWwmbPmmDuftu4tdjYfj1WBhuxyRh2f9aoNLAjUD8Q+DCn8C1LcDTW1JHvmtbAbvaQPMPpb45Zjbavg0iUrv/opsctRCmiuRiHpvPF5/AadLPuIjCD/3rbSA5BvjND2g7TkqLuV74uXPXlAR0B1Ke5c13a3/h11aXm6Xsq1ROab1Ziqg0TIwM8E2Pelj2v6YwNTZAUOgTvLn0OB7EpgDW1YHXJgOjzgAfHwVajACMK0mBzt5JwPw60gzIdw+rzOBJVOHcOSCNEqpgjDJfBhzqbZXKPtvLs3omXyjesbk7wD6/D9zaU8i1FMCp5VLzV3KOGfVPLCzm9V4AQbOB6dbSPDb5BTYQwNp+xTsfqSgXNTdEpdWjkROcbUzxyV/ncfdJMvr+fAKrBrdAYxcbqQnKyRvo4Q10nipNanXuN+kbVchf0svcFqjdFfDqBtR6HTCppO1bIiq+v96Wfjo1BlxaaLUoBcrKkOZjqVpH+jA3MUe9y2U0B0r2KKKihjnnlhQDXPxTNW2Rd+HHxIVLX5aKcnQecCjvNCU4nqMFYvOw/I/NM3yciovBDVV4TVwrY8fodhi65iyuRybg7eUn8U33uhjatsbL+TNMrYCWI6R5cR6cBi6tA65tk74thfwtvQzlQI22gKsPUK+31IzFPjpUESQ8BFBOg5sTC4FD35Xd+W8fyLHxX41NUTWyEaeASlUB21rSnC/FGRpdGunJ+Qc2VObYLEU6wcHKFP984gO/+g7IUgjM/Pc6Pt8QgqdJaaoZZTLAtTXQaxHw5R1g8E6g9UjAxg3ISpO+YR7+XupEuLAhsOUjaZhlKpftoPKsjIJwIaTmmdKMpMlMlybXKyqwUVnSIIfkZ8B0G+B7J+BFXMF5/n5btbx3D0vLChTk6R2pb8ySptJ2adZPKq4fqpXdualQDG5IZ1jIjbDi/WaY1K0OZDJgW8hjvDYvCL+fvI/MrHyqqQ2NAfcOQFd/YOwl4NNgwHeG1DxlKAfiH0hNWRvel9Z1WdNDqlYPDwYy0/Kej0jXnF0lNc/s+argPKkJwJaP8y4FsGHgy8n1CmG48QPplyubgF1fvKx12TkGgAAyUoBTP788IPmp1FyTmQ5syT0FiAD+7ANEXc7/Ymt6AOEnXm5Pt5aWESgzOrwoqakN4JNrIFD/v4Bu/434snHTeJFyYrMU6RSZTIZPOtZCS/cqmLr9Kq4+SsC0Hdew6vg9+PdthHaedgUdCDjUk17txkkzikaclFbLvR0IxN4Fwo9LryB/wNAEcGgAVGsGVGsKVGsuVXEbGGr0fonKVOBU6eeZX4DuBQxT3v8tcHm99JqeY16p2yUc5ZPd78TVB6j/luroncxUIDFK6iO3uos010vHSXkDqqJmxQ0//l8THr2SKU+l2ZKNzQC/76U0IaT/R9MSpWk3jM20WkQGN6STmrpWxvZR7bD2TATm7QvFg9gXeH/1abTzsMPnXTzRzK1K4ScwMQc8fKVXtznAs7vAvcNA2FEg7Jg00dbjC9Lr7H/HGFcCMpKBBu8Abj5AlVpSwGNVjUEPla2y6huWu2Puk1CpicjCXloRutUnwK19OfLn+IArCUWO68Q/BJ7cVN1/YpH0qt7i5ZIER2aX7BrZnt8v3XEV2fR4qZaquFx9gA/3/ndsjuN6LwPq9JBqvQ2NVY/Jfg/KLYGqlq9WXjVgcEM6y9BAhg9au6FPY2fM3ReKv09H4Pidpzh+5yle86qKEe1rwqeWbfEW7bP9L1BpMfxlP4RH54HHF4EHZ4Doq1JgAwBXN0kvZUHkQOUa0vFVagKpcUBiNGDjIk2a5T0AMKv88j8HIYA/egNhR6RA6e1V7NhMhXsSKgXd7sWcsC5b2FHg+vaC9+cObnIuDQBI73uDHB8jikxpwcXlxVs+R8k/R9+UA9OkV34ens0/XV98uF8KHnI/33f/AP4ZlDd/u/HK98RFp3fRJPKfgs9dvSWQFC1NPJhz1Oj4m9I0GlbVALuKM8mfTAiNLWBSLiQkJMDa2hrx8fGwsrLSdnFIg25HJ2Lwb2fwOP5l1XUdR0sMaVMDb9R3RJVKJqU/uSJLGmJ+6DvAylmafv3ZXSkIUpRw6vbCjL8pLQ6qyATSk6TZUHN/gyLdsLLjy7V8us+TpiywcXm5Xwhgho3qMSNPA/Z1inf+jFTgewfVtOm5liuZaftyscYpz4BZRSzQ+HUksHcicOGP4pWB8jdou/QFBwAcGwG1/aSBEB6+UlpGKhB5SWrK6zITaPCWNOfOoe+AN74D/h0HODcBPgpSnvLXf49ixLlCOlpPfS4Fs4blt86jJJ/fDG5I74Q9TcZvx8Ow6fxDvMiQOi8ayIBW7rbo6e2ErvUdYWuhppXkFVlSx+Rnd6Xq9Nh7qp0j1cHQBOgyC2j9ifSBF/8AMKsCyC3Uex3SrJzBDSB14Jz034KJaYlSX5fcnWHd2gFDd73cViiAHaOlOWbq9JC+9cutAGPT/JspsoObpBhg20jgTuDLfYYmQFZ63mNy+ipMGvp87rdi3iRhyC6pP1F2n6NxV6UgNvvv0/Bd4O1iTtSY3SyY9ESahT3HF59f/z2GEed6qubv8ZM0SKJuT6Bn+Z/5n8FNIRjcULb4lAysOxuBbRcf4WbUyz4CMhnQxMUG3Rs64U1vZ9hbmZZdIZ7eAWKuAfu+lZqr0tQ45Pzt1VKzWeuRgDWHpKpdSqzUP8SpUenPkf3fb+huwL6u1GwJSPOw/OaXN3928PH3u8DtfXn3A1Ig02wI0OR9YMcYaRmSnCydgUHb8jYx5Tz/5uHAlY0lvRvdZesBPLtT/PxmVaR+ec0/fBk0CAHs/lL60tHpa2nUlmvrlx1vD84CzKsAPv8t9pkd3DTqD7z1yyvfwqpdxzD87H/BjZEpMPG+dG2FAjCoGAOnGdwUgsEN5SfiWQp2X43EzkuPce3xywDDQAa09bDDG/Ud8UY9BziUZaBTkMhL0nD0ota3KcpHRwDnxmopEgH4zlGaQn/EIWnUXEk9DwfWdJMCmvvHpLTs4KKgzp8tP5IWYTy9onRlztbhK+Doj3nTp8dLtYzZc8CQZFqc9K3n/glpDahs7h2Bql7S7x2+BK5ulpqRqrgDN3dJ/elKW4Oa/R547Vug45evVHwgV3Bj6QR8cbPwA8ohBjeFYHBDRXkc9wI7Lz3G7iuRuPTwZR8EmQxo7GKD9h52aONhh8YuNjA11vAoKCGkeT6ubpJmWY68VPJzjAmR/vOl4ol/KPVnaDlC6hieLfvD5/VvpQ+24rjwh9Q02XmaNEHklVwdPIsKbsraa98Ch8twNuHyyrGRtIp397lSJ+lD3wHdfpSGltt5AqY5/h4KBfDsdtnPYB4eLNXovfaN1Iz4ilSCG/v6wMiTr3xOTWNwUwgGN1QS4c+S8e/lSBy4EY2LEXEq++RGBmjpXgXtPe3QzqMq6jhawsBAS6OaFAogdJc0XPbZXalKvDC5O47qu8x0wChHh/L7J6SmmR7zpHmNoq5I6cbmgPd7UlNDzm/WHSZI0wLYekpLfeSUlgjE3ASqN3/ZAbjjRCD4ZyA915BpbQc3umbsZfy07xrG3xxQcJ7sWhkdpxLcABXy/4CSfH6X327RROWAm20ljHrNA6Ne80Bk/AscuhmD0/dicereM8QkpuHY7ac4dvspgJuwszBBWw87tPOwQ3vPqnC01mATloEBULeX9BJC6h+QmSYtzpdzWHq2f8cDPX/SXPnKghDAySXSJIo12pX+PJc3SjPdvr1aCl6u/PNywcL1/1PNm5EidZZt89nLtPiIl0GLrQfQYz6weQTw5hLAqyvwa2fgaSjwTo5Otkfm5F+WyEvS5JCUl41r8Zpmvf8HXFor/V7ZDTLZtYLzvvObXgQ2eZhV1nYJyhxrbohKQQiBOzFJOHZbmjfn1L1nSElXXazP094C7Tzt0N7TDj417WBmosWJ/OIigICe0krGOTk2AvquABzqa6dcr+LGv9IU/0DxvoXGPfhvQsUcnSdTYqWlNUqqbq+C10TKafR5YOl//XFqdwVu7S35tUiSPefT01t5O0O7dwS6zpZGCrq0BObUkNKnx+OnDXsw/sZ70rbvdGk28R2jge7zAU9fTd6BVv2y+yQ+OtNN2njjO9UAvYJgzQ1RGZPJZPB0sISngyU+bOeO9EwFLkQ8x/HbT3HszlNcfhiH2zFJuB2ThDUn7sPU2ADN3CrDt64D2nrYwaOqhWabsGxcgXGX8zZ3RF2W1v/5OhK4cwDw6Kw6gVd59jys+HmvbQU2DpGm9X/ju5ejx0oT2ADFC2yAl4ENANw5WLpr6YJG7wGN3pXeh0ubF52/6WBpcVuhkP52536TpvmXyaQOvF/eBebWepl/8A7pp0M96eeE29LQdQCynIuKOjWWJrUbW4q+ahVcpoH5yw2XVtoriIYwuCFSAxMjA7SuaYvWNW0xwc8LcSnpOHn3GY7dfoqjt57gUdwLnLjzDCfuPFMe814LF7zX0hWNXWw0V9Dp8cCqLsDDM6rpPzip5imvhJBGCjnUl+YGyc/Dc8Cqzi+3hx2QAhtAGhZ9bQtgbifVAmiSOidzLE8sHKX12MJPSjWD+XVy7zFPmmMHAF6fgsRz62GZcPvl/qmxUufd5+HSkPjspiKZIdDwHemVUyU74L11wPoC+tJY2Ct/VWmayN0fSo9kGJrhvsIBVWQJsHJ8hekLKggGN0RlwMbcBN0bOqF7QycIIXArOgnH7zzFvqtROHNf6uy7/uwDrD/7ALWqVkLrmrbwqWWLdh52sDF/hZmSi2N4oLQg4olF+e+POA0kRkozIbu2LtuylMTdw9KKz/k5t0YKanotAlblampYnU/TQ8rTgs9FqrrPA3ZPyH/fwE2AZxfp99afSj+v7wD++W+l7//9I82um1OHCThv3gWd/u0AAMjoPAPGBoZSjWF2zUtxeHWTOnY7eReaLdUoR0BjqKbJOSsimQG6ps+GDAI31DD6qrxjnxsiDUtKy8SGsw9wNiwWgTeikaV4+U/Q0ECG9p52aFTNGj29nVHboQwXoMtMB7aPLHyytrd+lZoT1CHqKhA4Baj5mrQIafd50npbBcnKVJ0KvjgjiKxdpH4X9Orq95VWd248EJhl9zL9vXXS37HvL0D1UszvAyDo3CVlcJM2JBDyGvlMKKgmU7dfhc2ZBXCRxaDfrB362YEYwMIDt7DwgFRbdn92Dy2XpnTY54aoHLOQG2FYO3cMa+eOuJR0nAmLxal7sThyKwZ3nyQjKPQJgkKfYPEhaUbU91u7Ynqv+jAyVPMsokYmUtNM1znA3Jr559kyArh/HKhUFch4AVSyBQ7OBIbuAdzaABf/lvpE9FvzstmhIH+8CaQ8A+4ekraXNAU6TQYa9pMWcPR+T1qE9I83pYnqshdtbDu24Fqm3BjYSGtAPb8vzZESOKXgfM2GAL0WYd1KfwyIzGeF7fpvAfXelH4ftB3Y9w3Qa7EU0NTpnjd/KQlZ2Xa0lwFYnPUWAKCfngY2+ojBDZEW2ZibSLMf13cEUA/XHydg0/mH+O3Ey86yf52KwF+nItCjkbQcRE27SvBUZ41OJVupn03cA2BhPsOQL/yeN21NN2lZh+x1svyrA59dkGpint4GNg2Vpo1v89nLJQZSnuU9T5C/9AKkxf6y5VyNuriBjb4ZfwP4qe7L7f5/SaO4AGn1Zrsx+Qc3kx9KTY//rRadbJTrG7CFA1CvD1Anx5woNTsBn55QW9HTzBwQKarABkmAY+HNSkSlweCGqByp52yFqc71MLGbFz764zyO3Hqi3LfrciR2XY4EAFibGcPD3gLdGzrhfy1d1TPM3MZFWhk4cAoQvLTo/LkXAF3SFKjVGbj736igqCvSrK9B/sDDs69evorMUA5kpeVNb/AO0HYMsLKD1DF3/A2p4/GhWZh+wxlh0XG4qXDBadPRUn4jU2m5B0MTafX5bO4dXwY2RZFbqgyBNlbkKNfAzUDNjhpZad4nTXqPXWdlikaojBrTAwxuiMohuZEhfv9Q6oeQmpGFrRcf4Xz4c+y89BhpmQrEv8jA+fDnOB/+HLP+vY6WNaooZ0tu6V4FgDRcvcQMDKQht37fSzPrLvLOv8alIHdzDXf+662Sl6EisKoGfBQkNddd3SyttK3IlIbTn1stNek4N5HWgsruvHl9O/DPIOl3+/rA+5ukNX5kMtURagZy4I3vcO3eSZxVPM977fzmJHqFNcNMRI7gRkPzvmjyY7ZU/w6owmNwQ1TOmRobYkBLVwxo6Yp5/bwR8SwF685GYHnQXWWeM/djceZ+LJYefrly8ZSe9fB+a1fIjUpZqyO3BL66JzUrKTJVO5VWdJ5vALf3v9z28JUCk5w6fCX1LbH1lEbyKDLzr9HIOUy5TveCZ36u11s654XfgbdWqta8FFdB/VMKWriz98/Anol5l3nIwUC/xpSQnmBwQ1TBuNqaY2LXOpjYtQ6EEDh59xlO3n2KPVeicO9psjLfrH+vY+6+mzAzNsSYzp4Y2raUE9bJZNKH+vR4aQ2rw98Dx+ap6W7K0PubgWvbpI7QPRdI9yGENNeJEFJn6dv7pdXSsxcSVSikfEnR0lD4nNTRVPP6N9KrGFSaEd75Ddj9JfDuH6qZPj0JPA4B6r6Z/0maDJRWpg4//t+SGwvyZAmx6QyXhztxSNEE3xbzNtSJsRWVBQY3RBWYTCZDWw87tPWww5d+dZCUlol1pyOw+cJDRCek4nlKBlIzFJix8zoO3ojByg+aoZL8Ff7ZGxgAnadIo5wAaQ2rn1sj11RpgJ2XtJ5Sadh6AtVbvFwfqFozaSK+zFQgNU7qmxJ5UVo64sVzaUkDG1fA1QfY97W0mvKIg4CxmVQjkx+ZLP9J/LKXZsgd2GhDztaUBm9LTV25m1gc6he9dIaBAeDeAfjsXL67Mw1M8b8MKazRRnBDVBYY3BDpEAu5EUZ0qIkRHWpCoRA4evsJRv59ASnpWTh+5ynqT9uHtcNboY3HKzYxZc8/Y18HmB5XdH5FljSKqqqXNEFgWpIUQBQ2Y2zf5arbJubSC3jZDGNhDzQd9DJPj/nFvoXyLk9PkTLqO6LrXVJKen9CCPbT0QFqnjiDiMoLAwMZOnnZ4/rMrvh10Mv1fP636jTuPknScGEMpUBIJpP6mlStrddT4ReHpj5ftT2Kpjy1Su26HAnvGftx7PaTojNXMPoWrzG4IdIDXeo5YP1HL5dS6Dz/CCZtvqzFElFRtB10lCVN1oyU5DmOWnsBCamZ+GD1maIzU7nG4IZIT7SuaYvAzzsot9effYCfAm8hJT1Ti6UibdP1b/S6fn/FpW8dtxncEOkRTwdLXJr6hnJ78cHbqDd1H2pM2oXey07gfo7RVqRdGmuW0vKHv54tb0gawuCGSM9YmxsjzL87OtexV0m/9CAOneYFAQCS0zKRmpGlhdJRtuIEHf67b2DAL6eQkaUoOnPBV3qFY8s/3b47KgiDGyI9JJPJsHpIC7zdtHqefTUm7UL9aftQZ8pefqvWouL0FVl59B6C7z3DwRsxGigRUcXB4IZIj81/1xsXp3QpcL/75N0qMyGT5pSkuSj9FWputN4sVcbnV/f9JaRm4NDN6FLVls3ceR0zdl5Tb4GKSdt/Z03jPDdEeq5yJRPcn90Dq47dw3e7buTZP2fvTcQmp6FnI2eYGBng8sM49GlSrfTLOpDavUoNmzY+8yry5+wHq07j0sN4jO3sic+71C72cfEvMvDbiTAAQCUTI3zxRm3Op1OGWHNDRACA4e1rIsy/O3xq2ubZ9+uxMPRedgLdFh3DxM1X4PXtXgSFxig7Ij+Oe6GFElO2LMUrBDfarrmpYC2flx5Ki5xuufiwZAfmuM+lh+/g0E02JZYlBjdEpCSTybDuo9a4P7sHdo9pX2jeIWvOApA6IreZfQjvrzqtrEEorDNy4itU6+uTknyrf5XgRhcoFAL3niRptI/Yq85DdO8JRyaWJTZLEVG+6jlb4f7sHkjLzMLQNWdx8u6zQvMfv/MU7pN3q6QNa+eO5m6VEfIgDs1rVMGEjZcQ/yIDAPDZ6x744g2vMit/RVeSj87fg+/D3MQIPRo55bv/xJ2n2HzhIab1qg9rM9UFQHVhssDJW65gw7kHmPFmfQxuU0NlX3lp+snKFXjl3ib1YnBDRIWSGxli7QhpdmMhBK49TsDnG0JwO6boJRxWHw/D6uNSP4OVR++p7Fty6A4Cr0fjow418fvJ+xjWviacrE2x6MBteDla4quuXjCUyWBoIEP4sxQ42Zji8sN41LCtBGszY8hkwDdbr6BWVQv8r5UrLE3VsGp3McS/yMDsPTfxVtNqaFGjilrO+SA2BVUt5TA1ftmPqSSfyVcfJWDU2gvo0ahHvvsHrjoNQPpb+r/VUGWf1j/71fAZv+HcAwDAggO38gY3r356tchdu1Yea9sUCoG1ZyLQxNUG9Z2ttV2cV1Iugptly5Zh7ty5iIqKgre3N5YsWYKWLVsWmH/jxo2YMmUK7t+/D09PT8yZMwfdu3fXYImJ9JNMJkODatYIHN9RmZaclolfj93D6uNhSEwt2WzHN6MSMf6fSwCAMesuKtOP33mqDIqKw3/PTewe0x51HC0Rm5KOgBP30bdpNThbm8HMxBCpGVnYdP4hXqtjj2o2ZsrjshQCWQqBtMwsWJoaIz1TAUMDqS7j2uMEeDlaQiYDLj+MQ8NqNoiITcHKI3ex8fxDrDsTgd+GNMfrdRxKdM+5XXscjx6Lj8PT3kLluZbmQ7moRR9vRyeqbE/cdFkZGJSWEAKj1l6AnYUcM3s3KNYxZRVQFfe0h0NjcCsqER91qKl8XkUFG08S03Ax4nmpy6bIVVOj0HBwY2r8shdKRpYCxoZ5e6X8eyUS3267CgC4P1sKlH85ehdVLeXoWt8JZiYVZxCB1oObDRs2YPz48VixYgVatWqFhQsXws/PD6GhobC3t8+T/+TJkxgwYAD8/f3Rs2dPrF27Fn369MGFCxfQoEHx/mERkfpUkhthnG9tjPNVHTmSmJqBrRcf4eitp7jyKA7RCWllWo7ui4+pbC89fKdMrwcAHwacg7tdJYQ9TYZMln/n2IX9GyPkQRyeJKahciVj/HUqAmuHt8L9ZylYfzYCl//roHo7JgkKhUCWELj3JBmHQ18u3lhv6l5YmhphzZCWsJAbYeHBW9hy4VGea43/5xI+960NV1tz3H+ajMuP4pGR+bJv07nw54hJTMXt6CRcCH+eJ7DpvugYujZwRINqVmjpbou7MUmYvecmxnT2hE8tWyw8cAtnwmLRvaETmrlVRh1HS9yOScLuK1EAgMFtaiAxNROhUQno2cgZ0QmpiElMw6DfzmDt8Fa48ige1SubY8Qf55TXPBX2DH71HSGEwK3oJDham8LU2AAmhgaIiE3B8TtPcf9pMr7qWkf5gfwo7gWO334CN9tKiEtJV57reUoGrj6KR31nK/RZdgKXHsbDt+7L4DPkQRwau9hg6H/9xeo6WaFD7apIz1Rgy4W8HYTjUtIRfPcZ6jtbo8Pcwyr7xH9VTjN3XseJO0/h/3ZD1HW0wqpj93Ds9lP88FYDeNhbApC+APRfGaxyfEpGFg5cj8a1xwmITkxFK/cq2HbxEZxszHAjMgHPktJRz8kKNubGOH7nKbrWd0Q7TztUqWSC1AwFFh+8jXG+njh6+ylqVa2EwOvRsLOQw9BAhiauNmjuVgWO1qZ4npyOK4/iYZajVvDyw3gkpWXiz+BwHLgRjSk96+HDtjWw71qUShmP3X6CH3bfBABMNLyC34a0gIe9BRytTZGSngkzY0MkpGbCylQKJcpLEyAAyISWZ+lq1aoVWrRogaVLlwIAFAoFXFxc8Nlnn2HSpEl58vfv3x/Jycn4999/lWmtW7dG48aNsWLFiiKvl5CQAGtra8THx8PKiqsSE2lTSnomwp+l4ExYLLZefISQB3HaLhKR2nSsXRV3nyTh4XP9G004uVsdlZoxdSjJ57dWa27S09Nx/vx5TJ48WZlmYGAAX19fBAcH53tMcHAwxo8fr5Lm5+eHbdu25Zs/LS0NaWkvvzEmJCS8esGJSC3MTYxQ18kKdZ2s8vSVKIgQAklpmUjNUCAtMwsXI+Jw8u4ztK5ZBXuvRqGVexVce5yAjedLOFSXSM2O3HpSdCYd5b/nJj7uWEtr19dqcPP06VNkZWXBwUG1zdrBwQE3b97M95ioqKh880dFReWb39/fHzNmzFBPgYlI62QyGSxNjWFpKm1Xr2yOXt7OAIDejasp883t562N4kEIgfQsBUwMDZCaoYCAQFqGAklpmTAxMkB6pgKhUYl4+DwFjtZmsLUwgYEMuPskGVXMTRCTmIbnKem4/zQZPrVs4eVoid+O34eF3BCVK5ngyK0nSM1Q4EZkAmo7WKBnI2f8euwe6jpaIToxFfEvMjCgpavKzNJmxobo17w6Np57iBcZWahmY4ZHOeYmqutkBTsLExy7/RQGMqCg7iBWpkZIKGG/KipfajtY4FZ00YMBXtXPA5uW+TUKo/U+N2Vt8uTJKjU9CQkJcHFx0WKJiEiXyWQy5ezN2R0wzU2kmaCzuVQxz3NcM7eCR17Nf/dloJa7bxMAjOnsmSdtYtc6edKK2+GXqKLTanBjZ2cHQ0NDREdHq6RHR0fD0dEx32McHR1LlF8ul0Mul6unwERERFTuaXWGYhMTEzRr1gwHDx5UpikUChw8eBA+Pj75HuPj46OSHwACAwMLzE9ERET6RevNUuPHj8fgwYPRvHlztGzZEgsXLkRycjKGDh0KABg0aBCqVasGf39/AMDYsWPRsWNHzJ8/Hz169MD69etx7tw5/PLLL9q8DSIiIiontB7c9O/fH0+ePMHUqVMRFRWFxo0bY+/evcpOwxERETAweFnB1KZNG6xduxbffvstvv76a3h6emLbtm2c44aIiIgAlIN5bjSN89wQERFVPCX5/Oaq4ERERKRTGNwQERGRTmFwQ0RERDqFwQ0RERHpFAY3REREpFMY3BAREZFOYXBDREREOoXBDREREekUBjdERESkU7S+/IKmZU/InJCQoOWSEBERUXFlf24XZ2EFvQtuEhMTAQAuLi5aLgkRERGVVGJiIqytrQvNo3drSykUCjx+/BiWlpaQyWRqPXdCQgJcXFzw4MEDrltVhvicNYPPWTP4nDWHz1ozyuo5CyGQmJgIZ2dnlQW186N3NTcGBgaoXr16mV7DysqK/3A0gM9ZM/icNYPPWXP4rDWjLJ5zUTU22dihmIiIiHQKgxsiIiLSKQxu1Egul2PatGmQy+XaLopO43PWDD5nzeBz1hw+a80oD89Z7zoUExERkW5jzQ0RERHpFAY3REREpFMY3BAREZFOYXBDREREOoXBjZosW7YMNWrUgKmpKVq1aoUzZ85ou0jl2tGjR9GrVy84OztDJpNh27ZtKvuFEJg6dSqcnJxgZmYGX19f3L59WyVPbGwsBg4cCCsrK9jY2GDYsGFISkpSyXP58mW0b98epqamcHFxwY8//ljWt1au+Pv7o0WLFrC0tIS9vT369OmD0NBQlTypqakYNWoUbG1tYWFhgbfffhvR0dEqeSIiItCjRw+Ym5vD3t4eX375JTIzM1XyBAUFoWnTppDL5fDw8EBAQEBZ3165sXz5cjRq1Eg5aZmPjw/27Nmj3M9nXDZmz54NmUyGcePGKdP4rF/d9OnTIZPJVF516tRR7q8Qz1jQK1u/fr0wMTERv/32m7h27ZoYMWKEsLGxEdHR0douWrm1e/du8c0334gtW7YIAGLr1q0q+2fPni2sra3Ftm3bxKVLl8Sbb74p3N3dxYsXL5R5unbtKry9vcWpU6fEsWPHhIeHhxgwYIByf3x8vHBwcBADBw4UV69eFevWrRNmZmZi5cqVmrpNrfPz8xNr1qwRV69eFSEhIaJ79+7C1dVVJCUlKfN88sknwsXFRRw8eFCcO3dOtG7dWrRp00a5PzMzUzRo0ED4+vqKixcvit27dws7OzsxefJkZZ579+4Jc3NzMX78eHH9+nWxZMkSYWhoKPbu3avR+9WWHTt2iF27dolbt26J0NBQ8fXXXwtjY2Nx9epVIQSfcVk4c+aMqFGjhmjUqJEYO3asMp3P+tVNmzZN1K9fX0RGRipfT548Ue6vCM+YwY0atGzZUowaNUq5nZWVJZydnYW/v78WS1Vx5A5uFAqFcHR0FHPnzlWmxcXFCblcLtatWyeEEOL69esCgDh79qwyz549e4RMJhOPHj0SQgjx888/i8qVK4u0tDRlnokTJwovL68yvqPyKyYmRgAQR44cEUJIz9XY2Fhs3LhRmefGjRsCgAgODhZCSIGogYGBiIqKUuZZvny5sLKyUj7br776StSvX1/lWv379xd+fn5lfUvlVuXKlcWqVav4jMtAYmKi8PT0FIGBgaJjx47K4IbPWj2mTZsmvL29891XUZ4xm6VeUXp6Os6fPw9fX19lmoGBAXx9fREcHKzFklVcYWFhiIqKUnmm1tbWaNWqlfKZBgcHw8bGBs2bN1fm8fX1hYGBAU6fPq3M06FDB5iYmCjz+Pn5ITQ0FM+fP9fQ3ZQv8fHxAIAqVaoAAM6fP4+MjAyVZ12nTh24urqqPOuGDRvCwcFBmcfPzw8JCQm4du2aMk/Oc2Tn0cd/A1lZWVi/fj2Sk5Ph4+PDZ1wGRo0ahR49euR5HnzW6nP79m04OzujZs2aGDhwICIiIgBUnGfM4OYVPX36FFlZWSp/RABwcHBAVFSUlkpVsWU/t8KeaVRUFOzt7VX2GxkZoUqVKip58jtHzmvoE4VCgXHjxqFt27Zo0KABAOk5mJiYwMbGRiVv7mdd1HMsKE9CQgJevHhRFrdT7ly5cgUWFhaQy+X45JNPsHXrVtSrV4/PWM3Wr1+PCxcuwN/fP88+Pmv1aNWqFQICArB3714sX74cYWFhaN++PRITEyvMM9a7VcGJ9NWoUaNw9epVHD9+XNtF0UleXl4ICQlBfHw8Nm3ahMGDB+PIkSPaLpZOefDgAcaOHYvAwECYmppquzg6q1u3bsrfGzVqhFatWsHNzQ3//PMPzMzMtFiy4mPNzSuys7ODoaFhnp7i0dHRcHR01FKpKrbs51bYM3V0dERMTIzK/szMTMTGxqrkye8cOa+hL0aPHo1///0Xhw8fRvXq1ZXpjo6OSE9PR1xcnEr+3M+6qOdYUB4rK6sK85/hqzIxMYGHhweaNWsGf39/eHt7Y9GiRXzGanT+/HnExMSgadOmMDIygpGREY4cOYLFixfDyMgIDg4OfNZlwMbGBrVr18adO3cqzPuZwc0rMjExQbNmzXDw4EFlmkKhwMGDB+Hj46PFklVc7u7ucHR0VHmmCQkJOH36tPKZ+vj4IC4uDufPn1fmOXToEBQKBVq1aqXMc/ToUWRkZCjzBAYGwsvLC5UrV9bQ3WiXEAKjR4/G1q1bcejQIbi7u6vsb9asGYyNjVWedWhoKCIiIlSe9ZUrV1SCycDAQFhZWaFevXrKPDnPkZ1Hn/8NKBQKpKWl8RmrUefOnXHlyhWEhIQoX82bN8fAgQOVv/NZq19SUhLu3r0LJyenivN+Vku3ZD23fv16IZfLRUBAgLh+/br46KOPhI2NjUpPcVKVmJgoLl68KC5evCgAiJ9++klcvHhRhIeHCyGkoeA2NjZi+/bt4vLly6J37975DgVv0qSJOH36tDh+/Ljw9PRUGQoeFxcnHBwcxAcffCCuXr0q1q9fL8zNzfVqKPinn34qrK2tRVBQkMqwzpSUFGWeTz75RLi6uopDhw6Jc+fOCR8fH+Hj46Pcnz2s84033hAhISFi7969omrVqvkO6/zyyy/FjRs3xLJly/Rq6OykSZPEkSNHRFhYmLh8+bKYNGmSkMlkYv/+/UIIPuOylHO0lBB81urwxRdfiKCgIBEWFiZOnDghfH19hZ2dnYiJiRFCVIxnzOBGTZYsWSJcXV2FiYmJaNmypTh16pS2i1SuHT58WADI8xo8eLAQQhoOPmXKFOHg4CDkcrno3LmzCA0NVTnHs2fPxIABA4SFhYWwsrISQ4cOFYmJiSp5Ll26JNq1ayfkcrmoVq2amD17tqZusVzI7xkDEGvWrFHmefHihRg5cqSoXLmyMDc3F3379hWRkZEq57l//77o1q2bMDMzE3Z2duKLL74QGRkZKnkOHz4sGjduLExMTETNmjVVrqHrPvzwQ+Hm5iZMTExE1apVRefOnZWBjRB8xmUpd3DDZ/3q+vfvL5ycnISJiYmoVq2a6N+/v7hz545yf0V4xjIhhFBPHRARERGR9rHPDREREekUBjdERESkUxjcEBERkU5hcENEREQ6hcENERER6RQGN0RERKRTGNwQERGRTmFwQ0Q6Lz09HR4eHjh58qRGr3v9+nVUr14dycnJGr0ukb5jcENEJfbkyRN8+umncHV1hVwuh6OjI/z8/HDixAllHplMhm3btmmvkDmsWLEC7u7uaNOmTbGP2bJlC9544w3Y2tpCJpMhJCQkT57U1FSMGjUKtra2sLCwwNtvv62yGGC9evXQunVr/PTTT+q4DSIqJgY3RFRib7/9Ni5evIjff/8dt27dwo4dO9CpUyc8e/ZM20XLQwiBpUuXYtiwYSU6Ljk5Ge3atcOcOXMKzPP5559j586d2LhxI44cOYLHjx/jrbfeUskzdOhQLF++HJmZmaUqPxGVgtoWciAivfD8+XMBQAQFBRWYx83NTWUtKzc3N+W+bdu2iSZNmgi5XC7c3d3F9OnTVdacASB+/vln0bVrV2Fqairc3d3Fxo0blfvT0tLEqFGjhKOjo5DL5cLV1VX88MMPBZbl7NmzwsDAQCQkJCjTfv/9d1GpUiVx69YtZdqnn34qvLy8RHJyssrxYWFhAoC4ePGiSnpcXJwwNjZWKduNGzcEABEcHKxSXrlcLg4cOFBgGYlIvVhzQ0QlYmFhAQsLC2zbtg1paWn55jl79iwAYM2aNYiMjFRuHzt2DIMGDcLYsWNx/fp1rFy5EgEBAfj+++9Vjp8yZQrefvttXLp0CQMHDsR7772HGzduAAAWL16MHTt24J9//kFoaCj+/vtv1KhRo8DyHjt2DLVr14alpaUybdCgQejevTsGDhyIzMxM7Nq1C6tWrcLff/8Nc3PzYj2H8+fPIyMjA76+vsq0OnXqwNXVFcHBwco0ExMTNG7cGMeOHSvWeYno1TG4IaISMTIyQkBAAH7//XfY2Nigbdu2+Prrr3H58mVlnqpVqwIAbGxs4OjoqNyeMWMGJk2ahMGDB6NmzZro0qULZs2ahZUrV6pco1+/fhg+fDhq166NWbNmoXnz5liyZAkAICIiAp6enmjXrh3c3NzQrl07DBgwoMDyhoeHw9nZOU/6ypUrERkZiTFjxmDYsGGYPn06mjVrVuznEBUVBRMTE9jY2KikOzg4ICoqSiXN2dkZ4eHhxT43Eb0aBjdEVGJvv/02Hj9+jB07dqBr164ICgpC06ZNERAQUOhxly5dwsyZM5W1PxYWFhgxYgQiIyORkpKizOfj46NynI+Pj7LmZsiQIQgJCYGXlxfGjBmD/fv3F3rNFy9ewNTUNE965cqVsXr1aixfvhy1atXCpEmTinn3JWdmZqZyf0RUthjcEFGpmJqaokuXLpgyZQpOnjyJIUOGYNq0aYUek5SUhBkzZiAkJET5unLlCm7fvp1vAJKfpk2bIiwsDLNmzcKLFy/w7rvv4p133ikwv52dHZ4/f57vvqNHj8LQ0BCRkZElHq7t6OiI9PR0xMXFqaRHR0fD0dFRJS02NlZZe0VEZY/BDRGpRb169VQCBGNjY2RlZankadq0KUJDQ+Hh4ZHnZWDw8r+jU6dOqRx36tQp1K1bV7ltZWWF/v3749dff8WGDRuwefNmxMbG5luuJk2a4ObNmxBCqKSfPHkSc+bMwc6dO2FhYYHRo0eX6H6bNWsGY2NjHDx4UJkWGhqKiIiIPDVPV69eRZMmTUp0fiIqPSNtF4CIKpZnz56hX79++PDDD9GoUSNYWlri3Llz+PHHH9G7d29lvho1auDgwYNo27Yt5HI5KleujKlTp6Jnz55wdXXFO++8AwMDA1y6dAlXr17Fd999pzx248aNaN68Odq1a4e///4bZ86cwerVqwEAP/30E5ycnNCkSRMYGBhg48aNcHR0zNP3Jdtrr72GpKQkXLt2DQ0aNAAAJCYm4oMPPsCYMWPQrVs3VK9eHS1atECvXr2UtUCxsbGIiIjA48ePAUiBCyDV2Dg6OsLa2hrDhg3D+PHjUaVKFVhZWeGzzz6Dj48PWrdurbz+/fv38ejRI5WOx0RUxrQ9XIuIKpbU1FQxadIk0bRpU2FtbS3Mzc2Fl5eX+Pbbb0VKSooy344dO4SHh4cwMjJSGQq+d+9e0aZNG2FmZiasrKxEy5YtxS+//KLcD0AsW7ZMdOnSRcjlclGjRg2xYcMG5f5ffvlFNG7cWFSqVElYWVmJzp07iwsXLhRa5nfffVdMmjRJuT106FDRsGFDkZqaqkybP3++qFKlinj48KEQQog1a9aoDGfPfk2bNk15zIsXL8TIkSNF5cqVhbm5uejbt6+IjIxUufYPP/wg/Pz8ivdwiUgtZELkqqslItIimUyGrVu3ok+fPmo75+XLl9GlSxfcvXsXFhYWajtvUdLT0+Hp6Ym1a9eibdu2Grsukb5jnxsi0nmNGjXCnDlzEBYWptHrRkRE4Ouvv2ZgQ6RhrLkhonKlLGpuiEi/sEMxEZUr/L5FRK+KzVJERESkUxjcEBERkU5hcENEREQ6hcENERER6RQGN0RERKRTGNwQERGRTmFwQ0RERDqFwQ0RERHpFAY3REREpFP+D0b8gWS31bFqAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "g = torch.Generator().manual_seed(42)\n",
        "g.manual_seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "class DNet(nn.Module):\n",
        "    def __init__(self, input_size: int, hidden_size: int, output_size: int):\n",
        "        super().__init__()\n",
        "        self.seq_model = nn.Sequential(\n",
        "            nn.Linear(input_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, hidden_size,bias=True),\n",
        "\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(hidden_size, output_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return self.seq_model(x)\n",
        "\n",
        "\n",
        "dnet = DNet(input_size=2,hidden_size=16,output_size=1)\n",
        "loss_fn = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(dnet.parameters(), lr=0.01)\n",
        "\n",
        "t_losses = []\n",
        "val_losses = []\n",
        "\n",
        "min_val_loss : float = float('inf')\n",
        "patience : int = 100  # Number of epochs to wait for improvement before stopping\n",
        "steps_no_improve : int= 0\n",
        "min_step : int = 0\n",
        "\n",
        "for steps in range(50000):\n",
        "    dnet.train()\n",
        "\n",
        "    output = dnet(train_data)\n",
        "    train_loss = loss_fn(output, train_labels)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if steps % 10 == 0:\n",
        "        dnet.eval()\n",
        "        output = dnet(val_data)\n",
        "        val_loss = loss_fn(output, val_labels)\n",
        "        output = dnet(train_data)\n",
        "        t_loss = loss_fn(output,train_labels)\n",
        "\n",
        "        if val_loss < min_val_loss:\n",
        "            min_val_loss = val_loss\n",
        "            steps_no_improve = 0\n",
        "            min_step = steps\n",
        "            #save model here\n",
        "        else:\n",
        "            steps_no_improve += 1\n",
        "            if steps_no_improve == patience:\n",
        "                print(f'Early stopping! min step : {min_step}')\n",
        "                break  # Early stop\n",
        "\n",
        "\n",
        "        t_losses.append(t_loss.item())\n",
        "        val_losses.append(val_loss.item())\n",
        "        # print(f\"{steps} val_loss: {val_loss.item()}, train_loss: {t_loss.item()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hgGIAsc2UT4w",
        "outputId": "118e70cc-8978-43b0-b0b5-27b1f92e40e1"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Early stopping! min step : 22410\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assumes `t_losses` and `val_losses` are lists of loss values\n",
        "plt.plot(t_losses, label='Training loss')\n",
        "plt.plot(val_losses, label='Validation loss')\n",
        "plt.title('Training and Validation Losses')\n",
        "plt.xlabel('Steps (x100)')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "jmrfbSMPUV43",
        "outputId": "38bfc238-95db-43c9-9b6b-5fa4ab3157c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}