{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNM6I+keYCcbIL6OPUgS7v6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NoCodeProgram/deepLearning/blob/main/nn/classification_b.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDl0swNLEGnj",
        "outputId": "893ef554-5df6-46cb-9acb-b3b2d6711ea2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'deepLearning'...\n",
            "remote: Enumerating objects: 56, done.\u001b[K\n",
            "remote: Counting objects: 100% (56/56), done.\u001b[K\n",
            "remote: Compressing objects: 100% (49/49), done.\u001b[K\n",
            "remote: Total 56 (delta 9), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (56/56), 1.85 MiB | 4.47 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/NoCodeProgram/deepLearning.git\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "# Load the DataFrame from a CSV file\n",
        "df = pd.read_csv('./deepLearning/nn/classify5k.csv')\n",
        "\n",
        "# Convert the DataFrame to a numpy array\n",
        "data = df[['x', 'y']].values\n",
        "labels = df['label'].values.reshape(-1, 1)\n",
        "\n",
        "# Print the shapes of the data and labels\n",
        "print(f'Data shape:{data.shape}')\n",
        "print(f'Labels shape:{labels.shape}')\n"
      ],
      "metadata": {
        "id": "3fd0kfWMPQRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot the points\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(data[:,0], data[:,1], c=labels, cmap='viridis', s=1)\n",
        "plt.title('Sample Data with Noisy Labels')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Ne2FwPnAP30z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the numpy arrays to PyTorch tensors\n",
        "data_torch = torch.tensor(data, dtype=torch.float32)\n",
        "labels_torch = torch.tensor(labels, dtype=torch.float32)\n",
        "data_length = len(data_torch)\n",
        "split_length = int(0.8*data_length)\n",
        "\n",
        "train_data = data_torch[:split_length]\n",
        "train_labels = labels_torch[:split_length]\n",
        "val_data = data_torch[split_length:]\n",
        "val_labels = labels_torch[split_length:]\n",
        "\n",
        "print(train_data.shape, train_labels.shape)"
      ],
      "metadata": {
        "id": "mtIZ6g6hQOBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "g = torch.Generator().manual_seed(42)\n",
        "\n",
        "def get_batch(data, labels, batch_size=256):\n",
        "    # Generate random indices\n",
        "    indices = torch.randint(0, len(data), size=(batch_size,), generator= g)\n",
        "\n",
        "    # Select the data and labels at these indices\n",
        "    data_batch = data[indices]\n",
        "    labels_batch = labels[indices]\n",
        "\n",
        "    return data_batch, labels_batch\n",
        "\n",
        "data_batch, labels_batch = get_batch(train_data,train_labels)\n",
        "print(data_batch.shape, labels_batch.shape)"
      ],
      "metadata": {
        "id": "jGHC_JKeQMEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 4\n",
        "output_size = 1\n",
        "\n",
        "g.manual_seed(42)\n",
        "W1 = torch.randn((input_size, hidden_size), generator=g)\n",
        "b1 = torch.randn(hidden_size, generator=g)\n",
        "W2 = torch.randn((hidden_size, output_size) , generator=g)\n",
        "b2 = torch.randn(output_size, generator=g)\n",
        "params = [W1,b1,W2,b2]\n",
        "for p in params:\n",
        "    p.requires_grad = True\n",
        "\n",
        "for steps in range(200000):\n",
        "    data_batch, labels_batch = get_batch(train_data,train_labels, batch_size=256)\n",
        "    tmp = data_batch@W1 + b1\n",
        "    tmp = F.relu(tmp)\n",
        "    output = tmp@W2 + b2\n",
        "    prob = torch.sigmoid(output)\n",
        "    loss = -1 * (labels_batch * torch.log(prob) + (1 - labels_batch) * torch.log(1 - prob)).mean()\n",
        "\n",
        "    loss.backward()\n",
        "    with torch.no_grad():\n",
        "        W1 -= 0.01 * W1.grad\n",
        "        b1 -= 0.01 * b1.grad\n",
        "        W2 -= 0.01 * W2.grad\n",
        "        b2 -= 0.01 * b2.grad\n",
        "        W1.grad.zero_()\n",
        "        b1.grad.zero_()\n",
        "        W2.grad.zero_()\n",
        "        b2.grad.zero_()\n",
        "\n",
        "    if steps % 1000 == 0:\n",
        "        tmp = val_data@W1 + b1\n",
        "        tmp = F.relu(tmp)\n",
        "        output = tmp@W2 + b2\n",
        "        prob = torch.sigmoid(output)\n",
        "        val_loss = -1 * (val_labels * torch.log(prob) + (1 - val_labels) * torch.log(1 - prob)).mean()\n",
        "        print(f\"{steps},val_loss: {val_loss},train_loss: {loss}\" )\n",
        "\n"
      ],
      "metadata": {
        "id": "HJ_VUCJ6Qm0n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate 10000 new points\n",
        "n_points_test = 100000\n",
        "points_test = np.random.uniform(-1, 1, (n_points_test, 2))\n",
        "points_test_torch = torch.from_numpy(points_test).float()\n",
        "\n",
        "# Run the points through the network\n",
        "with torch.no_grad():  # We don't need gradients for this part\n",
        "    tmp = points_test_torch@W1 + b1\n",
        "    tmp = F.relu(tmp)\n",
        "    output_test = tmp@W2 + b2\n",
        "    prob = torch.sigmoid(output_test)\n",
        "pred = (0.5 < prob).numpy()\n",
        "\n",
        "# Plot the points, colored by their predicted class\n",
        "plt.figure(figsize=(6, 6))\n",
        "plt.scatter(points_test[:, 0], points_test[:, 1], c=pred, cmap='viridis', s=1)\n",
        "plt.title('Predicted Classes for Test Points')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CXWs0AgNTLW2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}